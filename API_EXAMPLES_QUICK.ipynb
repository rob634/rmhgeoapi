{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# API Examples - Quick Reference\n\nCondensed notebook covering the core Platform endpoints (updated 13 DEC 2025):\n\n1. Health Check\n2. Container Check (Sync)\n3. Process Vector\n4. **Process Raster v2** (single file, ‚â§800 MB)\n5. **Process Large Raster v2** (100 MB - 30 GB, tiled processing)\n6. **Process Raster Collection v2** (‚â§20 files, each ‚â§800 MB)\n7. Rejection Examples (size/count limit violations)\n\n### Size Routing Summary\n\n| File Size | Job Type | Notes |\n|-----------|----------|-------|\n| ‚â§800 MB | `process_raster_v2` | Standard COG conversion |\n| 100 MB - 30 GB | `process_large_raster_v2` | Tiled COG workflow |\n| Collection ‚â§20 files | `process_raster_collection_v2` | Each file must be ‚â§800 MB |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - All variables defined here\n",
    "# =============================================================================\n",
    "\n",
    "# Function App Base URL\n",
    "BASE_URL = \"https://rmhazuregeoapi-a3dma3ctfdgngwf6.eastus-01.azurewebsites.net\"\n",
    "\n",
    "# Storage Containers (Bronze = raw input, Silver = processed output)\n",
    "BRONZE_RASTERS_CONTAINER = \"bronze-rasters\"\n",
    "BRONZE_VECTORS_CONTAINER = \"bronze-vectors\"\n",
    "SILVER_COGS_CONTAINER = \"silver-cogs\"\n",
    "\n",
    "# STAC Collections\n",
    "RASTER_COLLECTION_ID = \"system-rasters\"\n",
    "VECTOR_COLLECTION_ID = \"system-vectors\"\n",
    "\n",
    "# PostGIS Schema\n",
    "POSTGIS_SCHEMA = \"geo\"\n",
    "\n",
    "# =============================================================================\n",
    "# Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def api_call(method, endpoint, data=None, params=None, timeout=30):\n",
    "    \"\"\"Make API call and return formatted response.\"\"\"\n",
    "    url = f\"{BASE_URL}{endpoint}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{method} {endpoint}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if data:\n",
    "        print(f\"\\nRequest Body:\")\n",
    "        print(json.dumps(data, indent=2))\n",
    "    \n",
    "    try:\n",
    "        if method == \"GET\":\n",
    "            response = requests.get(url, params=params, timeout=timeout)\n",
    "        elif method == \"POST\":\n",
    "            response = requests.post(url, json=data, headers=headers, timeout=timeout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "        \n",
    "        print(f\"\\nStatus: {response.status_code}\")\n",
    "        \n",
    "        try:\n",
    "            result = response.json()\n",
    "            print(f\"\\nResponse:\")\n",
    "            print(json.dumps(result, indent=2, default=str))\n",
    "            return result\n",
    "        except:\n",
    "            print(f\"\\nResponse (text): {response.text[:500]}\")\n",
    "            return response.text\n",
    "            \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"\\n‚ùå Request timed out (timeout={timeout}s)\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def check_job_status(job_id, max_polls=20, poll_interval=5):\n",
    "    \"\"\"Poll job status until completion or timeout.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Polling job: {job_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i in range(max_polls):\n",
    "        result = requests.get(f\"{BASE_URL}/api/jobs/status/{job_id}\", timeout=30).json()\n",
    "        status = result.get(\"status\", \"unknown\")\n",
    "        stage = result.get(\"current_stage\", \"?\")\n",
    "        \n",
    "        print(f\"  [{i+1}/{max_polls}] Status: {status}, Stage: {stage}\")\n",
    "        \n",
    "        if status in [\"completed\", \"failed\"]:\n",
    "            print(f\"\\nFinal Result:\")\n",
    "            print(json.dumps(result, indent=2, default=str))\n",
    "            return result\n",
    "        \n",
    "        time.sleep(poll_interval)\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è Polling timeout after {max_polls * poll_interval}s\")\n",
    "    return result\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"API CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Base URL:              {BASE_URL}\")\n",
    "print(f\"Bronze Rasters:        {BRONZE_RASTERS_CONTAINER}\")\n",
    "print(f\"Bronze Vectors:        {BRONZE_VECTORS_CONTAINER}\")\n",
    "print(f\"Silver COGs:           {SILVER_COGS_CONTAINER}\")\n",
    "print(f\"Raster Collection:     {RASTER_COLLECTION_ID}\")\n",
    "print(f\"Vector Collection:     {VECTOR_COLLECTION_ID}\")\n",
    "print(f\"PostGIS Schema:        {POSTGIS_SCHEMA}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Health Check\n",
    "\n",
    "Comprehensive system health check (~60s due to database, Service Bus, and storage checks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health Check (takes ~60s)\n",
    "result = api_call(\"GET\", \"/api/health\", timeout=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Container Check (Sync)\n",
    "\n",
    "Quick synchronous endpoint to list blobs in a container. No job queue - returns immediately.\n",
    "\n",
    "**Parameters:**\n",
    "- `suffix`: Filter by extension (e.g., `.tif`, `.geojson`)\n",
    "- `metadata`: `true` (default) returns full blob info, `false` returns just names\n",
    "- `limit`: Max blobs to return (default: 500, max: 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container Check - Sync endpoint (returns immediately, no job queue)\n",
    "# Uses the bronze container configured above\n",
    "\n",
    "# List first 10 TIF files with full metadata\n",
    "container_name = \"rmhazuregeobronze\"  # QA environment container\n",
    "result = api_call(\"GET\", f\"/api/containers/{container_name}/blobs\", \n",
    "                  params={\"suffix\": \".tif\", \"limit\": 10, \"metadata\": \"true\"})\n",
    "\n",
    "# Show summary\n",
    "if result and isinstance(result, dict):\n",
    "    count = result.get(\"count\", 0)\n",
    "    blobs = result.get(\"blobs\", [])\n",
    "    print(f\"\\nüìä Found {count} TIF files\")\n",
    "    if blobs:\n",
    "        total_mb = sum(b.get(\"size_mb\", 0) for b in blobs)\n",
    "        print(f\"üì¶ Total size: {total_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Process Vector\n",
    "\n",
    "Submit a vector file (GeoJSON, Shapefile, GeoPackage) for ingestion into PostGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit Vector\n",
    "vector_request = {\n",
    "    \"dataset_id\": \"test-vectors\",\n",
    "    \"resource_id\": \"geojson-8\",\n",
    "    \"version_id\": \"v1\",\n",
    "    \"container_name\": BRONZE_VECTORS_CONTAINER,\n",
    "    \"file_name\": \"8.geojson\",\n",
    "    \"service_name\": \"Test GeoJSON 8\"\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/platform/submit\", vector_request)\n",
    "vector_job_id = result.get(\"job_id\") if result else None\n",
    "print(f\"\\nüìã Job ID: {vector_job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Vector Job Status\n",
    "if vector_job_id:\n",
    "    check_job_status(vector_job_id)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No job_id from previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 4. Process Raster (Single File)\n\nSubmit a single raster file for COG conversion and STAC cataloging.\n\n### Size Limits (13 DEC 2025)\n\n| Limit | Value | Behavior |\n|-------|-------|----------|\n| **Max file size** | 800 MB | Files >800MB rejected ‚Üí use `process_large_raster_v2` |\n| **Min file size** | None | Any size accepted |\n\n**Pre-flight validation** automatically checks file size before processing.\n\n### Test Data\n- **dctest.tif** (25.8 MB) - Small RGB GeoTIFF, processes in ~22 seconds\n- **antigua.tif** (11.16 GB) - Too large, will be rejected with error message"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Submit Single Raster via CoreMachine API (direct)\n# Using dctest.tif (25.8 MB) - verified working 13 DEC 2025\n\nraster_request = {\n    \"blob_name\": \"dctest.tif\",\n    \"container_name\": \"rmhazuregeobronze\"\n}\n\nresult = api_call(\"POST\", \"/api/jobs/submit/process_raster_v2\", raster_request)\nraster_job_id = result.get(\"job_id\") if result else None\n\n# Show size metadata from pre-flight validation\nif result and \"parameters\" in result:\n    params = result[\"parameters\"]\n    print(f\"\\nüìè Pre-flight Size Check:\")\n    print(f\"   File size: {params.get('_blob_size_mb', 'N/A'):.2f} MB\")\n    print(f\"   File exists: ‚úÖ\")\n\nprint(f\"\\nüìã Job ID: {raster_job_id}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Raster Job Status\n",
    "if raster_job_id:\n",
    "    check_job_status(raster_job_id)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No job_id from previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 5. Process Large Raster (100 MB - 30 GB)\n\nSubmit a large raster for tiled COG processing. Uses 5-stage workflow:\n1. Generate tiling scheme\n2. Extract tiles (sequential)\n3. Create COGs (parallel)\n4. Create MosaicJSON\n5. Create STAC collection\n\n### Size Limits (13 DEC 2025)\n\n| Limit | Value | Behavior |\n|-------|-------|----------|\n| **Min file size** | 100 MB | Files <100MB should use `process_raster_v2` |\n| **Max file size** | 30 GB | Files >30GB not supported |\n\n### Test Data\n- **antigua.tif** (11.16 GB) - Large Caribbean DEM, processes via tiling workflow"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Submit Large Raster via CoreMachine API (direct)\n# Using antigua.tif (11.16 GB) - verified 13 DEC 2025\n# Note: This is a long-running job (~30+ minutes for tiling and COG creation)\n\nlarge_raster_request = {\n    \"blob_name\": \"antigua.tif\",\n    \"container_name\": \"rmhazuregeobronze\"\n}\n\nresult = api_call(\"POST\", \"/api/jobs/submit/process_large_raster_v2\", large_raster_request)\nlarge_raster_job_id = result.get(\"job_id\") if result else None\n\n# Show size metadata from pre-flight validation\nif result and \"parameters\" in result:\n    params = result[\"parameters\"]\n    size_mb = params.get('_blob_size_mb', 0)\n    print(f\"\\nüìè Pre-flight Size Check:\")\n    print(f\"   File size: {size_mb:.2f} MB ({size_mb/1024:.2f} GB)\")\n    print(f\"   Valid for large raster: {'‚úÖ' if 100 <= size_mb <= 30000 else '‚ùå'}\")\n\nprint(f\"\\nüìã Job ID: {large_raster_job_id}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Large Raster Job Status\n",
    "if large_raster_job_id:\n",
    "    check_job_status(large_raster_job_id, max_polls=30, poll_interval=10)  # Longer timeout for large files\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No job_id from previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 6. Process Raster Collection (Multi-File)\n\nSubmit multiple raster files to be processed as a collection with MosaicJSON.\n\n### Size and Count Limits (13 DEC 2025)\n\n| Limit | Value | Behavior |\n|-------|-------|----------|\n| **Max files per collection** | 20 | Collections with >20 files rejected |\n| **Max individual file size** | 800 MB | Collections with ANY file >800MB rejected |\n| **Min files per collection** | 2 | Single files should use `process_raster_v2` |\n\n**Pre-flight validation order:**\n1. **Collection count** - Rejected immediately if >20 files (before any blob checks)\n2. **Individual file sizes** - Each blob checked in parallel; rejected if ANY exceeds 800MB\n3. **File existence** - All blobs must exist in the container\n\n### Size Metadata Captured\nAfter validation, these fields are available in job parameters:\n- `_blob_list_count` - Number of files\n- `_blob_list_max_size_mb` - Largest file size\n- `_blob_list_total_size_mb` - Total size of all files\n- `_blob_list_largest_blob` - Name of largest file\n- `_blob_list_has_large_raster` - True if any file >800MB\n\n### Test Data\n- **namangan/** folder (4 tiles, 1.6 GB total):\n  - R1C1: 778 MB, R1C2: 704 MB, R2C1: 73 MB, R2C2: 65 MB\n  - All under 800 MB limit ‚úÖ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Submit Raster Collection via CoreMachine API (direct)\n# Using namangan 4-tile collection (1.6 GB total) - verified 13 DEC 2025\n\ncollection_request = {\n    \"container_name\": \"rmhazuregeobronze\",\n    \"blob_list\": [\n        \"namangan/namangan14aug2019_R1C1cog.tif\",  # 778 MB\n        \"namangan/namangan14aug2019_R1C2cog.tif\",  # 704 MB\n        \"namangan/namangan14aug2019_R2C1cog.tif\",  # 73 MB\n        \"namangan/namangan14aug2019_R2C2cog.tif\"   # 65 MB\n    ],\n    \"collection_id\": \"namangan-test\"\n}\n\nresult = api_call(\"POST\", \"/api/jobs/submit/process_raster_collection_v2\", collection_request)\ncollection_job_id = result.get(\"job_id\") if result else None\n\n# Show size metadata from pre-flight validation\nif result and \"parameters\" in result:\n    params = result[\"parameters\"]\n    print(f\"\\nüìè Pre-flight Size Check:\")\n    print(f\"   Files in collection: {params.get('_blob_list_count', 'N/A')}\")\n    print(f\"   Largest file: {params.get('_blob_list_max_size_mb', 0):.2f} MB\")\n    print(f\"   Total size: {params.get('_blob_list_total_size_mb', 0):.2f} MB\")\n    print(f\"   Largest blob: {params.get('_blob_list_largest_blob', 'N/A')}\")\n    print(f\"   Has large raster (>800MB): {'‚ùå Yes' if params.get('_blob_list_has_large_raster') else '‚úÖ No'}\")\n\nprint(f\"\\nüìã Job ID: {collection_job_id}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Raster Collection Job Status\n",
    "if collection_job_id:\n",
    "    check_job_status(collection_job_id, max_polls=30, poll_interval=10)  # Longer timeout for multi-file\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No job_id from previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Reference: Manual Job Status Check\n",
    "\n",
    "Use this cell to check any job by ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Job Status Check\n",
    "# Replace with your job_id\n",
    "manual_job_id = \"YOUR_JOB_ID_HERE\"\n",
    "\n",
    "if manual_job_id != \"YOUR_JOB_ID_HERE\":\n",
    "    check_job_status(manual_job_id)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Replace 'YOUR_JOB_ID_HERE' with an actual job_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## 7. Rejection Examples (Size/Count Limit Violations)\n\nThese examples demonstrate the pre-flight validation rejecting invalid requests.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 1: Single raster too large (>800 MB)\n# antigua.tif is 11.16 GB - should be rejected with message to use process_large_raster_v2\n\nprint(\"=\" * 60)\nprint(\"TEST 1: Single raster exceeding 800 MB limit\")\nprint(\"=\" * 60)\n\nlarge_single_request = {\n    \"blob_name\": \"antigua.tif\",  # 11.16 GB\n    \"container_name\": \"rmhazuregeobronze\"\n}\n\nresult = api_call(\"POST\", \"/api/jobs/submit/process_raster_v2\", large_single_request)\nif result and \"error\" in result:\n    print(f\"\\n‚úÖ Correctly rejected: {result.get('message', '')[:100]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Example 2: Collection with too many files (>20)\n# Should be rejected before any blob checks are made\n\nprint(\"=\" * 60)\nprint(\"TEST 2: Collection exceeding 20 file limit\")\nprint(\"=\" * 60)\n\ntoo_many_files_request = {\n    \"container_name\": \"rmhazuregeobronze\",\n    \"blob_list\": [f\"file{i}.tif\" for i in range(21)],  # 21 files\n    \"collection_id\": \"test-too-many\"\n}\n\nresult = api_call(\"POST\", \"/api/jobs/submit/process_raster_collection_v2\", too_many_files_request)\nif result and \"error\" in result:\n    print(f\"\\n‚úÖ Correctly rejected: {result.get('message', '')[:100]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Example 3: Collection with missing blob\n# Should be rejected with list of missing files\n\nprint(\"=\" * 60)\nprint(\"TEST 3: Collection with non-existent file\")\nprint(\"=\" * 60)\n\nmissing_blob_request = {\n    \"container_name\": \"rmhazuregeobronze\",\n    \"blob_list\": [\n        \"namangan/namangan14aug2019_R1C1cog.tif\",  # exists\n        \"nonexistent_file_xyz123.tif\"               # does not exist\n    ],\n    \"collection_id\": \"test-missing\"\n}\n\nresult = api_call(\"POST\", \"/api/jobs/submit/process_raster_collection_v2\", missing_blob_request)\nif result and \"error\" in result:\n    print(f\"\\n‚úÖ Correctly rejected: {result.get('message', '')[:100]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}