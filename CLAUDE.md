# ğŸ“ Documentation Has Been Restructured

**Date**: 16 OCT 2025
**Author**: Robert and Geospatial Claude Legion

## ğŸ¯ Claude - Start Here!

All Claude-optimized documentation has been moved to the **`/docs_claude/`** folder for better organization.

### Primary Entry Point:
```
ğŸ“‚ /docs_claude/CLAUDE_CONTEXT.md
```

This is your main starting point - it contains everything you need to understand the system quickly.

### Documentation Structure:
```
docs_claude/
â”œâ”€â”€ CLAUDE_CONTEXT.md                      # ğŸ¯ START HERE - Primary context
â”œâ”€â”€ TODO.md                                # âš¡ PRIMARY TASK LIST - Only active TODO file
â”œâ”€â”€ COREMACHINE_PLATFORM_ARCHITECTURE.md   # ğŸ—ï¸ NEW - Two-layer architecture (26 OCT 2025)
â”œâ”€â”€ ARCHITECTURE_REFERENCE.md              # Deep technical specifications
â”œâ”€â”€ FILE_CATALOG.md                        # Quick file lookup
â”œâ”€â”€ DEPLOYMENT_GUIDE.md                    # Deployment procedures
â””â”€â”€ HISTORY.md                             # Completed work log
```

### Quick Access Commands:
```bash
# View primary context
cat docs_claude/CLAUDE_CONTEXT.md

# Check active tasks (ONLY TODO file)
cat docs_claude/TODO.md

# See technical details
cat docs_claude/ARCHITECTURE_REFERENCE.md
```

## Important Notes:
- **USE MILITARY DATE FORMAT** (22 SEP 2025)
- **Author Attribution**: "Robert and Geospatial Claude Legion"
- **Update FILE_CATALOG.md** after any file changes

## ğŸ”€ Git Workflow - Dev Branch Strategy (9 OCT 2025)

**CRITICAL: Always work on `dev` branch, commit frequently with detailed messages**

### Branch Strategy:
- **`dev`** - Active development branch (commit frequently here)
- **`master`** - Stable milestones only (merge from dev when stable)

### Workflow Pattern:
```bash
# 1. Ensure you're on dev branch
git checkout dev

# 2. Make changes and commit frequently with descriptive messages
git add -A
git commit -m "descriptive message about what changed"

# 3. When stable, merge to master
git checkout master
git merge dev
git push origin master

# 4. Continue working on dev
git checkout dev
```

### Why This Pattern:
- **Frequent commits on dev** = Detailed git history of what broke and when
- **Clean master** = Only stable, tested code
- **Easy rollback** = Can always revert to last working commit on dev
- **Clear debugging** = Git log shows exactly what changed between working/broken states

### Commit Message Format:
```
Brief description of changes

ğŸ”§ Technical details (what was changed)
âœ… Status updates (what works now)
âš ï¸ Known issues (what's still broken)

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
```

**Lesson Learned**: Moving too fast on STAC + Raster ETL without commits = Lost track of what broke Azure Functions with no git history. Never again!

## ğŸš€ Folder Migration Status (22 SEP 2025) - CRITICAL SUCCESS!

### âœ… ACHIEVED: Azure Functions Now Support Folder Structure!

**What We Learned (CRITICAL FOR FUTURE MIGRATIONS):**
1. **`__init__.py` is REQUIRED** in each folder to make it a Python package
2. **`.funcignore` must NOT have `*/`** - this excludes ALL subdirectories!
3. **Both import styles work** with proper `__init__.py`:
   - `from utils.contract_validator import enforce_contract`
   - `from utils import enforce_contract` (if exported in `__init__.py`)

**Current Status:**
- âœ… **utils/** folder created with `__init__.py`
- âœ… **contract_validator.py** successfully moved to `utils/`
- âœ… All 5 files updated with new import paths
- âœ… `.funcignore` fixed - removed `*/` wildcard
- âœ… Deployment verified - health endpoint responding!

**Next Migration Candidates:**
- `schemas/` - All schema_*.py files (6 files)
- `controllers/` - All controller_*.py files (5 files)
- `repositories/` - All repository_*.py files (6 files)
- `services/` - All service_*.py files (4 files)
- `triggers/` - All trigger_*.py files (7 files)

## ğŸ“š Quick Navigation Index

### Priority Items
- **Current Priority** â†’ Line 38 (Error Handling Implementation)
- **TODO.md Reference** â†’ Line 118 (Current development tasks)
- **Recent Achievements** â†’ Line 346 (Completed work summary)

### Core Documentation
- **File Structure** â†’ Line 47 (Universal header template)
- **Development Philosophy** â†’ Line 93 (No Backward Compatibility)
- **Architecture Overview** â†’ Line 149 (Jobâ†’Stageâ†’Task abstraction)
- **Database Schema** â†’ Line 264 (PostgreSQL tables)
- **Project Structure** â†’ Line 283 (File organization)

### Technical Sections
- **Queue-Driven Orchestration** â†’ Line 166
- **Key Design Features** â†’ Line 173
- **Factory & Registry Pattern** â†’ Line 226
- **Pydantic Models** â†’ Line 239
- **Auto-Discovery System** â†’ Line 188

### Configuration & Deployment
- **Key URLs** â†’ Line 120 (Function App, Database)
- **Deployment Info** â†’ Line 126 (Active apps, commands)
- **Storage Environment** â†’ Line 131 (Azure storage keys)
- **Database Monitoring Endpoints** â†’ Line 362

### Implementation Details
- **Workflow Architecture Rationale** â†’ Line 440
- **Job Idempotency** â†’ Line 457
- **Future Implementation** â†’ Line 463
- **PostGIS Details** â†’ Line 476

**Stage Advancement Logic**: Partially implemented, needs completion for end-to-end job workflow

## ğŸš¨ Contract Violations vs Business Errors

**CRITICAL DISTINCTION FOR ERROR HANDLING (26 SEP 2025)**

### Contract Violations (Programming Bugs)
**Type**: `ContractViolationError` (inherits from `TypeError`)
**When**: Wrong types passed, missing required fields, interface violations
**Handling**: NEVER catch these - let them bubble up to crash the function
**Purpose**: Find bugs during development, not runtime failures

**Examples**:
```python
# Contract violation - wrong type passed
if not isinstance(job_id, str):
    raise ContractViolationError(
        f"job_id must be str, got {type(job_id).__name__}"
    )

# Contract violation - wrong return type from method
if not isinstance(result, (dict, TaskResult)):
    raise ContractViolationError(
        f"Handler returned {type(result).__name__} instead of TaskResult"
    )
```

### Business Logic Errors (Expected Runtime Failures)
**Type**: `BusinessLogicError` and subclasses
**When**: Normal failures during operation (network issues, missing resources)
**Handling**: Catch and handle gracefully
**Purpose**: Keep system running despite expected issues

**Subclasses**:
- `ServiceBusError` - Service Bus communication failures
- `DatabaseError` - Database operation failures
- `TaskExecutionError` - Task failed during execution
- `ResourceNotFoundError` - Resource doesn't exist
- `ValidationError` - Business validation failed

**Examples**:
```python
# Business error - Service Bus unavailable
except ServiceBusError as e:
    logger.warning(f"Service Bus temporarily unavailable: {e}")
    return {"success": False, "retry": True}

# Business error - File not found in blob storage
except ResourceNotFoundError as e:
    logger.info(f"Expected resource not found: {e}")
    return {"success": False, "error": str(e)}
```

### Implementation Pattern
```python
try:
    # Validate contracts first
    if not isinstance(param, expected_type):
        raise ContractViolationError("...")

    # Execute business logic
    result = do_work(param)

except ContractViolationError:
    # Let contract violations bubble up (bugs)
    raise

except BusinessLogicError as e:
    # Handle expected business failures gracefully
    logger.warning(f"Business failure: {e}")
    return handle_business_failure(e)

except Exception as e:
    # Log unexpected errors with full details
    logger.error(f"Unexpected: {e}\n{traceback.format_exc()}")
    return handle_unexpected_error(e)
```

**FILE STRUCTURE**
All .py files use Google style documentation but at the top before that, please maintain Claude Context Config in the format below
**PLEASE UPDATE PROJECT_FILE_INDEX.md AS NEEDED**
## ğŸ“ Universal Header Template

```python
# ============================================================================
# CLAUDE CONTEXT - [DESCRIPTIVE_TITLE]
# ============================================================================
# EPOCH: 4 - ACTIVE âœ…
# STATUS: [Component type] - [Brief description]
# PURPOSE: [One sentence description of what this file does]
# LAST_REVIEWED: [DD MMM YYYY]
# EXPORTS: [Main classes, functions, or constants exposed to other modules]
# INTERFACES: [Abstract base classes or protocols this file implements]
# PYDANTIC_MODELS: [Data models defined or consumed by this file]
# DEPENDENCIES: [Key external libraries: GDAL, psycopg, azure-storage]
# SOURCE: [Where data comes from: env vars, database, blob storage, etc.]
# SCOPE: [Operational scope: global, service-specific, environment-specific]
# VALIDATION: [How inputs/config are validated: Pydantic, custom validators]
# PATTERNS: [Architecture patterns used: Repository, Factory, Singleton]
# ENTRY_POINTS: [How other code uses this: import statements, main functions]
# INDEX: [Major sections with line numbers for quick navigation]
# ============================================================================
```

**CRITICALY IMPORTANT - DO NOT UPDATE ANY .MD FILES WITH "PRODUCTION READY" UNLESS EXPLICILTY INSTRUCTED TO DO SO**

**CRITICAL DEPLOYMENT INFORMATION**
Please refer to claude_log_access.md for instructions on accessing function app application insights logs for testing and debugging



**Important md files**
- docs_claude/TODO.md - âš¡ PRIMARY AND ONLY active task list
- docs_claude/HISTORY.md - Completed work log
- docs_claude/CLAUDE_CONTEXT.md - Primary context
- docs_claude/FILE_CATALOG.md - Quick file lookup
- docs_claude/ARCHITECTURE_REFERENCE.md - Deep technical specs

**Key URLs**:
- Function App: https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net (**ONLY** active app)
- Database: rmhpgflex.postgres.database.azure.com (geo schema)
- Resource Group: `rmhazure_rg` (NOT rmhresourcegroup)

**ğŸš¨ CRITICAL DEPLOYMENT INFO:**
- **ACTIVE FUNCTION APP**: `rmhgeoapibeta` (ONLY this one!)
- **DEPRECATED APPS**: `rmhazurefn`, `rmhgeoapi`, `rmhgeoapifn` (NEVER use these)
- **DEPLOYMENT COMMAND**: `func azure functionapp publish rmhgeoapibeta --python --build remote`

**ğŸ“‹ POST-DEPLOYMENT TESTING:**
```bash
# 1. Health Check
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/health

# 2. ğŸ”„ REDEPLOY DATABASE SCHEMA (Required after deployment!)
curl -X POST https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/schema/redeploy?confirm=yes

# 3. Submit Test Job
curl -X POST https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/jobs/submit/hello_world \
  -H "Content-Type: application/json" \
  -d '{"message": "deployment test"}'

# 4. Check Job Status (use job_id from step 3)
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/jobs/status/{JOB_ID}
```

**ğŸ”„ SCHEMA MANAGEMENT ENDPOINTS:**
- **Redeploy (Recommended)**: `POST /api/db/schema/redeploy?confirm=yes` - Nuke and redeploy in one operation
- **Nuke Only**: `POST /api/db/schema/nuke?confirm=yes` - Just drop everything (use with caution)

**ğŸ” DATABASE DEBUGGING ENDPOINTS (No DBeaver Required!):**
```bash
# Get all jobs and tasks (comprehensive dump)
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/debug/all?limit=100

# Query specific job by ID
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/jobs/{JOB_ID}

# Query all jobs with filters
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/jobs?status=failed&limit=10

# Get all tasks for a specific job
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/tasks/{JOB_ID}

# Query tasks with filters
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/tasks?status=failed&limit=20

# Database statistics and health
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/stats

# Test PostgreSQL functions
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/functions/test

# Diagnose enum types
curl https://rmhgeoapibeta-dzd8gyasenbkaqax.eastus-01.azurewebsites.net/api/db/enums/diagnostic
```

**Query Parameters:**
- `limit`: Max number of results (default: 100)
- `status`: Filter by status (pending, processing, completed, failed)
- `hours`: Only show records from last N hours
- `job_type`: Filter by job type

**ğŸ” APPLICATION INSIGHTS LOG ACCESS (CRITICAL FOR DEBUGGING):**

**PREREQUISITE - Must be logged in to Azure:**
```bash
# Login via browser (required once per session)
az login

# Verify login
az account show --query "{subscription:name, user:user.name}" -o table
```

**RECOMMENDED PATTERN - Script File (Most Reliable):**
```bash
# Create query script
cat > /tmp/query_ai.sh << 'EOF'
#!/bin/bash
TOKEN=$(az account get-access-token --resource https://api.applicationinsights.io --query accessToken -o tsv)
curl -s -H "Authorization: Bearer $TOKEN" \
  "https://api.applicationinsights.io/v1/apps/829adb94-5f5c-46ae-9f00-18e731529222/query" \
  --data-urlencode "query=traces | where timestamp >= ago(15m) | order by timestamp desc | take 10" \
  -G
EOF

# Execute and format
chmod +x /tmp/query_ai.sh && /tmp/query_ai.sh | python3 -m json.tool
```

**Common KQL Queries (replace query= in script above):**
```kql
# Recent errors
traces | where timestamp >= ago(1h) | where severityLevel >= 3 | order by timestamp desc | take 20

# Retry-related logs
traces | where timestamp >= ago(15m) | where message contains "retry" or message contains "RETRY" | order by timestamp desc

# Task processing
traces | where timestamp >= ago(15m) | where message contains "Processing task" | order by timestamp desc

# Health endpoint
union requests, traces | where timestamp >= ago(30m) | where operation_Name contains "health" | take 20
```

**Key Identifiers:**
- **App ID**: `829adb94-5f5c-46ae-9f00-18e731529222`
- **Resource Group**: `rmhazure_rg`
- **Function App**: `rmhgeoapibeta`

**Important Notes:**
- **Must run `az login` first** (opens browser for auth)
- Bearer tokens expire after 1 hour - script regenerates automatically
- **Use script file pattern** - inline commands fail due to shell evaluation issues
- Standard `az monitor app-insights query` doesn't work (requires AAD auth)
- **Full guide**: `docs_claude/APPLICATION_INSIGHTS_QUERY_PATTERNS.md`
- **Auth details**: `docs_claude/claude_log_access.md`

**STORAGE ENVIRONMENT**
Use rmhazuregeo with the storage account key to access storage to check queues and containers
[REDACTED - See Azure Portal or Key Vault for actual key]

## ğŸš¨ Development Philosophy: No Backward Compatibility

**CRITICAL: This is a development environment focused on core architecture design and proof of concept.**

### Core Principle: Explicit Error Handling Over Fallbacks

When making core architecture changes, **NEVER implement fallback logic or attempt to accomodate legacy code**. Instead:

âœ… **DO**: Add explicit error handling with clear migration guidance  
âŒ **DON'T**: Create fallbacks that mask breaking changes  

### Examples

**âŒ WRONG - Fallback Pattern:**
```python
# BAD: Hides architectural changes
job_type = entity.get('job_type') or entity.get('job_type')
if not job_type:
    job_type = 'default_value'  # Masks the problem
```

**âœ… CORRECT - Explicit Error Pattern:**
```python
# GOOD: Forces proper migration
job_type = entity.get('job_type')
if not job_type:
    job_type = entity.get('job_type')
    if job_type:
        logger.error(f"Found deprecated job_type: {job_type}")
        raise ValueError(f"job_type required (found job_type: {job_type})")
    else:
        raise ValueError("job_type is required field")
```

### Rationale

**Why no backward compatibility?**
1. **Development Environment**: No production users to maintain compatibility for
2. **Core Design Focus**: Architecture changes need to be clean and intentional because we are designing first principles for a much larger system
3. **Clear Migration Path**: Errors force proper updates rather than hidden technical debt
4. **Fast Iteration**: No legacy code slowing down development
5. **Quality Enforcement**: Explicit errors catch integration issues immediately


### Implementation Guidelines

**When changing core architecture:**
1. **Remove deprecated patterns completely**
2. **Add explicit validation with clear error messages**
3. **Update all calling code to use new pattern**
4. **Add tests that verify deprecated patterns fail**
5. **Document migration requirements clearly**

**Error messages should:**
- Clearly state what's wrong
- Explain the new required pattern
- Provide specific field/parameter guidance
- Include the deprecated value found (for debugging)

### Recent Examples

**Controller Pattern Migration (7 September 2025):**
- âŒ Removed: Direct instantiation `controller = HelloWorldController()`
- âœ… Added: Factory pattern `controller = JobFactory.create_controller("hello_world")`
- âœ… Added: Decorator registration `@JobRegistry.instance().register()`
- âœ… Added: Clear error for unregistered job types

**Result**: Clean factory pattern with no direct controller instantiation allowed.

This approach ensures rapid development, clean code, and forces proper architectural compliance.



## ğŸ—ï¸ Architecture

### **Job â†’ Stage â†’ Task Abstraction**
```
JOB (Controller Layer - Orchestration)
 â”œâ”€â”€ STAGE 1 (Controller Layer - Sequential)
 â”‚   â”œâ”€â”€ Task A (Service + Repository Layer - Parallel)
 â”‚   â”œâ”€â”€ Task B (Service + Repository Layer - Parallel) 
 â”‚   â””â”€â”€ Task C (Service + Repository Layer - Parallel)
 â”‚                     â†“ Last task completes stage
 â”œâ”€â”€ STAGE 2 (Controller Layer - Sequential)
 â”‚   â”œâ”€â”€ Task D (Service + Repository Layer - Parallel)
 â”‚   â””â”€â”€ Task E (Service + Repository Layer - Parallel)
 â”‚                     â†“ Last task completes stage
 â””â”€â”€ COMPLETION (job_type specific aggregation)
```

### **Queue-Driven Orchestration**
```
HTTP Request â†’ Jobs Queue â†’ Job Controller â†’ Tasks Queue â†’ Task Processors
                   â†“              â†“               â†“             â†“
               Job Record    Stage Creation   Task Records   Service Layer
```

### **Key Design Features**

#### **Sequential Stages with Parallel Tasks**
- **Stages execute sequentially**: Stage 1 â†’ Stage 2 â†’ ... â†’ Completion
- **Tasks execute in parallel**: All tasks in a stage run concurrently
- **Results flow forward**: Previous stage results passed to next stage

#### **"Last Task Turns Out the Lights"**
- **Atomic detection**: SQL operations prevent race conditions
- **Stage completion**: Last task in stage triggers transition
- **Job completion**: Last task in final stage triggers job completion

#### **Idempotent Operations**
- **Job IDs**: SHA256 hash of parameters for natural deduplication
- **Duplicate submissions**: Return existing job without creating new one
- **Parameter consistency**: Same inputs always produce same job ID

#### **Auto-Discovery Import Validation System** ğŸ”
- **Automatic Module Detection**: Scans filesystem for new Python files using naming patterns
- **Zero-Configuration Monitoring**: New classes automatically included in health validation
- **Two-Tier Validation**: Critical external dependencies + auto-discovered application modules
- **Continuous Health Reporting**: `/api/health` endpoint provides real-time import status

**Auto-Discovery Patterns:**
```
controller_*.py â†’ "* workflow controller"
service_*.py    â†’ "* service implementation"  
model_*.py      â†’ "* Pydantic model definitions"
repository_*.py â†’ "* repository layer"
trigger_*.py    â†’ "* HTTP trigger class"
util_*.py       â†’ "* utility module"
validator_*.py  â†’ "* validation utilities"
```

**Import Validation Registry Structure:**
```json
{
  "critical_modules": {
    "azure.functions": { "status": "success", "last_validated": "..." },
    "pydantic": { "status": "success", "last_validated": "..." }
  },
  "application_modules": {
    "controller_hello_world": { "auto_discovered": true, "status": "success" },
    "service_geospatial": { "auto_discovered": true, "status": "success" }
  }
}
```

**Benefits for Development:**
- **Early Import Detection**: Catches missing dependencies before runtime failures
- **Deployment Verification**: Confirms all modules load correctly in Azure Functions
- **Health Monitoring**: Real-time status via health endpoint  
- **Zero Maintenance**: Automatically includes new files following naming conventions

### **Core Classes & Patterns**

#### **Factory & Registry Pattern (NEW 7 September 2025)**
- **JobFactory**: Creates controllers via `JobFactory.create_controller(job_type)`
- **JobRegistry**: Singleton registry for decorator-based controller registration
- **TaskFactory**: Creates bulk tasks (100-1000) with semantic IDs like "tile_x5_y10"

#### **Abstract Base Classes**
- **BaseController**: Job orchestration with abstract methods:
  - `validate_job_parameters()`: Validate job parameters
  - `create_stage_tasks()`: Create tasks for a stage
  - `aggregate_stage_results()`: Aggregate task results
  - `should_advance_stage()`: Determine stage advancement

#### **Pydantic Models**
- **WorkflowDefinition**: Defines job stages and dependencies
- **StageDefinition**: Stage configuration (task type, parallelism, timeouts)
- **JobRecord/TaskRecord**: Database models with JSONB fields
- **TaskResult**: Task execution results with success/failure status

### **Database Schema (PostgreSQL)**
**ğŸš¨ ARCHITECTURAL DECISION: PostgreSQL Replaces Azure Storage Tables**

**Rationale:**
- **Race Condition Prevention**: ACID transactions prevent "last task turns out lights" race conditions
- **Strict Schema Enforcement**: PostgreSQL enforces data types, constraints, and relationships
- **Complex Queries**: Support for joins, aggregations, and advanced querying
- **Atomic Operations**: Critical for workflow state transitions

```sql
-- PostgreSQL Tables (app schema)
jobs: id, job_type, status, stage, parameters, metadata, result_data, created_at, updated_at

-- Tasks table  
tasks: id, job_id, task_type, status, stage, parameters, heartbeat, retry_count, metadata, result_data, created_at, updated_at
```

**âš ï¸ DEPRECATED: Azure Storage Tables**
- Storage Tables were replaced due to race condition vulnerabilities
- Health endpoint shows table errors (expected - tables no longer used)

## ğŸ“ Current Project Structure (Updated 7 September 2025)
```
rmhgeoapi/ (32 files total)
â”œâ”€â”€ function_app.py          # Azure Functions entry point
â”œâ”€â”€ config.py                # Strongly typed configuration with Pydantic v2 â­ NEW
â”œâ”€â”€ host.json                # Azure Functions runtime configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚
â”œâ”€â”€ Jobâ†’Task Architecture (Pydantic Strong Typing):
â”‚   â”œâ”€â”€ controller_base.py         # âœ… Abstract base with workflow validation
â”‚   â”œâ”€â”€ controller_hello_world.py  # âœ… HelloWorld 2-stage implementation  
â”‚   â”œâ”€â”€ model_core.py              # âœ… Core Pydantic models for Jobâ†’Task
â”‚   â”œâ”€â”€ model_job_base.py          # âœ… Job parameter models
â”‚   â”œâ”€â”€ model_stage_base.py        # âœ… Stage workflow models  
â”‚   â”œâ”€â”€ model_task_base.py         # âœ… Task execution models
â”‚   â”œâ”€â”€ schema_core.py             # âœ… Schema validation utilities
â”‚   â”œâ”€â”€ schema_workflow.py         # âœ… Workflow definition schemas
â”‚   â”œâ”€â”€ service_hello_world.py     # âœ… HelloWorld business logic
â”‚   â””â”€â”€ validator_schema.py        # âœ… Custom validators
â”‚
â”œâ”€â”€ Storage & Repository Layer:
â”‚   â”œâ”€â”€ adapter_storage.py   # âœ… Azure Storage abstraction
â”‚   â””â”€â”€ repository_data.py   # âœ… Data repository patterns with completion detection
â”‚
â”œâ”€â”€ Utilities:
â”‚   â”œâ”€â”€ util_completion.py   # Job completion orchestration
â”‚   â””â”€â”€ util_logger.py       # Centralized logging
â”‚
â”œâ”€â”€ Configuration:
â”‚   â”œâ”€â”€ local.settings.json  # Local development configuration
â”‚   â”œâ”€â”€ local.settings.example.json # Configuration template
â”‚   â””â”€â”€ INFRA_CONFIG.md      # Azure infrastructure documentation
â”‚
â””â”€â”€ Documentation (8 files):
    â”œâ”€â”€ CLAUDE.md            # ğŸš¨ PRIMARY: Project context & status
    â”œâ”€â”€ CONFIGURATION_USAGE.md # Config system usage guide â­ NEW  
    â”œâ”€â”€ PROJECT_FILE_INDEX.md # Complete file catalog â­ NEW
    â”œâ”€â”€ FILE_NAMING_CONVENTION.md # Naming standards
    â”œâ”€â”€ HELLO_WORLD_IMPLEMENTATION_PLAN.md # Controller demo (not working)
    â”œâ”€â”€ STRONG_TYPING_ARCHITECTURE_STATUS.md # Typing status
    â”œâ”€â”€ consolidated_redesign.md # Architecture evolution
    â””â”€â”€ redesign.md          # Historical design docs
```

## ğŸ”‘ Core Concepts

### Endpoint Usage (CRITICAL)
- **Primary Endpoint**: `/api/jobs/{job_type}` 


### Data Tiers
- **Bronze**: Raw data deposited by users (or Robert)(`rmhazuregeobronze`)
- **Silver**: COGs + PostGIS
- **Gold**: GeoParquet exports (future)


## ğŸš€ Current Status (Updated 7 September 2025)

### **Recent Achievements (See HISTORY.md for details)**
- âœ… Repository Architecture Cleanup: Clear naming, no duplicates (7 Sept)
- âœ… Controller Factory Pattern: Decorator-based registration (7 Sept)  
- âœ… BaseController Consolidation: Single source of truth (7 Sept)
- âœ… psycopg.sql Composition: SQL injection prevention (5 Sept)
- âœ… Database Monitoring System: Nuclear Red Button (3 Sept)
- âœ… Poison Queue Root Cause: 4 critical issues fixed (3 Sept)

### **Operational Status**

**Systems Working:**
- HTTP job submission â†’ Queue message creation â†’ Queue processing â†’ Database retrieval
- PostgreSQL schema validation and function deployment
- Enhanced logging with correlation tracking
- Database query endpoints (`/api/db/*`)
- Nuclear Red Button schema reset system

**Database Monitoring Endpoints:**
- `/api/db/jobs` - Query jobs with filtering
- `/api/db/tasks/{job_id}` - Query tasks for specific job  
- `/api/db/stats` - Database statistics and metrics
- `/api/db/enums/diagnostic` - Schema diagnostic tools
- `/api/db/functions/test` - Function testing and verification
- `/api/db/schema/nuke?confirm=yes` - Nuclear schema reset (DEV ONLY)

## ğŸ’¡ Key Technical Decisions

### **Complex Workflow Architecture Rationale**
The sophisticated Jobâ†’Stageâ†’Task system accommodates real-world geospatial workflows like "stage raster":

**Example Real Workflow - "stage_raster":**
1. **Stage 1**: Ensure metadata exists, extract if missing
2. **Stage 2**: If raster is gigantic, create tiling scheme  
3. **Stage 3**: **Fan-out** - Parallel tasks to reproject/validate raster chunks
4. **Stage 4**: **Fan-out** - Parallel tasks to convert chunks to COGs
5. **Stage 5**: Job completion updates STAC record with tiled COGs as single dataset

**Architecture Features Supporting This:**
- **Sequential Stages**: Each stage waits for previous to complete
- **Fan-out/Fan-in**: Stages can create N parallel tasks, wait for all to complete
- **Inter-stage Data Flow**: Results from previous stages feed into next stages
- **"Last Task Turns Out Lights"**: Atomic completion detection prevents race conditions

### Job Idempotency & Deduplication
- **SHA256(job_type + params)** = deterministic job ID
- **Natural deduplication**: Same inputs always produce same job ID
- **Duplicate submissions**: Return existing job without creating new work


## ğŸš¨ FUTURE Implementation Details for storage container content analysis

### Blob Inventory (solves 64KB limit)
- Gzipped inventories in `rmhazuregeoinventory` (93.5% compression)
- Three files: full, geo-only, summary

### Poison Queue Monitoring
- Timer: Every 5 min | Endpoint: `/api/monitor/poison`
- Auto-marks jobs as failed after 5 dequeues

### Large Path Handling
- Maxar paths >255 chars â†’ MD5 hash IDs

## Future Database details

### PostGIS: v3.4, `geo` schema, geometry types
- We need the geometry field name to be a global config variable so when this application is deployed it can be set to "shape" if we are acomodating ArcGIS Enterprise Geodatabases

