# SAFe Epic & Feature Registry

**Last Updated**: 19 DEC 2025
**Framework**: SAFe (Scaled Agile Framework)
**Purpose**: Master reference for Azure DevOps Boards import
**Source of Truth**: This file defines Epic/Feature numbers; TODO.md should align

---

## Quick Reference

**FY26 Target (ends 30 JUN 2026)**: E1 âœ…, E2, E9, E7, E6

| Priority | Epic | Name | Status | Features | WSJF |
|:--------:|------|------|--------|:--------:|:----:|
| â€” | E1 | Vector Data as API | âœ… Complete | 4 | â€” |
| 1 | E2 | Raster Data as API | ğŸš§ Partial | 7 | TBD |
| 2 | E9 | DDH Platform Integration | ğŸ“‹ Planned | 4 | TBD |
| 3 | E7 | Data Externalization | ğŸ“‹ Planned | 3 | TBD |
| 4 | E6 | Platform Observability | ğŸš§ Mostly Complete | 3 | TBD |
| 5 | E3 | Zarr/Climate Data as API | ğŸš§ Partial | 3 | TBD |
| 6 | E4 | Managed Datasets | ğŸš§ Partial | 2 | TBD |
| 7 | E5 | Vector Styling | ğŸš§ Partial | 2 | TBD |
| 8 | E8 | H3 Analytics Pipeline | ğŸš§ Partial | 6 | TBD |

**Priority Notes**:
- **E9 + E6 tightly coupled**: Observability enables Integration monitoring
- **E9 requires elaboration**: ITSDA team (ITS Platform / DDH owner) has original requirements but no geospatial knowledge
- **E3, E4, E5, E8**: Nice-to-have for FY26 â€” E3 (Zarr/Climate) is top priority among these

| Enabler | Name | Status | Enables |
|---------|------|--------|---------|
| EN1 | Job Orchestration Engine | âœ… Complete | E1, E2, E3 |
| EN2 | Database Architecture | âœ… Complete | All |
| EN3 | Azure Platform Integration | âœ… Complete | All |
| EN4 | Configuration System | âœ… Complete | All |
| EN5 | Pre-flight Validation | âœ… Complete | E1, E2 |
| EN6 | Long-Running Task Infrastructure | ğŸ“‹ Planned | E2, E3 |

---

# COMPLETED EPICS

## Epic E1: Vector Data as API âœ…

**Business Requirement**: "Make vector data available as API"
**Status**: âœ… COMPLETE
**Completed**: NOV 2025

### Feature F1.1: Vector ETL Pipeline âœ…

**Deliverable**: `process_vector` job with idempotent DELETE+INSERT pattern

| Story | Description |
|-------|-------------|
| S1.1.1 | Design etl_batch_id idempotency pattern |
| S1.1.2 | Create PostGIS handler with DELETE+INSERT |
| S1.1.3 | Implement chunked upload (500-row chunks) |
| S1.1.4 | Add spatial + batch index creation |
| S1.1.5 | Create process_vector job with JobBaseMixin |

**Key Files**: `jobs/process_vector.py`, `services/vector/process_vector_tasks.py`, `services/vector/postgis_handler.py`

---

### Feature F1.2: OGC Features API âœ…

**Deliverable**: `/api/features/collections/{id}/items` with bbox queries

| Story | Description |
|-------|-------------|
| S1.2.1 | Create /api/features landing page |
| S1.2.2 | Implement /api/features/collections list |
| S1.2.3 | Add bbox query support |
| S1.2.4 | Create interactive map web interface |

**Key Files**: `web_interfaces/features/`, `triggers/ogc_features.py`

---

### Feature F1.3: Vector STAC Integration âœ…

**Deliverable**: Items registered in pgSTAC `system-vectors` collection

| Story | Description |
|-------|-------------|
| S1.3.1 | Create system-vectors collection |
| S1.3.2 | Generate STAC items for vector datasets |
| S1.3.3 | Add vector-specific STAC properties |

**Key Files**: `infrastructure/pgstac_bootstrap.py`, `services/stac_metadata.py`

---

### Feature F1.4: Vector Unpublish âœ…

**Deliverable**: `unpublish_vector` job for data removal

| Story | Description |
|-------|-------------|
| S1.4.1 | Create unpublish data models |
| S1.4.2 | Implement unpublish handlers |
| S1.4.3 | Add STAC item/collection validators |
| S1.4.4 | Create unpublish_vector job |

**Key Files**: `jobs/unpublish_vector.py`, `services/unpublish_handlers.py`, `core/models/unpublish.py`

**Note**: Code complete, needs deploy + test with `dry_run=true`

---

## Epic E2: Raster Data as API ğŸš§

**Business Requirement**: "Make GeoTIFF available as API"
**Status**: ğŸš§ PARTIAL (collection/mosaic workflow pending)
**Core Complete**: NOV 2025

### Feature F2.1: Raster ETL Pipeline âœ…

**Deliverable**: `process_raster_v2` with 3-tier compression

| Story | Description |
|-------|-------------|
| S2.1.1 | Create COG conversion service |
| S2.1.2 | Implement 3-tier compression (analysis/visualization/archive) |
| S2.1.3 | Fix JPEG INTERLEAVE for YCbCr encoding |
| S2.1.4 | Add DEM auto-detection with colormap URLs |
| S2.1.5 | Implement blob size pre-flight validation |
| S2.1.6 | Create process_raster_v2 with JobBaseMixin (73% code reduction) |

**Key Files**: `jobs/process_raster_v2.py`, `services/raster_cog.py`

---

### Feature F2.2: TiTiler Integration âœ…

**Deliverable**: Tile serving, previews, viewer URLs via rmhtitiler

| Story | Description |
|-------|-------------|
| S2.2.1 | Configure TiTiler for COG access |
| S2.2.2 | Generate viewer URLs in job results |
| S2.2.3 | Add preview image endpoints |
| S2.2.4 | Implement tile URL generation |

**Key Files**: `services/titiler_client.py`

---

### Feature F2.3: Raster STAC Integration âœ…

**Deliverable**: Items registered in pgSTAC with COG assets

| Story | Description |
|-------|-------------|
| S2.3.1 | Create system-rasters collection |
| S2.3.2 | Generate STAC items with COG assets |
| S2.3.3 | Add raster-specific STAC properties |
| S2.3.4 | Integrate DDH metadata passthrough |

**Key Files**: `infrastructure/pgstac_bootstrap.py`, `services/stac_metadata.py`

---

### Feature F2.4: Raster Unpublish âœ…

**Deliverable**: `unpublish_raster` job for data removal

| Story | Description |
|-------|-------------|
| S2.4.1 | Implement raster unpublish handlers |
| S2.4.2 | Create unpublish_raster job |

**Key Files**: `jobs/unpublish_raster.py`, `services/unpublish_handlers.py`

**Note**: Code complete, needs deploy + test with `dry_run=true`

---

### Feature F2.5: Raster Data Extract API âœ…

**Deliverable**: Pixel-level data access endpoints (distinct from tile service)

**Access Pattern Distinction**:
| F2.2: Tile Service | F2.5: Data Extract API |
|--------------------|------------------------|
| XYZ tiles for map rendering | Pixel values for analysis |
| `/tiles/{z}/{x}/{y}` | `/api/raster/point`, `/extract`, `/clip` |
| Visual consumption | Data consumption |
| Pre-rendered, cached | On-demand, precise |

| Story | Description |
|-------|-------------|
| S2.5.1 | Create TiTiler client service |
| S2.5.2 | Create STAC client service with TTL cache |
| S2.5.3 | Implement /api/raster/extract endpoint (bbox â†’ image) |
| S2.5.4 | Implement /api/raster/point endpoint (lon/lat â†’ value) |
| S2.5.5 | Implement /api/raster/clip endpoint (geometry â†’ masked image) |
| S2.5.6 | Implement /api/raster/preview endpoint (quick thumbnail) |
| S2.5.7 | Add error handling + validation |

**Key Files**: `raster_api/`, `services/titiler_client.py`, `services/stac_client.py`

---

### Feature F2.6: Large Raster Support âœ…

**Deliverable**: `process_large_raster_v2` for oversized files

| Story | Description |
|-------|-------------|
| S2.6.1 | Create large raster processing job |
| S2.6.2 | Implement chunked processing strategy |

**Key Files**: `jobs/process_large_raster_v2.py`

**Note**: For files exceeding chunked processing limits, requires EN6 (Long-Running Task Infrastructure)

---

### Feature F2.7: Raster Collection Processing ğŸ“‹ PLANNED

**Deliverable**: `process_raster_collection` job creating pgstac searches (unchanging mosaic URLs)

**Distinction from F2.1**:
| Aspect | F2.1: Individual TIF | F2.7: TIF Collection |
|--------|---------------------|----------------------|
| Input | Single blob | Manifest or folder |
| ETL output | Single COG + STAC item | Multiple COGs + pgstac search |
| API artifact | Item URL | **Search URL** (unchanging mosaic) |
| Use case | One-off analysis layer | Basemap/tile service |

| Story | Status | Description |
|-------|--------|-------------|
| S2.7.1 | ğŸ“‹ | Design collection manifest schema |
| S2.7.2 | ğŸ“‹ | Create multi-file orchestration job |
| S2.7.3 | ğŸ“‹ | Implement pgstac search registration |
| S2.7.4 | ğŸ“‹ | Generate stable mosaic URL in job results |
| S2.7.5 | ğŸ“‹ | Add collection-level STAC metadata |

**Key Files**: `jobs/process_raster_collection.py` (planned)

---

# ACTIVE EPICS

## Epic E3: Zarr/Climate Data as API ğŸš§

**Business Requirement**: "Now do Zarr" + time-series access
**Status**: ğŸš§ PARTIAL

### Feature F3.1: xarray Service Layer âœ…

**Deliverable**: Time-series and statistics endpoints

| Story | Description |
|-------|-------------|
| S3.1.1 | Create xarray reader service |
| S3.1.2 | Implement /api/xarray/point time-series |
| S3.1.3 | Implement /api/xarray/statistics |
| S3.1.4 | Implement /api/xarray/aggregate |

**Key Files**: `xarray_api/`, `services/xarray_reader.py`

---

### Feature F3.2: Virtual Zarr Pipeline ğŸ“‹ PLANNED

**Deliverable**: Kerchunk references for NetCDF (eliminate physical conversion)

| Story | Status | Description |
|-------|--------|-------------|
| S3.2.1 | â¬œ | CMIP6 filename parser |
| S3.2.2 | â¬œ | Chunking validator (pre-flight) |
| S3.2.3 | â¬œ | Reference generator (single file â†’ Kerchunk JSON) |
| S3.2.4 | â¬œ | Virtual combiner (time series references) |
| S3.2.5 | â¬œ | STAC datacube registration |
| S3.2.6 | â¬œ | Inventory job |
| S3.2.7 | â¬œ | Generate job (full pipeline) |
| S3.2.8 | â¬œ | TiTiler-xarray config |

**Dependencies**: `virtualizarr`, `kerchunk`, `h5netcdf`, `h5py`

---

### Feature F3.3: Reader App Migration â¬œ READY

**Deliverable**: Move read APIs to rmhogcstac (clean separation)

| Story | Status | Description |
|-------|--------|-------------|
| S3.3.1 | â¬œ | Copy raster_api module |
| S3.3.2 | â¬œ | Copy xarray_api module |
| S3.3.3 | â¬œ | Copy service clients |
| S3.3.4 | â¬œ | Update requirements.txt |
| S3.3.5 | â¬œ | Register routes |
| S3.3.6 | â¬œ | Deploy and validate |

---

## Epic E4: Managed Datasets ğŸš§

**Business Requirement**: Auto-updating external data sources
**Status**: ğŸš§ PARTIAL

### Feature F4.1: Managed Infrastructure âœ…

**Deliverable**: Registry, scheduler, update job framework

| Story | Description |
|-------|-------------|
| S4.1.1 | Create data models |
| S4.1.2 | Design database schema |
| S4.1.3 | Create repository layer |
| S4.1.4 | Create registry service |
| S4.1.5 | Implement HTTP CRUD endpoints |
| S4.1.6 | Create timer scheduler (2 AM UTC) |
| S4.1.7 | Create 4-stage update job |
| S4.1.8 | Implement WDPA handler |

**Key Files**: `core/models/curated.py`, `infrastructure/curated_repository.py`, `services/curated/`, `jobs/curated_update.py`

---

### Feature F4.2: Dataset Handlers â¬œ READY

**Deliverable**: Additional external source handlers

| Story | Status | Description |
|-------|--------|-------------|
| S4.2.1 | â¬œ | Manual update trigger endpoint |
| S4.2.2 | â¬œ | FATHOM handler (flood data) |
| S4.2.3 | ğŸ“‹ | Admin0 handler (Natural Earth) |
| S4.2.4 | ğŸ“‹ | Style integration (depends on E5) |

---

## Epic E5: Vector Styling ğŸš§

**Business Requirement**: Server-side map rendering styles
**Status**: ğŸš§ PARTIAL

### Feature F5.1: OGC API Styles âœ…

**Deliverable**: CartoSym-JSON storage with multi-format output

| Story | Description |
|-------|-------------|
| S5.1.1 | Create Pydantic models |
| S5.1.2 | Build style translator (CartoSym â†’ Leaflet/Mapbox) |
| S5.1.3 | Create repository layer |
| S5.1.4 | Implement service orchestration |
| S5.1.5 | Create GET /features/collections/{id}/styles |
| S5.1.6 | Create GET /features/collections/{id}/styles/{sid} |
| S5.1.7 | Add geo.feature_collection_styles table |

**Key Files**: `ogc_styles/`

**Tested**: 18 DEC 2025 - All three output formats verified (Leaflet, Mapbox GL, CartoSym-JSON)

---

### Feature F5.2: ETL Style Integration ğŸ“‹ PLANNED

**Deliverable**: Auto-create default styles on vector ingest

| Story | Status | Description |
|-------|--------|-------------|
| S5.2.1 | ğŸ“‹ | Design default style templates |
| S5.2.2 | ğŸ“‹ | Integrate into process_vector job |

---

## Epic E6: Platform Observability ğŸš§

**Business Requirement**: Remote diagnostics without DB access
**Status**: ğŸš§ MOSTLY COMPLETE

### Feature F6.1: Health & Diagnostics âœ…

**Deliverable**: Comprehensive health and status APIs

| Story | Description |
|-------|-------------|
| S6.1.1 | Enhanced /api/health endpoint |
| S6.1.2 | Platform status for DDH (/api/platform/*) |
| S6.1.3 | 29 dbadmin endpoints |

**Key Files**: `web_interfaces/health/`, `triggers/admin/db_*.py`

---

### Feature F6.2: Error Telemetry âœ…

**Deliverable**: Structured logging and retry tracking

| Story | Description |
|-------|-------------|
| S6.2.1 | Add error_source field to logs |
| S6.2.2 | Create 6 retry telemetry checkpoints |
| S6.2.3 | Implement log_nested_error() helper |
| S6.2.4 | Add JSON deserialization error handling |

**Key Files**: `core/error_handler.py`, `core/machine.py`

---

### Feature F6.3: Verbose Validation ğŸ”µ BACKLOG

**Deliverable**: Enhanced error context

| Story | Status | Description |
|-------|--------|-------------|
| S6.3.1 | ğŸ”µ | Verbose pre-flight validation |
| S6.3.2 | ğŸ”µ | Unified DEBUG_MODE |

---

# PLANNED EPICS

## Epic E7: Data Externalization ğŸ“‹

**Business Requirement**: Controlled data movement to external access zones
**Status**: ğŸ“‹ PLANNED

```
INTERNAL ZONE              EXTERNAL ZONE
(rmhazuregeo*)      â†’      (client-accessible)
        â†“
  Approval + ADF Copy
        â†“
  Cloudflare WAF/CDN
        â†“
   Public Access
```

### Feature F7.1: Publishing Workflow ğŸ“‹ PLANNED

**Owner**: Claude (code)
**Deliverable**: Approval queue, audit log, status APIs

| Story | Status | Acceptance Criteria |
|-------|--------|---------------------|
| S7.1.1 | â¬œ | Design publish schema (`app.publish_queue`, `app.publish_audit_log`) |
| S7.1.2 | â¬œ | Create publishing repository |
| S7.1.3 | â¬œ | Submit for review endpoint |
| S7.1.4 | â¬œ | Approve/Reject endpoints |
| S7.1.5 | â¬œ | Status check endpoint |
| S7.1.6 | â¬œ | Audit log queries |

---

### Feature F7.2: ADF Data Movement ğŸ“‹ PLANNED

**Owner**: Claude (code) + Robert (Azure config)
**Deliverable**: Blob copy pipelines with approval triggers

| Story | Status | Acceptance Criteria |
|-------|--------|---------------------|
| S7.2.1 | â¬œ | Create ADF instance |
| S7.2.2 | â¬œ | Design internalâ†’external pipeline |
| S7.2.3 | â¬œ | Create blob-to-blob copy activity |
| S7.2.4 | â¬œ | Integrate approve trigger |
| S7.2.5 | â¬œ | Add copy status to audit log |
| S7.2.6 | â¬œ | Add env variables |

---

### Feature F7.3: External Delivery Infrastructure ğŸ“‹ PLANNED

**Owner**: Robert (infrastructure)
**Deliverable**: Cloudflare WAF/CDN, external storage

| Story | Status | Acceptance Criteria |
|-------|--------|---------------------|
| S7.3.1 | â¬œ | Create external storage account |
| S7.3.2 | â¬œ | Configure Cloudflare WAF rules |
| S7.3.3 | â¬œ | Set up CDN for static assets |
| S7.3.4 | â¬œ | Configure custom domain |
| S7.3.5 | â¬œ | Validate end-to-end external access |

---

## Epic E8: H3 Analytics Pipeline ğŸš§

**Business Requirement**: Columnar aggregations of raster/vector data to H3 hexagonal grid
**Status**: ğŸš§ PARTIAL (Infrastructure complete, aggregation handlers in progress)

**Architecture**:
```
Source Data           H3 Aggregation          Output
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rasters     â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Zonal Stats   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ PostgreSQL OLTP â”‚
â”‚ (COGs)      â”‚       â”‚ (mean,sum,etc)â”‚       â”‚ (h3.zonal_stats)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Vectors     â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Point Counts  â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ GeoParquet OLAP â”‚
â”‚ (PostGIS)   â”‚       â”‚ (category agg)â”‚       â”‚ (DuckDB export) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Feature F8.1: H3 Grid Infrastructure âœ…

**Deliverable**: Normalized H3 schema with cell-country mappings

| Story | Status | Description |
|-------|--------|-------------|
| S8.1.1 | âœ… | Design normalized schema (cells, cell_admin0, cell_admin1) |
| S8.1.2 | âœ… | Create stat_registry metadata catalog |
| S8.1.3 | âœ… | Create zonal_stats table for raster aggregations |
| S8.1.4 | âœ… | Create point_stats table for vector aggregations |
| S8.1.5 | âœ… | Create batch_progress table for idempotency |
| S8.1.6 | âœ… | Implement H3Repository with COPY-based bulk inserts |

**Key Files**: `infrastructure/h3_schema.py`, `infrastructure/h3_repository.py`, `infrastructure/h3_batch_tracking.py`

---

### Feature F8.2: Grid Bootstrap System âœ…

**Deliverable**: 3-stage cascade job generating res 2-7 pyramid

| Story | Status | Description |
|-------|--------|-------------|
| S8.2.1 | âœ… | Create generate_h3_grid handler (base + cascade modes) |
| S8.2.2 | âœ… | Create cascade_h3_descendants handler (multi-level) |
| S8.2.3 | âœ… | Create finalize_h3_pyramid handler |
| S8.2.4 | âœ… | Create bootstrap_h3_land_grid_pyramid job |
| S8.2.5 | âœ… | Implement batch-level idempotency (resumable jobs) |
| S8.2.6 | âœ… | Add country/bbox filtering for testing |

**Key Files**: `jobs/bootstrap_h3_land_grid_pyramid.py`, `services/handler_generate_h3_grid.py`, `services/handler_cascade_h3_descendants.py`, `services/handler_finalize_h3_pyramid.py`

**Expected Cell Counts** (land-filtered):
- Res 2: ~2,000 | Res 3: ~14,000 | Res 4: ~98,000
- Res 5: ~686,000 | Res 6: ~4.8M | Res 7: ~33.6M

---

### Feature F8.3: Rasterâ†’H3 Aggregation ğŸš§ IN PROGRESS

**Deliverable**: Zonal statistics from COGs to H3 cells

| Story | Status | Description |
|-------|--------|-------------|
| S8.3.1 | âœ… | Create h3_raster_aggregation job definition |
| S8.3.2 | âœ… | Design 3-stage workflow (inventory â†’ compute â†’ finalize) |
| S8.3.3 | â¬œ | Implement h3_inventory_cells handler |
| S8.3.4 | â¬œ | Implement h3_raster_zonal_stats handler |
| S8.3.5 | â¬œ | Implement h3_aggregation_finalize handler |
| S8.3.6 | âœ… | Create insert_zonal_stats_batch() repository method |

**Key Files**: `jobs/h3_raster_aggregation.py`

**Stats Supported**: mean, sum, min, max, count, std, median

---

### Feature F8.4: Vectorâ†’H3 Aggregation â¬œ READY

**Deliverable**: Point/polygon counts aggregated to H3 cells

| Story | Status | Description |
|-------|--------|-------------|
| S8.4.1 | â¬œ | Create h3_vector_aggregation job |
| S8.4.2 | â¬œ | Implement point-in-polygon handler |
| S8.4.3 | â¬œ | Implement category grouping |
| S8.4.4 | âœ… | Create insert_point_stats_batch() repository method |

**Schema Ready**: `h3.point_stats` table exists

---

### Feature F8.5: GeoParquet Export ğŸ“‹ PLANNED

**Deliverable**: Columnar export for OLAP analytics

| Story | Status | Description |
|-------|--------|-------------|
| S8.5.1 | ğŸ“‹ | Design export job parameters |
| S8.5.2 | ğŸ“‹ | Implement PostgreSQL â†’ GeoParquet writer |
| S8.5.3 | ğŸ“‹ | Add DuckDB/Databricks compatibility |
| S8.5.4 | ğŸ“‹ | Create export_h3_stats job |

---

### Feature F8.6: Analytics API ğŸ“‹ PLANNED

**Deliverable**: Query endpoints for H3 statistics

| Story | Status | Description |
|-------|--------|-------------|
| S8.6.1 | ğŸ“‹ | GET /api/h3/stats/{dataset_id} |
| S8.6.2 | ğŸ“‹ | GET /api/h3/stats/{dataset_id}/cells?iso3=&bbox= |
| S8.6.3 | ğŸ“‹ | GET /api/h3/registry (list all datasets) |
| S8.6.4 | ğŸ“‹ | Interactive H3 map interface |

---

## Epic E9: DDH Platform Integration ğŸ“‹

**Business Requirement**: Enable DDH application to consume geospatial platform services
**Status**: ğŸ“‹ PLANNED
**Owner**: DDH Team (with Robert coordination)

**Integration Points**:
```
DDH Application                    Geospatial Platform
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚â”€â”€â”€â”€ Submit â”€â”€â–¶â”‚ /api/jobs/submit/*  â”‚
â”‚  Data Hub       â”‚               â”‚ (vector, raster)    â”‚
â”‚  Dashboard      â”‚â—€â”€â”€ Status â”€â”€â”€â”€â”‚ /api/jobs/status/*  â”‚
â”‚                 â”‚               â”‚ /api/platform/*     â”‚
â”‚                 â”‚â”€â”€â”€â”€ Query â”€â”€â”€â–¶â”‚ /api/features/*     â”‚
â”‚                 â”‚               â”‚ /api/raster/*       â”‚
â”‚                 â”‚               â”‚ /api/h3/*           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Feature F9.1: API Contract & Documentation ğŸ“‹ PLANNED

**Owner**: DDH Team + Robert
**Deliverable**: Formal API specification for cross-team development

| Story | Status | Description |
|-------|--------|-------------|
| S9.1.1 | ğŸ“‹ | Generate OpenAPI 3.0 spec from existing endpoints |
| S9.1.2 | ğŸ“‹ | Document job submission request/response formats |
| S9.1.3 | ğŸ“‹ | Document STAC item structure for vectors/rasters |
| S9.1.4 | ğŸ“‹ | Document error response contract |
| S9.1.5 | ğŸ“‹ | Publish API docs (Swagger UI or static) |

---

### Feature F9.2: Job Lifecycle Callbacks ğŸ“‹ PLANNED

**Owner**: DDH Team (consumer) + Claude (implementation)
**Deliverable**: Webhook notifications for job state changes

| Story | Status | Description |
|-------|--------|-------------|
| S9.2.1 | ğŸ“‹ | Design callback payload schema |
| S9.2.2 | ğŸ“‹ | Add callback_url parameter to job submission |
| S9.2.3 | ğŸ“‹ | Implement webhook POST on job completion |
| S9.2.4 | ğŸ“‹ | Implement webhook POST on job failure |
| S9.2.5 | ğŸ“‹ | Add retry logic for failed callbacks |

---

### Feature F9.3: Authentication & Authorization ğŸ“‹ PLANNED

**Owner**: DDH Team + Robert
**Deliverable**: Secure API access between systems

| Story | Status | Description |
|-------|--------|-------------|
| S9.3.1 | ğŸ“‹ | Define auth strategy (API key, OAuth, managed identity) |
| S9.3.2 | ğŸ“‹ | Implement auth middleware |
| S9.3.3 | ğŸ“‹ | Create DDH service account/identity |
| S9.3.4 | ğŸ“‹ | Document auth setup for DDH team |

---

### Feature F9.4: Integration Testing ğŸ“‹ PLANNED

**Owner**: DDH Team + Robert
**Deliverable**: End-to-end test suite validating integration

| Story | Status | Description |
|-------|--------|-------------|
| S9.4.1 | ğŸ“‹ | Create integration test environment |
| S9.4.2 | ğŸ“‹ | Write vector ETL round-trip test |
| S9.4.3 | ğŸ“‹ | Write raster ETL round-trip test |
| S9.4.4 | ğŸ“‹ | Write OGC Features query test |
| S9.4.5 | ğŸ“‹ | Set up CI pipeline for integration tests |

---

# COMPLETED ENABLERS

Technical foundation that enables all Epics above.

## Enabler EN1: Job Orchestration Engine âœ…

**What It Enables**: All ETL jobs (E1, E2, E3)

| Component | Description |
|-----------|-------------|
| CoreMachine | Jobâ†’Stageâ†’Task state machine |
| JobBaseMixin | 70%+ code reduction for new jobs |
| Retry Logic | Exponential backoff with telemetry |
| Stage Completion | "Last task turns out the lights" pattern |

**Key Files**: `core/machine.py`, `core/state_manager.py`, `jobs/base.py`, `jobs/mixins.py`

---

## Enabler EN2: Database Architecture âœ…

**What It Enables**: Data separation, safe schema management

| Component | Description |
|-----------|-------------|
| Dual Database | App DB (nukeable) vs Business DB (protected) |
| Schema Management | full-rebuild, redeploy, nuke endpoints |
| Managed Identity | Same identity, different permission grants |

**Key Files**: `config/database_config.py`, `triggers/admin/db_maintenance.py`

---

## Enabler EN3: Azure Platform Integration âœ…

**What It Enables**: Secure, scalable Azure deployment

| Component | Description |
|-----------|-------------|
| Managed Identity | User-assigned identity for all services |
| Service Bus | Queue-based job orchestration |
| Blob Storage | Bronze/Silver tier with SAS URLs |

**Key Files**: `infrastructure/service_bus.py`, `infrastructure/storage.py`

---

## Enabler EN4: Configuration System âœ…

**What It Enables**: Environment-based configuration

| Component | Description |
|-----------|-------------|
| Modular Config | Split from 1200-line monolith |
| Type Safety | Pydantic-based config classes |

**Key Files**: `config/__init__.py`, `config/database_config.py`, `config/storage_config.py`, `config/queue_config.py`, `config/raster_config.py`

---

## Enabler EN5: Pre-flight Validation âœ…

**What It Enables**: Early failure before queue submission

| Validator | Description |
|-----------|-------------|
| blob_exists | Validate blob container + name |
| blob_exists_with_size | Combined existence + size check |
| collection_exists | Validate STAC collection |
| stac_item_exists | Validate STAC item |

**Key Files**: `infrastructure/validators.py`

---

# BACKLOG ENABLERS

## Enabler EN6: Long-Running Task Infrastructure ğŸ“‹ PLANNED

**Purpose**: Docker-based worker for tasks exceeding Azure Functions 30-min timeout
**What It Enables**: E2 (oversized rasters), E3 (large climate datasets)
**Reference**: See architecture diagram at `/api/interface/health`

| Task | Status | Description |
|------|--------|-------------|
| EN6.1 | ğŸ“‹ | Create Docker image with GDAL/rasterio/xarray |
| EN6.2 | ğŸ“‹ | Deploy Azure Container App or Web App for Containers |
| EN6.3 | ğŸ“‹ | Create `long-running-raster-tasks` Service Bus queue |
| EN6.4 | ğŸ“‹ | Implement queue listener in Docker worker |
| EN6.5 | ğŸ“‹ | Add routing logic to dispatch oversized jobs |
| EN6.6 | ğŸ“‹ | Health check and monitoring integration |

**Enables**:
- F2.6 (Large Raster Support) - files exceeding chunked processing limits
- F3.2 (Virtual Zarr Pipeline) - large NetCDF reference generation

---

## Enabler: Repository Pattern Enforcement ğŸ”µ

**Purpose**: Eliminate remaining direct database connections

| Task | Status | Notes |
|------|--------|-------|
| Fix triggers/schema_pydantic_deploy.py | â¬œ | Has psycopg.connect |
| Fix triggers/health.py | â¬œ | Has psycopg.connect |
| Fix core/schema/sql_generator.py | â¬œ | Has psycopg.connect |
| Fix core/schema/deployer.py | â¬œ | Review for direct connections |

---

## Enabler: Dead Code Audit ğŸ”µ

**Purpose**: Remove orphaned code, reduce maintenance burden

| Task | Status |
|------|--------|
| Audit core/ folder | â¬œ |
| Audit infrastructure/ folder | â¬œ |
| Remove commented-out code | â¬œ |
| Update FILE_CATALOG.md | â¬œ |

---

# COMPLETED ENABLERS (ADDITIONAL)

## Enabler: PgSTAC Repository Consolidation âœ…

**Purpose**: Fix "Collection not found after insertion" - two classes manage pgSTAC data
**Completed**: DEC 2025

| Task | Status |
|------|--------|
| Rename PgStacInfrastructure â†’ PgStacBootstrap | âœ… |
| Create PgStacRepository | âœ… |
| Move data operations to PgStacRepository | âœ… |
| Remove duplicate methods | âœ… |

**Key Files**: `infrastructure/pgstac_bootstrap.py`, `infrastructure/pgstac_repository.py`

---

# SUMMARY

## Counts

| Category | Count |
|----------|-------|
| Completed Epics | 1 |
| Active Epics | 6 |
| Planned Epics | 2 |
| **Total Epics** | **9** |
| Completed Features | 17 |
| Active Features | 6 |
| Planned Features | 11 |
| **Total Features** | **34** |
| Completed Enablers | 6 |
| Backlog Enablers | 3 |

## For Azure DevOps Import

| ADO Work Item Type | Maps To |
|-------------------|---------|
| Epic | Epic (E1-E9) |
| Feature | Feature (F1.1, F2.1, etc.) |
| User Story | Story (S1.1.1, S2.1.1, etc.) |
| Task | Enabler tasks |

**Cross-Team Assignment**:
- E9 (DDH Platform Integration) â†’ Assign to DDH Team in ADO
- All other Epics â†’ Assign to Geospatial Team

---

**Last Updated**: 19 DEC 2025 (Added F2.7: Raster Collection Processing)
