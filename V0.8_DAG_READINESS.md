# V0.8 DAG Readiness Assessment

**Created**: 29 JAN 2026
**Status**: ASSESSMENT (Epoch 4 - No DAG implementation)
**Purpose**: Document architecture readiness for future DAG orchestration

---

## Executive Summary

The V0.8 Entity Architecture provides **~70% of the foundation** for future DAG orchestration. This document assesses what's ready, what needs evolution, and establishes patterns for new development to maximize DAG-readiness without implementing DAG in Epoch 4.

**Key Principle**: Epoch 4 uses Function App orchestration with sequential stages and "last task turns out the lights" pattern. These patterns are **required** for the current architecture. New tasks should be designed as pure functions where possible, but existing patterns must be preserved.

---

## Epoch 4 Architecture (Current)

### Required Patterns

These patterns are **required** for Function App orchestration and must be preserved:

| Pattern | Why Required | Used By |
|---------|--------------|---------|
| **Sequential Stages** | Function App 10-min timeout requires breaking work into stages | All multi-stage jobs |
| **Last Task Detection** | Atomic SQL determines when stage completes (parallel tasks) | CoreMachine |
| **Tasks Update Own State** | No central orchestrator polling in Function App model | All handlers |
| **Queue-per-Priority** | Service Bus routing for different task types | jobs-queue, long-running-tasks |

### Current Data Flow

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              PLATFORM API                                    │
│                    (Future: Separate Function App)                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  1. DDH Request arrives at /api/platform/submit                             │
│                                                                              │
│  2. Platform creates GeospatialAsset BEFORE job                             │
│     └── AssetService.create_or_update_asset()                               │
│         └── app.geospatial_assets INSERT (revision=1, pending_review)       │
│                                                                              │
│  3. Platform translates request to CoreMachine job                          │
│     └── translate_to_coremachine() → job_type + params                      │
│                                                                              │
│  4. Platform submits job with asset_id in parameters                        │
│     └── { ...params, asset_id: "abc123..." } → jobs-queue                   │
│                                                                              │
│  5. Return { request_id, job_id, monitor_url }                              │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    │ Service Bus Queue
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                              ORCHESTRATOR                                    │
│              (Function App + Docker Worker in Epoch 4)                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  FUNCTION APP PATH (small/medium files):                                     │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │  Stage 1: Validate                                                   │    │
│  │    ├── Task receives job from queue                                  │    │
│  │    ├── Handler executes validation                                   │    │
│  │    ├── Handler calls mark_task_completed() ← UPDATES OWN STATE      │    │
│  │    └── "Last task" detection advances to Stage 2                     │    │
│  │                                                                      │    │
│  │  Stage 2: Process (COG creation)                                     │    │
│  │    ├── Tasks execute in parallel                                     │    │
│  │    ├── Each task calls mark_task_completed()                         │    │
│  │    └── Last task advances to Stage 3                                 │    │
│  │                                                                      │    │
│  │  Stage 3: Finalize (STAC registration)                               │    │
│  │    ├── Single task executes                                          │    │
│  │    ├── Handler calls mark_job_completed()                            │    │
│  │    └── Job done                                                      │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│                                                                              │
│  DOCKER WORKER PATH (large files):                                           │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │  Single consolidated handler (no stages)                             │    │
│  │    ├── Receives job from long-running-tasks queue                    │    │
│  │    ├── Links job to asset: AssetService.link_job_to_asset()         │    │
│  │    ├── Executes all phases internally (checkpoint-based)             │    │
│  │    ├── Updates asset with content_hash                               │    │
│  │    └── Returns success/failure to CoreMachine                        │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Future DAG Architecture (Epoch 5+)

### Target Model

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              PLATFORM API                                    │
│                       (Separate Function App)                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  1. DDH Request arrives                                                      │
│  2. Platform creates GeospatialAsset (same as Epoch 4)                      │
│  3. Platform defines DAG (nodes + edges)                                     │
│  4. Platform submits DAG definition to orchestrator                          │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                           DAG ORCHESTRATOR                                   │
│                    (Docker App - Long-running process)                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                         CONTROL LOOP                                  │   │
│  │                                                                       │   │
│  │   while True:                                                         │   │
│  │       ready_tasks = query_tasks_with_dependencies_met()               │   │
│  │       for task in ready_tasks:                                        │   │
│  │           dispatch_to_executor_pool(task)                             │   │
│  │                                                                       │   │
│  │       completed = poll_executor_results()                             │   │
│  │       for result in completed:                                        │   │
│  │           update_task_state(result)  ← ORCHESTRATOR OWNS STATE       │   │
│  │           check_dag_completion(result.dag_id)                         │   │
│  │                                                                       │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
│                              ┌───────────┐                                   │
│                              │  DISPATCH │                                   │
│                              └─────┬─────┘                                   │
│                    ┌───────────────┼───────────────┐                         │
│                    ▼               ▼               ▼                         │
│              ┌─────────┐     ┌─────────┐     ┌─────────┐                    │
│              │ Task A  │     │ Task B  │     │ Task C  │                    │
│              │ (pure)  │     │ (pure)  │     │ (pure)  │                    │
│              └────┬────┘     └────┬────┘     └────┬────┘                    │
│                   │               │               │                          │
│                   └───────────────┴───────────────┘                          │
│                                   │                                          │
│                            Return results                                    │
│                      (no state updates in tasks)                             │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Key Differences

| Aspect | Epoch 4 (Function App) | Epoch 5+ (DAG) |
|--------|------------------------|----------------|
| **State ownership** | Tasks update own state | Orchestrator owns all state |
| **Dependencies** | Implicit (sequential stages) | Explicit graph (edges) |
| **Completion detection** | "Last task" atomic SQL | Orchestrator tracks all |
| **Dispatch** | Queue-based (pull) | Orchestrator-based (push) |
| **Timeout handling** | 10-min Function App limit | No timeout (Docker) |
| **Parallelism** | Within-stage only | Any valid DAG topology |

---

## DAG-Readiness Assessment

### What's Already Ready ✅

| Component | Status | Notes |
|-----------|--------|-------|
| **GeospatialAsset as first-class entity** | ✅ Ready | Created before processing, independent of job lifecycle |
| **Platform/Orchestrator separation** | ✅ Ready | Clean boundary at queue interface |
| **Asset `processing_status` field** | ✅ Ready | Can track DAG state on entity |
| **`asset_id` passed to handlers** | ✅ Ready | Handlers know which entity they're processing |
| **Handlers are functionally stateless** | ✅ Ready | Receive params, return results |
| **Deterministic IDs** | ✅ Ready | Asset ID, request ID are idempotent |
| **Revision tracking** | ✅ Ready | Audit trail for entity changes |
| **Docker consolidated handlers** | ✅ Ready | Already don't use stages internally |

### What Needs Evolution ⚠️

| Current Pattern | DAG Pattern | Migration Path |
|-----------------|-------------|----------------|
| Tasks call `mark_task_completed()` | Tasks return results only | New tasks: pure functions. Existing: keep for Epoch 4 |
| Implicit stages (1→2→3) | Explicit DAG edges | Define DAG schema, stages become linear DAGs |
| CoreMachine job-centric | Task-centric tracking | Add task state table or extend jobs |
| "Last task" detection | Orchestrator completion check | Orchestrator polls/receives all results |
| Queue pull model | Orchestrator push model | Orchestrator becomes dispatcher |

### Not Needed for DAG ❌

| Concern | Why Not Needed |
|---------|----------------|
| Change existing handlers | They work, just wrap them |
| Rewrite CoreMachine | Can coexist, DAG is additive |
| Change Platform API | Already creates assets correctly |
| Modify asset schema | `processing_status` sufficient |

---

## Guidelines for New Development

### New Task Handlers (Epoch 4)

When creating NEW task handlers, follow these patterns to maximize DAG-readiness:

```python
# ✅ DAG-READY: Pure function pattern
def my_new_handler(params: Dict[str, Any], context: Any = None) -> Dict[str, Any]:
    """
    Process task and return results.

    DAG-Ready Pattern:
    - Receive parameters
    - Execute processing
    - Return results dict
    - Let CALLER handle state updates
    """
    # Do work
    result = process_something(params)

    # Return results - don't call mark_task_completed()
    return {
        "success": True,
        "result": {
            "output_path": result.path,
            "metrics": result.metrics
        }
    }


# ⚠️ EPOCH 4 REQUIRED: Existing handlers must keep state updates
def existing_handler(params: Dict[str, Any], context: Any = None) -> Dict[str, Any]:
    """
    Existing handler - keeps state updates for Epoch 4 compatibility.

    DO NOT MODIFY existing handlers to remove state updates.
    They are required for Function App orchestration.
    """
    result = process_something(params)

    # Required for Epoch 4 - tasks update own state
    mark_task_completed(params['task_id'], result)

    return {"success": True, "result": result}
```

### New Jobs (Epoch 4)

When creating new jobs:

1. **Use Docker path when possible** - Consolidated handlers are already DAG-like
2. **Keep stages minimal** - Fewer stages = easier DAG migration
3. **Pass `asset_id`** - All jobs should link to GeospatialAsset
4. **Return structured results** - Use Pydantic models for type safety

```python
# ✅ GOOD: Single-stage Docker job (DAG-ready)
class MyNewJob(JobBaseMixin, JobBase):
    job_type = "my_new_job"
    stages = [
        {"number": 1, "name": "process", "task_type": "my_handler", "parallelism": "single"}
    ]
    # Single stage = trivial DAG (one node)


# ⚠️ OK: Multi-stage job (required for Function App)
class MyComplexJob(JobBaseMixin, JobBase):
    job_type = "my_complex_job"
    stages = [
        {"number": 1, "name": "prepare", "task_type": "prepare_handler", "parallelism": "single"},
        {"number": 2, "name": "process", "task_type": "process_handler", "parallelism": "parallel"},
        {"number": 3, "name": "finalize", "task_type": "finalize_handler", "parallelism": "single"}
    ]
    # Stages become linear DAG: prepare → process[] → finalize
```

### Asset Integration

All new code should integrate with GeospatialAsset:

```python
# In Platform submit handler
asset, operation = asset_service.create_or_update_asset(
    dataset_id=req.dataset_id,
    resource_id=req.resource_id,
    version_id=req.version_id,
    data_type=req.data_type,
    ...
)
job_params['asset_id'] = asset.asset_id  # Pass to handler


# In task handler
asset_id = params.get('asset_id')
if asset_id:
    asset_service.link_job_to_asset(asset_id, job_id, content_hash)
```

---

## Migration Path to DAG (Epoch 5+)

When DAG orchestration is implemented:

### Phase 1: Add DAG Infrastructure
- Create `app.dag_definitions` table (nodes, edges)
- Create `app.dag_instances` table (running DAGs)
- Create `app.dag_task_states` table (per-task state)
- Docker orchestrator with control loop

### Phase 2: Wrap Existing Handlers
- Existing handlers become "legacy adapters"
- Wrapper catches `mark_task_completed()` calls
- Orchestrator receives result instead

```python
# Wrapper for legacy handlers
def dag_adapter(legacy_handler):
    def wrapper(params, context):
        # Intercept state updates
        with intercept_state_updates() as captured:
            result = legacy_handler(params, context)

        # Return result to orchestrator (don't apply state updates)
        return {
            "success": result.get("success"),
            "result": result.get("result"),
            "captured_state_updates": captured  # For debugging
        }
    return wrapper
```

### Phase 3: Migrate Jobs to DAG
- Convert stage definitions to DAG edges
- Sequential stages → linear DAG
- Parallel stages → fan-out/fan-in pattern

```python
# Epoch 4 stages
stages = [
    {"number": 1, "name": "validate"},
    {"number": 2, "name": "process", "parallelism": "parallel"},
    {"number": 3, "name": "finalize"}
]

# Epoch 5 DAG equivalent
dag = {
    "nodes": ["validate", "process_1", "process_2", "process_3", "finalize"],
    "edges": [
        ("validate", "process_1"),
        ("validate", "process_2"),
        ("validate", "process_3"),
        ("process_1", "finalize"),
        ("process_2", "finalize"),
        ("process_3", "finalize"),
    ]
}
```

### Phase 4: New Jobs Use DAG Natively
- New jobs define DAGs directly
- Complex dependencies possible
- No stage limitations

---

## Summary

| Epoch | Orchestration Model | State Ownership | Key Pattern |
|-------|--------------------|-----------------| ------------|
| **4 (Current)** | Function App + Docker | Tasks own state | Sequential stages, last-task detection |
| **5 (Future)** | DAG Orchestrator | Orchestrator owns state | Explicit dependencies, control loop |

**Epoch 4 Constraints** (must preserve):
- Sequential stages for Function App timeout handling
- "Last task turns out the lights" for parallel stage completion
- Tasks call `mark_task_completed()` in existing handlers

**DAG-Ready Patterns** (use in new code):
- Pure function handlers (return results, don't update state)
- Single-stage Docker jobs when possible
- Asset integration via `asset_id` parameter
- Structured results with Pydantic models

**No breaking changes required** - Epoch 5 DAG can coexist with Epoch 4 patterns via adapter wrappers.

---

## References

- [V0.8_ENTITIES.md](/V0.8_ENTITIES.md) - Entity architecture specification
- [docs_claude/ARCHITECTURE_REFERENCE.md](/docs_claude/ARCHITECTURE_REFERENCE.md) - CoreMachine patterns
- [docs_claude/DOCKER_INTEGRATION.md](/docs_claude/DOCKER_INTEGRATION.md) - Docker orchestration framework
