# V0.8 PLAN: Docker Worker Consolidation & Vector ETL

**Version**: 0.8.0
**Date**: 23 JAN 2026
**Status**: PLANNING
**Epic**: E7 - Platform Maturity

---

## Executive Summary

Consolidate task queues (`raster-tasks` + `vector-tasks` → `functionapp-tasks`), establish Docker worker as PRIMARY execution environment for all heavy operations, and implement Docker-based vector ETL pipeline.

### V0.8 Priorities

1. **Queue Consolidation**: Merge raster/vector queues into `functionapp-tasks`
2. **Docker Vector ETL**: Implement vector pipeline for Docker worker
3. **App Mode Simplification**: 5 clean modes for 3 deployment configurations
4. **Admin Override**: Force-functionapp option for debugging

---

## 1. DEPLOYMENT CONFIGURATIONS

### Configuration 1: Standalone (Development Only)

Single Function App handles everything. For local development and testing.

```
┌─────────────────────────────────────────────────────────────────┐
│                     STANDALONE (DEV)                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Single Function App                                      │    │
│  │ APP_MODE=standalone                                      │    │
│  │                                                          │    │
│  │ Listens:                                                 │    │
│  │   - geospatial-jobs                                      │    │
│  │   - container-tasks (if DOCKER_WORKER_ENABLED=false)     │    │
│  │   - functionapp-tasks                                    │    │
│  │                                                          │    │
│  │ Serves:                                                  │    │
│  │   - ALL HTTP endpoints                                   │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

**Environment Variables**:
```bash
APP_MODE=standalone
DOCKER_WORKER_ENABLED=false  # Process container-tasks locally
```

---

### Configuration 2: This Environment (Alternate)

Platform + Orchestrator combined, separate FunctionApp Worker, Docker Worker.

```
┌─────────────────────────────────────────────────────────────────┐
│                   ALTERNATE (THIS ENVIRONMENT)                   │
│                      Corporate ASE (4 instances)                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌───────────────────────────────────────┐                      │
│  │ Function App 1: Platform+Orchestrator │  Instance 4          │
│  │ APP_MODE=orchestrator                 │  (2 CPU, 8GB)        │
│  │                                       │                      │
│  │ Listens: geospatial-jobs              │                      │
│  │ Serves:  ALL HTTP endpoints           │                      │
│  │          (/platform/*, /jobs/*,       │                      │
│  │           /admin/*, /dbadmin/*)       │                      │
│  └───────────────────────────────────────┘                      │
│                                                                  │
│  ┌───────────────────────────────────────┐                      │
│  │ Function App 2: Task Worker           │  Instances 1-2       │
│  │ APP_MODE=worker_functionapp           │  (2 CPU, 4GB each)   │
│  │                                       │                      │
│  │ Listens: functionapp-tasks            │                      │
│  │ Serves:  /admin/* only                │                      │
│  └───────────────────────────────────────┘                      │
│                                                                  │
│  ┌───────────────────────────────────────┐                      │
│  │ Docker Worker (Container)             │  Instance 3          │
│  │ APP_MODE=worker_docker                │  (2 CPU, 8GB full)   │
│  │                                       │                      │
│  │ Listens: container-tasks              │                      │
│  │ Serves:  /health, /readyz only        │                      │
│  └───────────────────────────────────────┘                      │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

**Environment Variables**:

Function App 1 (Platform+Orchestrator):
```bash
APP_MODE=orchestrator
DOCKER_WORKER_ENABLED=true
DOCKER_WORKER_URL=https://rmhheavyapi-....azurewebsites.net
```

Function App 2 (Task Worker):
```bash
APP_MODE=worker_functionapp
```

Docker Worker:
```bash
APP_MODE=worker_docker
```

---

### Configuration 3: Production (Full Separation)

Maximum isolation. Platform has auth enabled, all apps independent.

```
┌─────────────────────────────────────────────────────────────────┐
│                      PRODUCTION (FULL SEPARATION)                │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌───────────────────────────────────────┐                      │
│  │ Function App 1: Platform (Gateway)    │                      │
│  │ APP_MODE=platform                     │                      │
│  │                                       │                      │
│  │ Listens: NOTHING (send-only)          │                      │
│  │ Serves:  /api/platform/* only         │                      │
│  │ Auth:    ENABLED + MANAGED            │                      │
│  │                                       │                      │
│  │ External apps call this to request    │                      │
│  │ ETL operations                        │                      │
│  └───────────────────────────────────────┘                      │
│                                                                  │
│  ┌───────────────────────────────────────┐                      │
│  │ Function App 2: Orchestrator          │                      │
│  │ APP_MODE=orchestrator                 │                      │
│  │                                       │                      │
│  │ Listens: geospatial-jobs              │                      │
│  │ Serves:  /api/jobs/*, /api/admin/*,   │                      │
│  │          /api/dbadmin/*               │                      │
│  │ Auth:    Internal network only        │                      │
│  └───────────────────────────────────────┘                      │
│                                                                  │
│  ┌───────────────────────────────────────┐                      │
│  │ Function App 3: Task Worker           │                      │
│  │ APP_MODE=worker_functionapp           │                      │
│  │                                       │                      │
│  │ Listens: functionapp-tasks            │                      │
│  │ Serves:  /api/admin/* only            │                      │
│  │ Auth:    Internal network only        │                      │
│  └───────────────────────────────────────┘                      │
│                                                                  │
│  ┌───────────────────────────────────────┐                      │
│  │ Docker Worker (Container)             │                      │
│  │ APP_MODE=worker_docker                │                      │
│  │                                       │                      │
│  │ Listens: container-tasks              │                      │
│  │ Serves:  /health, /readyz only        │                      │
│  └───────────────────────────────────────┘                      │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 2. QUEUE STRUCTURE

### Final Queue Names

| Queue | Primary Listener | Purpose |
|-------|------------------|---------|
| `geospatial-jobs` | Orchestrator | Job coordination, stage advancement |
| `container-tasks` | Docker Worker | ALL heavy operations (GDAL, geopandas, bulk SQL) |
| `functionapp-tasks` | FunctionApp Worker | Lightweight DB + backup heavy ops |

### Queue Migration

| Old Queue | New Queue | Action |
|-----------|-----------|--------|
| `geospatial-jobs` | `geospatial-jobs` | Keep unchanged |
| `long-running-tasks` | `container-tasks` | Rename |
| `raster-tasks` | `functionapp-tasks` | Merge |
| `vector-tasks` | `functionapp-tasks` | Merge |

### Message Flow

```
┌─────────────────────────────────────────────────────────────────┐
│                        MESSAGE FLOW                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  External App                                                    │
│       │                                                          │
│       ▼                                                          │
│  ┌─────────────┐     ┌──────────────────┐                       │
│  │  Platform   │────▶│ geospatial-jobs  │                       │
│  │  (Gateway)  │     │     Queue        │                       │
│  └─────────────┘     └────────┬─────────┘                       │
│                               │                                  │
│                               ▼                                  │
│                      ┌────────────────┐                         │
│                      │  Orchestrator  │                         │
│                      │  (Job Router)  │                         │
│                      └───────┬────────┘                         │
│                              │                                   │
│              ┌───────────────┼───────────────┐                  │
│              │               │               │                   │
│              ▼               ▼               ▼                   │
│     ┌────────────────┐ ┌──────────────┐                         │
│     │ container-tasks│ │functionapp-  │                         │
│     │     Queue      │ │tasks Queue   │                         │
│     └───────┬────────┘ └──────┬───────┘                         │
│             │                 │                                  │
│             ▼                 ▼                                  │
│     ┌────────────────┐ ┌──────────────┐                         │
│     │ Docker Worker  │ │ FunctionApp  │                         │
│     │ (Heavy Work)   │ │   Worker     │                         │
│     └────────────────┘ └──────────────┘                         │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 3. APP MODES

### Mode Definitions

```python
class AppMode(str, Enum):
    """Application deployment modes."""

    STANDALONE = "standalone"              # All queues, all HTTP (dev only)
    PLATFORM = "platform"                  # HTTP gateway only, send to jobs
    ORCHESTRATOR = "orchestrator"          # Jobs queue + all HTTP (can combine with platform)
    WORKER_FUNCTIONAPP = "worker_functionapp"  # functionapp-tasks queue
    WORKER_DOCKER = "worker_docker"        # container-tasks queue
```

### Mode Behavior Matrix

| Mode | Jobs Queue | Container Queue | FunctionApp Queue | Platform HTTP | Admin HTTP |
|------|------------|-----------------|-------------------|---------------|------------|
| `standalone` | ✅ Listen | ✅ Listen* | ✅ Listen | ✅ | ✅ |
| `platform` | Send only | ❌ | ❌ | ✅ | ❌ |
| `orchestrator` | ✅ Listen | ❌ | ❌ | ✅** | ✅ |
| `worker_functionapp` | ❌ | ❌ | ✅ Listen | ❌ | ✅ |
| `worker_docker` | ❌ | ✅ Listen | ❌ | ❌ | Health only |

*standalone listens to container-tasks only if `DOCKER_WORKER_ENABLED=false`
**orchestrator includes platform endpoints for combined deployment

### HTTP Endpoint Exposure

| Endpoint Group | standalone | platform | orchestrator | worker_functionapp | worker_docker |
|----------------|------------|----------|--------------|-------------------|---------------|
| `/api/platform/*` | ✅ | ✅ | ✅ | ❌ | ❌ |
| `/api/jobs/*` | ✅ | ❌ | ✅ | ❌ | ❌ |
| `/api/admin/*` | ✅ | ❌ | ✅ | ✅ | ❌ |
| `/api/dbadmin/*` | ✅ | ❌ | ✅ | ✅ | ❌ |
| `/api/health` | ✅ | ✅ | ✅ | ✅ | ✅ |
| `/health`, `/readyz` | ✅ | ✅ | ✅ | ✅ | ✅ |

---

## 4. TASK ROUTING

### Routing Categories

#### DOCKER_TASKS → `container-tasks` Queue

All GDAL, geopandas, and heavy pgstac SQL operations:

```python
DOCKER_TASKS = frozenset([
    # =========================================================================
    # CONSOLIDATED RASTER HANDLERS (existing)
    # =========================================================================
    "raster_process_complete",        # F7.13: Validate → COG → STAC
    "raster_process_large_complete",  # F7.18: Tiling pipeline
    "h3_pyramid_complete",            # F7.20: H3 pyramid (post-V0.8)

    # =========================================================================
    # RASTER OPERATIONS (GDAL-dependent)
    # =========================================================================
    "raster_validate",
    "raster_create_cog",
    "raster_extract_stac_metadata",
    "raster_list_files",
    "raster_generate_tiling_scheme",
    "raster_extract_tiles",
    "raster_create_mosaicjson",
    "raster_create_stac_collection",

    # =========================================================================
    # FATHOM RASTER OPERATIONS (GDAL)
    # =========================================================================
    "fathom_band_stack",              # Stack 8 return periods
    "fathom_spatial_merge",           # Merge tiles band-by-band

    # =========================================================================
    # H3 RASTER AGGREGATION (rasterstats - memory intensive)
    # =========================================================================
    "h3_raster_zonal_stats",

    # =========================================================================
    # VECTOR ETL - DOCKER (V0.8 NEW - geopandas + pgstac SQL)
    # =========================================================================
    "vector_docker_prepare",          # NEW: Geopandas read/transform
    "vector_docker_upload",           # NEW: Bulk pgstac insert
    "vector_docker_stac",             # NEW: STAC item creation
])
```

#### FUNCTIONAPP_TASKS → `functionapp-tasks` Queue

Lightweight DB operations, inventory, STAC queries:

```python
FUNCTIONAPP_TASKS = frozenset([
    # =========================================================================
    # LEGACY VECTOR ETL (FunctionApp - backup/admin only after V0.8)
    # =========================================================================
    "process_vector_prepare",
    "process_vector_upload",
    "vector_create_stac",
    "vector_extract_stac_metadata",

    # =========================================================================
    # INVENTORY OPERATIONS (blob listing, lightweight)
    # =========================================================================
    "inventory_container_summary",
    "inventory_list_blobs",
    "inventory_analyze_blob",
    "inventory_aggregate_analysis",
    "inventory_classify_geospatial",
    "inventory_aggregate_geospatial",

    # =========================================================================
    # FATHOM INVENTORY (DB queries, not raster)
    # =========================================================================
    "fathom_generate_scan_prefixes",
    "fathom_scan_prefix",
    "fathom_assign_grid_cells",
    "fathom_inventory_summary",
    "fathom_tile_inventory",
    "fathom_grid_inventory",
    "fathom_stac_register",
    "fathom_stac_rebuild",

    # =========================================================================
    # H3 POSTGIS OPERATIONS (DB-bound, not memory intensive)
    # =========================================================================
    "h3_create_stac",
    "h3_native_streaming_postgis",
    "h3_generate_grid",
    "h3_cascade_descendants",
    "h3_finalize_pyramid",
    "h3_inventory_cells",
    "h3_aggregation_finalize",

    # =========================================================================
    # STAC OPERATIONS (pgSTAC queries, lightweight)
    # =========================================================================
    "stac_repair_inventory",
    "stac_repair_item",
    "stac_rebuild_validate",
    "stac_rebuild_item",

    # =========================================================================
    # UNPUBLISH OPERATIONS (STAC queries, blob deletes)
    # =========================================================================
    "unpublish_inventory_raster",
    "unpublish_inventory_vector",
    "unpublish_delete_blob",
    "unpublish_drop_table",
    "unpublish_delete_stac",

    # =========================================================================
    # CURATED DATASET UPDATES (HTTP, DB, lightweight)
    # =========================================================================
    "curated_check_source",
    "curated_fetch_data",
    "curated_etl_process",
    "curated_finalize",

    # =========================================================================
    # H3 EXPORT (DB-bound)
    # =========================================================================
    "h3_export_validate",
    "h3_export_build",
    "h3_export_register",

    # =========================================================================
    # INGEST COLLECTION (blob copy, pgSTAC)
    # =========================================================================
    "ingest_inventory",
    "ingest_copy_batch",
    "ingest_register_collection",
    "ingest_register_items",
    "ingest_finalize",

    # =========================================================================
    # ORPHAN BLOB OPERATIONS (blob listing, DB queries)
    # =========================================================================
    "orphan_blob_inventory",
    "silver_blob_validate",
    "silver_blob_register",

    # =========================================================================
    # TEST HANDLERS
    # =========================================================================
    "hello_world_greeting",
    "hello_world_reply",
])
```

### Routing Logic

```python
def _get_queue_for_task(self, task_type: str, force_functionapp: bool = False) -> str:
    """
    Route task to appropriate queue.

    Args:
        task_type: The handler task type
        force_functionapp: Admin override to use FunctionApp (debug only)

    Returns:
        Queue name for this task
    """
    # Admin override - force to FunctionApp for debugging
    # NOTE: Remove before production deployment
    if force_functionapp and task_type in DOCKER_TASKS:
        logger.warning(f"Admin override: routing {task_type} to functionapp-tasks")
        return config.queues.functionapp_tasks_queue

    # Normal routing
    if task_type in DOCKER_TASKS:
        return config.queues.container_tasks_queue  # "container-tasks"
    elif task_type in FUNCTIONAPP_TASKS:
        return config.queues.functionapp_tasks_queue  # "functionapp-tasks"
    else:
        raise ContractViolationError(
            f"Task type '{task_type}' not in DOCKER_TASKS or FUNCTIONAPP_TASKS. "
            f"Add to TaskRoutingDefaults in config/defaults.py"
        )
```

---

## 5. DOCKER VECTOR ETL (V0.8 Priority)

### New Job: `vector_docker_etl`

```python
class VectorDockerETLJob(JobBaseMixin, JobBase):
    """
    Docker-based vector ETL pipeline.

    Processes vector data using geopandas for transformations
    and bulk pgstac SQL for database operations.

    Stages:
        1. Prepare: Read source, validate, transform with geopandas
        2. Upload: Bulk insert to PostGIS using COPY
        3. STAC: Create/update STAC item
    """

    job_type = "vector_docker_etl"
    description = "Docker vector ETL with geopandas and bulk SQL"

    stages = [
        {
            "number": 1,
            "name": "prepare",
            "task_type": "vector_docker_prepare",
            "parallelism": "single"
        },
        {
            "number": 2,
            "name": "upload",
            "task_type": "vector_docker_upload",
            "parallelism": "single"
        },
        {
            "number": 3,
            "name": "stac",
            "task_type": "vector_docker_stac",
            "parallelism": "single"
        }
    ]

    parameters_schema = {
        'source_url': {'type': 'str', 'required': True},
        'collection_id': {'type': 'str', 'required': True},
        'table_name': {'type': 'str', 'required': False},
        'transform_options': {'type': 'dict', 'required': False},
    }
```

---

## 6. IMPLEMENTATION STEPS

### Phase 1: Queue Infrastructure
**Effort: 30 minutes | Risk: Low**

Create new Service Bus queues. Old queues remain active during migration.

#### Step 1.1: Create container-tasks queue
```bash
az servicebus queue create \
  --name container-tasks \
  --namespace-name $SB_NAMESPACE \
  --resource-group $RESOURCE_GROUP \
  --max-size 5120 \
  --default-message-time-to-live P14D \
  --lock-duration PT5M
```

#### Step 1.2: Create functionapp-tasks queue
```bash
az servicebus queue create \
  --name functionapp-tasks \
  --namespace-name $SB_NAMESPACE \
  --resource-group $RESOURCE_GROUP \
  --max-size 5120 \
  --default-message-time-to-live P14D \
  --lock-duration PT5M
```

#### Step 1.3: Verify queues created
```bash
az servicebus queue list --namespace-name $SB_NAMESPACE --query "[].name" -o table
```

**Deliverable**: New queues exist alongside old queues

---

### Phase 2: Configuration Updates
**Effort: 2-3 hours | Risk: Medium**

Update routing configuration and queue defaults.

#### Step 2.1: Update `config/defaults.py`

```python
# Changes to make:

# 1. Rename LONG_RUNNING_TASKS → DOCKER_TASKS
# 2. Add all raster tasks to DOCKER_TASKS
# 3. Rename RASTER_TASKS + VECTOR_TASKS → FUNCTIONAPP_TASKS
# 4. Update QueueDefaults class

class QueueDefaults:
    JOBS_QUEUE = "geospatial-jobs"
    CONTAINER_TASKS_QUEUE = "container-tasks"      # NEW (was long-running-tasks)
    FUNCTIONAPP_TASKS_QUEUE = "functionapp-tasks"  # NEW (merged raster + vector)

    # Deprecated - keep for migration period
    LONG_RUNNING_TASKS_QUEUE = "long-running-tasks"  # DEPRECATED
    RASTER_TASKS_QUEUE = "raster-tasks"              # DEPRECATED
    VECTOR_TASKS_QUEUE = "vector-tasks"              # DEPRECATED
```

#### Step 2.2: Update `config/queue_config.py`

```python
# Add new queue properties:

@property
def container_tasks_queue(self) -> str:
    """Queue for Docker container tasks (heavy operations)."""
    return os.environ.get(
        "SERVICE_BUS_CONTAINER_TASKS_QUEUE",
        QueueDefaults.CONTAINER_TASKS_QUEUE
    )

@property
def functionapp_tasks_queue(self) -> str:
    """Queue for FunctionApp tasks (lightweight operations)."""
    return os.environ.get(
        "SERVICE_BUS_FUNCTIONAPP_TASKS_QUEUE",
        QueueDefaults.FUNCTIONAPP_TASKS_QUEUE
    )
```

#### Step 2.3: Update `core/machine.py` routing

```python
# Update _get_queue_for_task method:

def _get_queue_for_task(self, task_type: str) -> str:
    """Route task to appropriate queue."""
    # Check for admin override
    force_functionapp = self._current_job_params.get('_force_functionapp', False)

    if force_functionapp and task_type in TaskRoutingDefaults.DOCKER_TASKS:
        logger.warning(f"Admin override: {task_type} → functionapp-tasks")
        return self.config.queues.functionapp_tasks_queue

    if task_type in TaskRoutingDefaults.DOCKER_TASKS:
        return self.config.queues.container_tasks_queue
    elif task_type in TaskRoutingDefaults.FUNCTIONAPP_TASKS:
        return self.config.queues.functionapp_tasks_queue
    else:
        raise ContractViolationError(
            f"Task type '{task_type}' not routed. "
            f"Add to DOCKER_TASKS or FUNCTIONAPP_TASKS in config/defaults.py"
        )
```

**Deliverable**: Routing logic uses new queue names

---

### Phase 3: App Mode Simplification
**Effort: 2-3 hours | Risk: Medium**

Simplify app modes from 8 to 5.

#### Step 3.1: Update `config/app_mode_config.py`

```python
# Remove these modes:
# - PLATFORM_ONLY (use ORCHESTRATOR instead)
# - PLATFORM_RASTER (no longer needed)
# - PLATFORM_VECTOR (no longer needed)
# - WORKER_RASTER (merged into WORKER_FUNCTIONAPP)
# - WORKER_VECTOR (merged into WORKER_FUNCTIONAPP)

class AppMode(str, Enum):
    STANDALONE = "standalone"
    PLATFORM = "platform"
    ORCHESTRATOR = "orchestrator"
    WORKER_FUNCTIONAPP = "worker_functionapp"
    WORKER_DOCKER = "worker_docker"
```

#### Step 3.2: Update queue listening properties

```python
@property
def listens_to_functionapp_tasks(self) -> bool:
    """Whether this mode processes functionapp-tasks queue."""
    return self.mode in [
        AppMode.STANDALONE,
        AppMode.WORKER_FUNCTIONAPP,
    ]

@property
def listens_to_container_tasks(self) -> bool:
    """Whether this mode processes container-tasks queue."""
    if self.mode == AppMode.WORKER_DOCKER:
        return True
    if self.mode == AppMode.STANDALONE and not self.docker_worker_enabled:
        return True
    return False
```

#### Step 3.3: Update HTTP endpoint properties

```python
@property
def has_platform_endpoints(self) -> bool:
    """Whether this mode exposes /api/platform/* endpoints."""
    return self.mode in [
        AppMode.STANDALONE,
        AppMode.PLATFORM,
        AppMode.ORCHESTRATOR,  # Combined deployment
    ]

@property
def has_jobs_endpoints(self) -> bool:
    """Whether this mode exposes /api/jobs/* endpoints."""
    return self.mode in [
        AppMode.STANDALONE,
        AppMode.ORCHESTRATOR,
    ]

@property
def has_admin_endpoints(self) -> bool:
    """Whether this mode exposes /api/admin/* endpoints."""
    return self.mode in [
        AppMode.STANDALONE,
        AppMode.ORCHESTRATOR,
        AppMode.WORKER_FUNCTIONAPP,
    ]
```

**Deliverable**: 5 clean app modes

---

### Phase 4: Azure Functions Triggers
**Effort: 1-2 hours | Risk: Medium**

Update Service Bus triggers to use new queues.

#### Step 4.1: Update `function_app.py`

```python
# Remove old triggers:
# - process_raster_task (raster-tasks queue)
# - process_vector_task (vector-tasks queue)

# Add new trigger:
if _app_mode.listens_to_functionapp_tasks:
    @app.service_bus_queue_trigger(
        arg_name="msg",
        queue_name="functionapp-tasks",
        connection="ServiceBusConnection"
    )
    def process_functionapp_task(msg: func.ServiceBusMessage):
        """Process tasks from functionapp-tasks queue."""
        handle_task_message(msg, core_machine, queue_name="functionapp-tasks")

# Note: container-tasks trigger only in standalone mode with DOCKER_WORKER_ENABLED=false
if _app_mode.listens_to_container_tasks:
    @app.service_bus_queue_trigger(
        arg_name="msg",
        queue_name="container-tasks",
        connection="ServiceBusConnection"
    )
    def process_container_task(msg: func.ServiceBusMessage):
        """Process tasks from container-tasks queue (dev only)."""
        handle_task_message(msg, core_machine, queue_name="container-tasks")
```

**Deliverable**: Functions listen to new queues

---

### Phase 5: Docker Worker Update
**Effort: 30 minutes | Risk: Low**

Update Docker worker to listen to `container-tasks` queue.

#### Step 5.1: Update `docker_service.py`

```python
# In BackgroundQueueWorker.__init__:
# Change queue name from "long-running-tasks" to "container-tasks"

class BackgroundQueueWorker:
    def __init__(self, ...):
        self.queue_name = config.queues.container_tasks_queue  # "container-tasks"
```

#### Step 5.2: Update `docker_main.py`

```python
# Same change if this file has hardcoded queue name
queue_name = config.queues.container_tasks_queue
```

**Deliverable**: Docker worker listens to `container-tasks`

---

### Phase 6: Docker Vector ETL Implementation
**Effort: 3-5 hours | Risk: Medium**

Implement the new vector ETL pipeline for Docker.

#### Step 6.1: Create `jobs/vector_docker_etl.py`

```python
# New job definition file
# See Section 5 for full implementation
```

#### Step 6.2: Create `handlers/vector_docker.py`

```python
# New handlers file with:
# - vector_docker_prepare
# - vector_docker_upload
# - vector_docker_stac
```

#### Step 6.3: Register job in `jobs/__init__.py`

```python
from jobs.vector_docker_etl import VectorDockerETLJob

ALL_JOBS = {
    # ... existing jobs ...
    "vector_docker_etl": VectorDockerETLJob,
}
```

#### Step 6.4: Register handlers in `services/__init__.py`

```python
from handlers.vector_docker import (
    vector_docker_prepare,
    vector_docker_upload,
    vector_docker_stac,
)

ALL_HANDLERS = {
    # ... existing handlers ...
    "vector_docker_prepare": vector_docker_prepare,
    "vector_docker_upload": vector_docker_upload,
    "vector_docker_stac": vector_docker_stac,
}
```

#### Step 6.5: Add to `config/defaults.py` DOCKER_TASKS

```python
DOCKER_TASKS = frozenset([
    # ... existing ...
    "vector_docker_prepare",
    "vector_docker_upload",
    "vector_docker_stac",
])
```

**Deliverable**: Docker vector ETL functional

---

### Phase 7: Admin Override Implementation
**Effort: 1-2 hours | Risk: Low**

Add force-functionapp parameter for debugging.

#### Step 7.1: Update admin job submission endpoint

```python
# In triggers/http/admin.py or equivalent:

def submit_job_admin(req: func.HttpRequest) -> func.HttpResponse:
    """Admin job submission with override options."""
    # Parse override parameter
    force_functionapp = req.params.get("force_functionapp", "").lower() == "true"

    if force_functionapp:
        logger.warning(f"Admin override: force_functionapp=true for job submission")

    # Add to job params
    job_params = req.get_json()
    job_params["_force_functionapp"] = force_functionapp

    # Submit job
    # ...
```

#### Step 7.2: Ensure NOT available on /platform endpoints

```python
# In triggers/http/platform.py:
# Do NOT add force_functionapp parameter
# This ensures external apps cannot use the override
```

**Deliverable**: Admin can override routing for debugging

---

### Phase 8: Testing & Validation
**Effort: 2-3 hours | Risk: Low**

Comprehensive testing before deployment.

#### Step 8.1: Local testing

```bash
# Run with standalone mode
APP_MODE=standalone DOCKER_WORKER_ENABLED=false python -m pytest tests/

# Test routing logic
python -c "from config.defaults import TaskRoutingDefaults; print(TaskRoutingDefaults.DOCKER_TASKS)"
```

#### Step 8.2: Integration tests

```bash
# Test hello_world routes to functionapp-tasks
curl -X POST .../api/jobs/submit/hello_world -d '{"message": "test"}'

# Test raster_etl routes to container-tasks
curl -X POST .../api/jobs/submit/raster_etl -d '{"source_url": "..."}'

# Test admin override
curl -X POST ".../api/admin/jobs/submit/raster_etl?force_functionapp=true" -d '{"source_url": "..."}'
```

**Deliverable**: All tests pass

---

### Phase 9: Deployment
**Effort: 1-2 hours | Risk: Medium**

Deploy to production environment.

#### Step 9.1: Deploy Function App updates

```bash
func azure functionapp publish rmhazuregeoapi --python --build remote
```

#### Step 9.2: Update Docker worker

```bash
# Build and push new container image
az acr build --registry rmhazureacr --image geospatial-worker:0.8.0 --file Dockerfile .

# Update container
az webapp config container set --name rmhheavyapi --resource-group rmhazure_rg \
  --docker-custom-image-name "rmhazureacr.azurecr.io/geospatial-worker:0.8.0"

# Restart
az webapp stop --name rmhheavyapi --resource-group rmhazure_rg && \
az webapp start --name rmhheavyapi --resource-group rmhazure_rg
```

#### Step 9.3: Post-deployment validation

```bash
# Health check
curl https://rmhazuregeoapi-....azurewebsites.net/api/health

# Sync schema
curl -X POST ".../api/dbadmin/maintenance?action=ensure&confirm=yes"

# Test job submission
curl -X POST .../api/jobs/submit/hello_world -d '{"message": "v0.8 test"}'
```

**Deliverable**: V0.8.0 deployed and validated

---

### Phase 10: Cleanup (After 1 Week Stabilization)
**Effort: 30 minutes | Risk: Low**

Remove old queues after confirming stability.

#### Step 10.1: Verify old queues are empty

```bash
az servicebus queue show --name raster-tasks --namespace-name $SB_NAMESPACE --query messageCount
az servicebus queue show --name vector-tasks --namespace-name $SB_NAMESPACE --query messageCount
az servicebus queue show --name long-running-tasks --namespace-name $SB_NAMESPACE --query messageCount
```

#### Step 10.2: Delete old queues

```bash
az servicebus queue delete --name raster-tasks --namespace-name $SB_NAMESPACE
az servicebus queue delete --name vector-tasks --namespace-name $SB_NAMESPACE
az servicebus queue delete --name long-running-tasks --namespace-name $SB_NAMESPACE
```

#### Step 10.3: Remove deprecated code

```python
# Remove from config/defaults.py:
# - LONG_RUNNING_TASKS_QUEUE
# - RASTER_TASKS_QUEUE
# - VECTOR_TASKS_QUEUE
# - LONG_RUNNING_TASKS list
# - RASTER_TASKS list
# - VECTOR_TASKS list
```

**Deliverable**: Clean codebase with no deprecated references

---

## 7. FILE CHANGE SUMMARY

### New Files

| File | Purpose |
|------|---------|
| `handlers/vector_docker.py` | Docker vector ETL handlers |
| `jobs/vector_docker_etl.py` | Docker vector ETL job definition |

### Modified Files

| File | Phase | Changes |
|------|-------|---------|
| `config/defaults.py` | 2 | DOCKER_TASKS, FUNCTIONAPP_TASKS, queue defaults |
| `config/queue_config.py` | 2 | New queue properties |
| `config/app_mode_config.py` | 3 | Simplified 5 modes |
| `core/machine.py` | 2 | Updated routing, force_functionapp |
| `function_app.py` | 4 | New triggers, removed old |
| `docker_service.py` | 5 | Queue name update |
| `docker_main.py` | 5 | Queue name update |
| `jobs/__init__.py` | 6 | Register vector_docker_etl |
| `services/__init__.py` | 6 | Register vector_docker handlers |
| `triggers/http/admin.py` | 7 | force_functionapp parameter |

### Documentation Updates

| File | Changes |
|------|---------|
| `CLAUDE.md` | Deployment configs, queue names |
| `docs_claude/DOCKER_INTEGRATION.md` | Mandatory status, architecture |
| `docs_claude/ARCHITECTURE_DIAGRAMS.md` | Updated diagrams |

---

## 8. ENVIRONMENT VARIABLES

### New Variables

```bash
# Queue configuration
SERVICE_BUS_CONTAINER_TASKS_QUEUE=container-tasks
SERVICE_BUS_FUNCTIONAPP_TASKS_QUEUE=functionapp-tasks

# App modes
APP_MODE=standalone           # Dev: all in one
APP_MODE=platform             # Prod: gateway only
APP_MODE=orchestrator         # Prod: jobs queue + HTTP
APP_MODE=worker_functionapp   # Prod: functionapp-tasks queue
APP_MODE=worker_docker        # All: container-tasks queue
```

### Deprecated Variables (Remove after Phase 10)

```bash
SERVICE_BUS_RASTER_TASKS_QUEUE
SERVICE_BUS_VECTOR_TASKS_QUEUE
SERVICE_BUS_LONG_RUNNING_TASKS_QUEUE
```

---

## 9. TESTING CHECKLIST

### Pre-Migration
- [ ] All existing jobs complete successfully
- [ ] Docker worker health check passes
- [ ] Current queue depths are zero

### Phase 1-2 (Queues + Routing)
- [ ] New queues created in Service Bus
- [ ] Routing config compiles without errors
- [ ] Unit tests pass for routing logic

### Phase 3-5 (App Modes + Triggers)
- [ ] App mode config validates for all 5 modes
- [ ] Function triggers register for correct queues
- [ ] Docker worker connects to `container-tasks`

### Phase 6 (Docker Vector ETL)
- [ ] `vector_docker_etl` job submits successfully
- [ ] Stage 1 (prepare) completes in Docker
- [ ] Stage 2 (upload) inserts to PostGIS
- [ ] Stage 3 (stac) creates STAC item
- [ ] End-to-end test with real vector file

### Phase 7 (Admin Override)
- [ ] `?force_functionapp=true` routes to FunctionApp
- [ ] Override only works on admin endpoints (not /platform)
- [ ] Override logged with warning

### Integration Tests
- [ ] `hello_world` job → functionapp-tasks ✓
- [ ] `raster_etl` job → container-tasks ✓
- [ ] `vector_docker_etl` job → container-tasks ✓
- [ ] `fathom_etl` job → mixed routing ✓
- [ ] Stage completion signaling works
- [ ] Checkpoint/resume works in Docker

---

## 10. ROLLBACK PLAN

### If Issues Arise

1. **Queue Level**: Old queues exist during migration
   - Revert `TaskRoutingDefaults` to use old names
   - Redeploy previous version

2. **App Mode Level**:
   - Use `APP_MODE=standalone` as fallback

3. **Docker Vector ETL**:
   - New job, doesn't affect existing workflows
   - Can disable without impacting other jobs

### Recovery Commands

```bash
# Revert to previous deployment
func azure functionapp publish rmhazuregeoapi --python --build remote --slot previous

# Check queue depths
az servicebus queue show --name container-tasks --namespace-name $SB_NAMESPACE --query messageCount

# Force drain a queue (move to DLQ)
# Use Service Bus Explorer in Azure Portal
```

---

## 11. SUCCESS CRITERIA

1. **Queue consolidation complete**: 3 active queues (jobs, container, functionapp)
2. **Docker Vector ETL functional**: End-to-end pipeline works
3. **App modes simplified**: 5 clean modes
4. **Admin override works**: Can force FunctionApp for debugging
5. **No job failures**: All existing job types complete
6. **Recovery works**: Queued messages wait for Docker recovery

---

## 12. POST-V0.8 ROADMAP

### V0.8.1: H3 Docker Pipeline

Move H3 operations to Docker:
- `h3_native_streaming_postgis` → Docker (geopandas)
- `h3_generate_grid` → Docker
- `h3_cascade_descendants` → Docker

### V0.8.2: Remove Admin Override

Before production:
- Remove `force_functionapp` parameter
- Audit all admin endpoints
- Lock down FunctionApp worker to internal network

### V0.8.3: FunctionApp SKU Optimization

After Docker handles all heavy work:
- Evaluate smaller SKU for FunctionApp workers
- Consider Consumption plan for lightweight tasks

---

## 13. RASTER LOGIC AND FILE MOUNT IMPLEMENTATION

### V0.8 Doctrine

**Assumptions:**
- Docker worker is ALWAYS present with Azure Files mount
- No mount = **functional but degraded state** (not unhealthy, but not optimal)
  - System remains healthy and operational
  - Performance may be reduced (uses container memory instead of mount)
  - Logged as warning, not error
  - Production deployments SHOULD have mount, but system works without it
- ONE raster workflow: `process_raster_docker` running on Docker
- Tiling decision is INTERNAL to the job (not separate job types)

### Architecture

```
Raster Submission (B2B API)
       │
       ▼
  Docker Worker
  └── process_raster_docker
       │
       ▼
  ┌─────────────────────┐
  │ file_size > tiling  │
  │ threshold?          │
  └──────────┬──────────┘
             │
      ┌──────┴──────┐
      ▼             ▼
   > threshold   ≤ threshold
      │             │
      ▼             ▼
   N COG Tiles   Single COG
   (tiled)       (one file)
```

### Configuration Settings (Final State)

| Setting | Default | Purpose |
|---------|---------|---------|
| `RASTER_USE_ETL_MOUNT` | `true` | Expected state (false = degraded) |
| `RASTER_TILING_THRESHOLD_MB` | 2000 | When to switch to tiled output |
| `RASTER_TILE_TARGET_MB` | 200 | Target size per tile |

### Implementation TODO

#### Phase 13.1: Remove Obsolete Config Settings ✅ COMPLETE (24 JAN 2026)
**Effort: 1 hour | Risk: Low**

Removed deprecated routing settings no longer used in V0.8:

- [x] **config/defaults.py**: Removed from `RasterDefaults`:
  - `RASTER_ROUTE_LARGE_MB`
  - `RASTER_ROUTE_DOCKER_MB`
  - `RASTER_ROUTE_REJECT_MB`
  - `ETL_MOUNT_IN_MEMORY_SIZE_LIMIT_MB`

- [x] **config/raster_config.py**: Removed fields

- [x] **config/env_validation.py**: Removed validation rules

- [x] **config/__init__.py**: Updated `debug_config()` output

#### Phase 13.2: Add Tiling Threshold Config ✅ COMPLETE (24 JAN 2026)
**Effort: 30 minutes | Risk: Low**

- [x] **config/defaults.py**: Added `RASTER_TILING_THRESHOLD_MB = 2000`
- [x] **config/raster_config.py**: Added `raster_tiling_threshold_mb` field
- [x] **config/defaults.py**: Changed `USE_ETL_MOUNT = True` (V0.8 expectation)

#### Phase 13.3: Implement Tiling Logic in process_raster_docker ✅ COMPLETE (24 JAN 2026)
**Effort: 2-3 hours | Risk: Medium**

Implemented unified handler that handles both single COG and tiled output:

- [x] **jobs/process_raster_docker.py**:
  - Added `_file_size_mb` parameter passthrough from validator
  - Added tiling parameters (`tile_size`, `overlap`, `band_names`) to schema
  - Updated `finalize_job()` to handle both `single_cog` and `tiled` output modes

- [x] **services/handler_process_raster_complete.py**:
  - Added `_process_raster_tiled()` internal function (adapted from process_large_raster_complete)
  - Handler now checks `_file_size_mb` vs `raster_tiling_threshold_mb` at start
  - Routes to tiled workflow if file exceeds threshold
  - Returns `output_mode: "single_cog"` or `output_mode: "tiled"` in result

Architecture:
```
process_raster_complete (handler)
    │
    ├── file_size <= threshold → Single COG (3 phases)
    │   └── Validation → COG → STAC
    │
    └── file_size > threshold → Tiled (5 phases)
        └── Tiling → Extract → COGs → MosaicJSON → STAC
```

#### Phase 13.4: Deprecate process_large_raster_docker ✅ COMPLETE (24 JAN 2026)
**Effort: 30 minutes | Risk: Low**

- [x] **jobs/process_large_raster_docker.py**:
  - Updated header with DEPRECATED status
  - Added `validate_parameters()` override with deprecation warning
  - Job still works for backward compatibility

- [x] **services/handler_process_large_raster_complete.py**:
  - Updated header with DEPRECATED status
  - Added deprecation warning at handler start
  - Handler still works for backward compatibility

Migration path documented:
- OLD: `job_type="process_large_raster_docker"`
- NEW: `job_type="process_raster_docker"` (same parameters, tiling automatic)

#### Phase 13.5: Update Pre-flight Validation ✅ COMPLETE (24 JAN 2026)
**Effort: 30 minutes | Risk: Low**

- [x] **triggers/trigger_platform_status.py**: Updated `platform_validate()`:
  - All raster uses `process_raster_docker`
  - Returns `output_mode` (single_cog vs tiled) based on file size
  - Returns `estimated_tiles` for tiled mode
  - Warns if mount is disabled (degraded state)

#### Phase 13.6: Startup Validation ✅ COMPLETE (24 JAN 2026)
**Effort: 30 minutes | Risk: Low**

- [x] **docker_service.py**: Updated `validate_etl_mount()`:
  - Logs WARNING if mount not present (NOT failure - degraded state)
  - Sets `degraded: True` in result when mount disabled
  - V0.8 doctrine: mount is EXPECTED, disabled = degraded not unhealthy

#### Phase 13.7: Retrofit Function App process_raster_v2
**Effort: 1 hour | Risk: Low**

The Function App's `process_raster_v2` job still references removed config settings.
Update to remove references to obsolete settings.

**Note:** Other Function App raster workflows (`process_large_raster_v2`, etc.) are
broken but will be ARCHIVED - do not fix, just deprecate/remove.

- [ ] **jobs/process_raster_v2.py**: Remove references to:
  - `raster_route_large_mb` (routing threshold - no longer used)
  - `raster_route_docker_mb` (Docker threshold - no longer used)
  - `raster_route_reject_mb` (reject threshold - no longer used)
  - Any size-based routing logic (V0.8: all raster goes to Docker)

- [ ] **jobs/process_raster_v2.py**: Add deprecation warning:
  - Function App raster processing is deprecated
  - Recommend `process_raster_docker` instead
  - Keep functional for backward compatibility during migration

- [ ] **Archive obsolete Function App raster jobs** (do NOT fix):
  - `jobs/process_large_raster_v2.py` → Mark as ARCHIVED
  - Any other Function App tiling jobs → Mark as ARCHIVED

- [ ] **Verify Function App starts** after config changes:
  - No import errors from removed config fields
  - Health endpoint works

### Testing Checklist (V0.8 Section 13)

**After deployment, verify:**

- [ ] Submit 500MB raster → Single COG output (`output_mode: "single_cog"`)
- [ ] Submit 3GB raster → Tiled output (`output_mode: "tiled"`, N tiles)
- [ ] Verify mount validation logs WARNING (not failure) when mount disabled
- [ ] Verify health endpoint shows "degraded" when mount missing (not "unhealthy")
- [ ] Verify system remains functional without mount (degraded performance)
- [ ] Verify pre-flight returns correct `output_mode` and `estimated_tiles`
- [ ] Verify `process_large_raster_docker` shows deprecation warning in logs
- [ ] Verify `finalize_job` correctly formats result for both modes
- [ ] Verify Function App starts without import errors (Phase 13.7)

### Files Changed

| File | Changes |
|------|---------|
| `config/defaults.py` | Remove 4 settings, add 1, change 1 default |
| `config/raster_config.py` | Remove 4 fields, add 1 |
| `config/env_validation.py` | Remove 3 rules |
| `config/__init__.py` | Update debug_config |
| `jobs/process_raster_docker.py` | Add tiling decision logic |
| `jobs/process_large_raster_docker.py` | Add deprecation |
| `triggers/trigger_platform_status.py` | Simplify validation |
| `docker_service.py` | Stricter mount validation |

---

## 14. STAC COLLECTION BEHAVIOR

### Overview

The `process_raster_docker` job creates/updates STAC items and collections. Understanding the collection behavior is essential for organizing raster catalogs.

### Collection Parameter

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `collection_id` | str | **REQUIRED** | Target STAC collection ID |
| `collection_must_exist` | bool | `false` | If `true`, fail if collection doesn't exist |

### Behavior Matrix

| Collection Exists? | `collection_must_exist` | Result |
|-------------------|-------------------------|--------|
| ✅ Yes | `false` | **Add item to existing collection** |
| ✅ Yes | `true` | **Add item to existing collection** |
| ❌ No | `false` | **Auto-create collection**, then add item |
| ❌ No | `true` | **❌ FAIL** with error |

### Use Cases

#### 1. Add Raster to Existing Collection

```bash
# Submit job with collection_id of an existing collection
curl -X POST .../api/jobs/submit/process_raster_docker \
  -H "Content-Type: application/json" \
  -d '{
    "blob_name": "new_raster.tif",
    "container_name": "bronze-data",
    "collection_id": "flood-analysis",
    "collection_must_exist": true
  }'
```

**Result**: Item added to `flood-analysis` collection. Fails if collection doesn't exist.

#### 2. Create New Collection (Auto-Create)

```bash
# Submit with new collection_id (auto-creates if missing)
curl -X POST .../api/jobs/submit/process_raster_docker \
  -H "Content-Type: application/json" \
  -d '{
    "blob_name": "first_raster.tif",
    "container_name": "bronze-data",
    "collection_id": "new-project-data"
  }'
```

**Result**: Collection `new-project-data` auto-created with minimal metadata, then item added.

#### 3. Strict Mode (Prevent Accidental Collections)

```bash
# Use collection_must_exist=true to prevent typos creating new collections
curl -X POST .../api/jobs/submit/process_raster_docker \
  -H "Content-Type: application/json" \
  -d '{
    "blob_name": "raster.tif",
    "container_name": "bronze-data",
    "collection_id": "floood-analysis",  # Typo!
    "collection_must_exist": true
  }'
```

**Result**: ❌ Fails with `"Collection 'floood-analysis' does not exist and collection_must_exist=True"`.

### Auto-Created Collection Template

When a collection is auto-created, it uses this minimal template:

```json
{
  "id": "{collection_id}",
  "type": "Collection",
  "stac_version": "1.0.0",
  "description": "Auto-created collection for standalone raster processing (created: {timestamp})",
  "extent": {
    "spatial": {"bbox": [[-180, -90, 180, 90]]},
    "temporal": {"interval": [[null, null]]}
  },
  "license": "proprietary"
}
```

**Note**: Auto-created collections have placeholder extents. The extent updates as items are added.

### Best Practices

1. **Pre-create collections** for organized projects:
   - Use `/api/stac/collections` endpoint or SQL to create collections with proper metadata
   - Then submit jobs with `collection_must_exist: true`

2. **Use `collection_must_exist: true`** in production:
   - Prevents accidental collection creation from typos
   - Enforces catalog organization

3. **Use auto-create only for**:
   - Quick prototyping/testing
   - Ad-hoc analysis where collection metadata isn't critical

### Implementation Location

Collection handling is in:
- `services/stac_catalog.py:355-398` - Checks existence, auto-creates if needed
- `services/raster_stac_collection.py` - Tiled output STAC collection creation

### Future Enhancement Ideas

| Enhancement | Description | Priority |
|-------------|-------------|----------|
| Collection CRUD API | `POST/PUT/DELETE /api/stac/collections` | Medium |
| Collection templates | Pre-defined collection schemas by type | Low |
| Collection validation | Validate collection metadata before job submission | Low |
| Bulk add to collection | Submit multiple rasters to same collection in one job | Medium |

---

## 15. VIEWER URL PATTERNS

### Single COG vs Collection/Tiled Output

The system uses different URL patterns for viewing depending on output mode:

| Output Mode | TiTiler Endpoint | URL Pattern |
|-------------|-----------------|-------------|
| **Single COG** | `/cog/viewer` | `{titiler_base}/cog/viewer?url={cog_url}` |
| **Tiled/Collection** | `/searches/{id}/viewer` | `{titiler_base}/searches/{search_id}/viewer` |

### Single COG URL Generation

For single COG output, TiTiler URLs are generated directly from the COG blob path:

```python
# In jobs/process_raster_docker.py finalize_job():
titiler_urls = config.generate_titiler_urls_unified(
    mode="cog",
    container=cog['cog_container'],
    blob_name=cog['cog_blob']
)
# Returns: {"viewer_url": "{titiler}/cog/viewer?url=..."}
```

**Implementation**: `config/app_config.py` → `generate_titiler_urls_unified()`

### Tiled/Collection URL Generation (pgSTAC Search)

For tiled output (collections), we register a pgSTAC search that treats the collection as a single scene:

```python
# In services/stac_collection.py:
from services.pgstac_search_registration import PgSTACSearchRegistration

search_registrar = PgSTACSearchRegistration()
search_id = search_registrar.register_collection_search(
    collection_id=collection_id,
    metadata={"name": f"{collection_id} mosaic"},
    bbox=collection_bbox
)

# Generate URLs from search_id
urls = search_registrar.get_search_urls(
    search_id=search_id,
    titiler_base_url=config.titiler_base_url,
    assets=["data"]
)
# Returns: {
#     "viewer": "{titiler}/searches/{search_id}/viewer",
#     "tilejson": "{titiler}/searches/{search_id}/WebMercatorQuad/tilejson.json",
#     "tiles": "{titiler}/searches/{search_id}/WebMercatorQuad/tiles/{z}/{x}/{y}"
# }
```

**Implementation**:
- `services/stac_collection.py` → `_create_stac_collection_impl()`
- `services/pgstac_search_registration.py` → `PgSTACSearchRegistration`

### Why pgSTAC Search for Collections?

1. **Dynamic mosaicking**: TiTiler-PgSTAC renders multiple COGs as a single layer
2. **OAuth compatibility**: Search-based URLs work with Managed Identity auth
3. **Automatic updates**: Adding items to collection updates the mosaic (no re-registration)
4. **Deterministic IDs**: `search_id = SHA256(collection_id)` (permanent, no expiry)

### ⚠️ CRITICAL BUG: Missing Import in Tiled Workflow

The tiled workflow in `handler_process_raster_complete.py` has a **broken import**:

```python
# Line 449 - BROKEN IMPORT
from .raster_stac_collection import create_stac_collection  # ❌ File doesn't exist!

# SHOULD BE:
from .stac_collection import create_stac_collection  # ✅ Correct path
```

**Impact**: Tiled workflow fails at Phase 5 (STAC Registration) with `ImportError`.

**Fix Required**:
- [x] Fix import path in `services/handler_process_raster_complete.py:449` ✅ FIXED (24 JAN 2026)
- [ ] Test tiled workflow end-to-end

### URL Examples

**Single COG**:
```
https://rmhtitiler-....azurecontainerapps.io/cog/viewer?url=https://storage.blob.core.windows.net/silver-cogs/flood_depth_cog.tif
```

**Tiled/Collection**:
```
https://rmhtitiler-....azurecontainerapps.io/searches/abc123def456/viewer
```

---

*Document created: 23 JAN 2026*
*Last updated: 24 JAN 2026*
*Author: Claude + Robert Harrison*
