# V0.9 pgSTAC Alignment — Detailed Implementation Tasks

**Created**: 16 FEB 2026
**Updated**: 18 FEB 2026 — Phase 1 COMPLETE, Phase 3 partially done
**Parent**: `V0.9_PGSTAC.md` (analysis + decisions)
**Approach**: Option A — Clean Break
**Status**: IN PROGRESS — Phase 1 COMPLETE

> **Phase 1 (P1.1-P1.9)**: COMPLETE — All model changes implemented.
> `APP_PREFIX`, extension constants, `ProvenanceProperties`, `PlatformProperties` (ddh:*),
> `AppProperties`/`AzureProperties`/`STACItemProperties` deleted. `stac_renders.py` created.
>
> **Phase 3 (partial)**: P3.1 + P3.2 COMPLETE — `pgstac_repository.py` accepts plain dicts.
> P3.3 COMPLETE — B2B queries updated (`platform:*` → `ddh:*`).
>
> **Phase 2**: NOT STARTED — Unified metadata builder, always-on statistics, handler rewrite.
> **Phase 4**: NOT STARTED — Consumer migration, grep sweep, nuke + re-ingest.

---

## Task Naming Convention

`P{phase}.{task}` — e.g., P1.1 = Phase 1, Task 1

Dependencies shown as `BLOCKED_BY: P1.1` — do not start until dependency is complete.

---

## Phase 1: Models + Constants

**Scope**: `core/models/stac.py` — rewrite namespace models to match Epoch 5 patterns.
**Reference**: `rmhdagmaster/core/models/stac_properties.py` (116 lines — the target)
**No other files change in Phase 1** — this is the foundation.

---

### P1.1 — Add APP_PREFIX and Extension URL Constants — COMPLETE

**File**: `core/models/stac.py`
**Action**: Add constants after the existing `STAC_VERSION = "1.0.0"` line.

**Add**:
```python
# App prefix — single point of change (aligned with Epoch 5 rmhdagmaster)
APP_PREFIX = "geoetl"

# STAC Extension URLs (standard extensions used by both Epoch 4 and Epoch 5)
STAC_EXT_PROJECTION = "https://stac-extensions.github.io/projection/v1.0.0/schema.json"
STAC_EXT_RASTER = "https://stac-extensions.github.io/raster/v1.1.0/schema.json"
STAC_EXT_FILE = "https://stac-extensions.github.io/file/v2.1.0/schema.json"
STAC_EXT_RENDER = "https://stac-extensions.github.io/render/v2.0.0/schema.json"
STAC_EXT_PROCESSING = "https://stac-extensions.github.io/processing/v1.2.0/schema.json"
```

**Acceptance Criteria**:
- `APP_PREFIX` is `"geoetl"` (matches Epoch 5)
- All 5 extension URLs match Epoch 5 exactly
- `STAC_VERSION` remains `"1.0.0"` (unchanged)
- Add all new constants to `__all__`

---

### P1.2 — Rewrite PlatformProperties (platform:* → ddh:*) — COMPLETE

**File**: `core/models/stac.py`
**Action**: Replace `PlatformProperties` class entirely.

**Current** (lines 161-251): 6 fields with `platform:*` aliases, `from_platform_refs()` factory, `to_flat_dict()`.

**New** (aligned with Epoch 5 `rmhdagmaster/core/models/stac_properties.py:73-86`):
```python
class PlatformProperties(BaseModel):
    """
    DDH platform identifiers — B2B passthrough.

    Namespace: ddh:*
    These are external identifiers from the upstream platform.
    Always use 'ddh:' prefix (not configurable — it's the platform name).
    """
    model_config = ConfigDict(populate_by_name=True)

    dataset_id: Optional[str] = Field(default=None, alias="ddh:dataset_id")
    resource_id: Optional[str] = Field(default=None, alias="ddh:resource_id")
    version_id: Optional[str] = Field(default=None, alias="ddh:version_id")
    access_level: Optional[str] = Field(default=None, alias="ddh:access_level")
```

**What changes**:
| Current | New | Reason |
|---------|-----|--------|
| `platform:dataset_id` | `ddh:dataset_id` | Epoch 5 namespace |
| `platform:resource_id` | `ddh:resource_id` | Epoch 5 namespace |
| `platform:version_id` | `ddh:version_id` | Epoch 5 namespace |
| `platform:access_level` | `ddh:access_level` | Epoch 5 namespace |
| `platform:request_id` | **DELETED** | Internal, not B2C |
| `platform:client` | **DELETED** | Internal, not B2C |
| `from_platform_refs()` | **DELETED** | Callers will construct directly |
| `to_flat_dict()` | **DELETED** | Use `model_dump(by_alias=True, exclude_none=True)` instead |
| `AccessLevel` enum for access_level | `Optional[str]` | Epoch 5 uses plain string |

**Acceptance Criteria**:
- 4 fields with `ddh:*` aliases
- No `request_id` or `client` fields
- No factory methods — callers construct directly
- Serialization via `model_dump(by_alias=True, exclude_none=True)` (Epoch 5 pattern)
- No `to_flat_dict()` method

---

### P1.3 — Add ProvenanceProperties (new geoetl:* namespace) — COMPLETE

**File**: `core/models/stac.py`
**Action**: Add new class (does not replace anything — `AppProperties` deletion is P1.4).

**New** (aligned with Epoch 5 `rmhdagmaster/core/models/stac_properties.py:39-66`):
```python
class ProvenanceProperties(BaseModel):
    """
    Custom platform provenance properties.

    Namespace: geoetl:* (via APP_PREFIX)
    Only properties that have NO standard STAC extension equivalent.

    Properties:
        job_id: Which processing job created this item
        managed_by: Which system manages this item (multi-producer catalog)
        epoch: Processing system version (internal versioning)
        raster_type: Domain-specific type classification
        processing_seconds: How long processing took
        statistics_extracted: Whether band stats were computed
    """
    model_config = ConfigDict(populate_by_name=True)

    job_id: Optional[str] = Field(default=None)
    managed_by: str = Field(default=APP_PREFIX)  # "geoetl" — the ETL system
    epoch: int = Field(default=4)               # this codebase is Epoch 4
    raster_type: Optional[str] = Field(default=None)
    processing_seconds: Optional[float] = Field(default=None)
    statistics_extracted: Optional[bool] = Field(default=None)

    def to_prefixed_dict(self) -> dict:
        """Serialize with APP_PREFIX, excluding None values."""
        raw = self.model_dump(exclude_none=True)
        return {f"{APP_PREFIX}:{k}": v for k, v in raw.items()}
```

**Key differences from Epoch 5**:
| Field | Epoch 5 | Epoch 4 | Reason |
|-------|---------|---------|--------|
| `managed_by` | `APP_PREFIX` (`"geoetl"`) | `APP_PREFIX` (`"geoetl"`) | Same ETL system |
| `epoch` | `5` | `4` | Distinguishes which ETL version created the item |

**What maps from old AppProperties → ProvenanceProperties**:
| Old (`app:*`) | New (`geoetl:*`) | Notes |
|---------------|-------------------|-------|
| `app:job_id` | `geoetl:job_id` | Renamed |
| `app:created_by` | `geoetl:managed_by` | Concept change: "who created" → "who manages" |
| `app:job_type` | **DELETED** | Not B2C relevant |
| `app:processing_timestamp` | **DELETED** | STAC `datetime` serves this purpose |
| `app:published` | **DELETED** | Not STAC concern (Decision #3) |

**New fields (no Epoch 4 equivalent)**:
| New | Purpose |
|-----|---------|
| `geoetl:epoch` | Distinguish Epoch 4 vs 5 items |
| `geoetl:raster_type` | Was implicit, now explicit |
| `geoetl:processing_seconds` | Performance tracking |
| `geoetl:statistics_extracted` | Was `azure:statistics_extracted` |

**Acceptance Criteria**:
- 6 fields matching Epoch 5 schema
- `managed_by` defaults to `APP_PREFIX` (`"geoetl"`) — the ETL system, not the Azure app
- `epoch` defaults to `4` (not `5`)
- `to_prefixed_dict()` uses `APP_PREFIX` for dynamic namespace
- Serialization excludes None values

---

### P1.4 — Delete AppProperties — COMPLETE

**File**: `core/models/stac.py`
**Action**: Delete the entire `AppProperties` class (lines 254-301).

**Reason**: All useful fields migrated to `ProvenanceProperties` (P1.3). Remaining fields (`job_type`, `processing_timestamp`, `published`) are either deleted or handled elsewhere.

**Acceptance Criteria**:
- `AppProperties` class removed
- Removed from `__all__`
- No references to `app:*` aliases remain in this file

---

### P1.5 — Delete AzureProperties — COMPLETE

**File**: `core/models/stac.py`
**Action**: Delete the entire `AzureProperties` class (lines 344-405).

**What happens to each field**:
| Old (`azure:*`) | Disposition | Notes |
|-----------------|-------------|-------|
| `azure:container` | **DELETED** | Derivable from `/vsiaz/` href |
| `azure:blob_path` | **DELETED** | Derivable from `/vsiaz/` href |
| `azure:tier` | **DELETED** | Internal infrastructure |
| `azure:size_mb` | → `file:size` (bytes) | Standard STAC file extension |
| `azure:statistics_extracted` | → `geoetl:statistics_extracted` | Custom provenance |
| `azure:etag` | **DELETED** | Internal infrastructure |
| `azure:content_type` | → asset `type` field | Standard STAC |

**Acceptance Criteria**:
- `AzureProperties` class removed
- Removed from `__all__`
- No references to `azure:*` aliases remain in this file

---

### P1.6 — Delete STACItemProperties Composite — COMPLETE

**File**: `core/models/stac.py`
**Action**: Delete the entire `STACItemProperties` class (lines 460-584).

**Reason**: This composite model assembled all namespace models into a single `to_flat_dict()`. With the new approach:
- Properties are built as plain dicts in the item builder (Phase 2)
- Each namespace model serializes independently
- No composite needed

**Acceptance Criteria**:
- `STACItemProperties` class removed
- Removed from `__all__`

---

### P1.7 — Keep GeoProperties, PostGISProperties, STACItemCore Unchanged — COMPLETE

**File**: `core/models/stac.py`
**Action**: NO CHANGES to these classes.

| Class | Lines | Why Keep |
|-------|-------|----------|
| `GeoProperties` | 304-341 | B2C relevant — country attribution (Decision #2) |
| `PostGISProperties` | 408-453 | Vector items — unchanged |
| `STACItemCore` | 591-636 | Structural validation — unchanged |

**Also keep unchanged**:
- `AccessLevel` enum (lines 57-113) — used by `promote_service.py`, DDL generation
- `AssetType` enum (lines 116-120) — used elsewhere
- `normalize_access_level()` helper (lines 127-154) — used by services

**Acceptance Criteria**:
- These classes remain exactly as-is
- Their `__all__` exports remain

---

### P1.8 — Update __all__ Exports — COMPLETE

**File**: `core/models/stac.py`
**Action**: Update `__all__` to reflect additions and deletions.

**New `__all__`**:
```python
__all__ = [
    # Constants
    'STAC_VERSION',
    'APP_PREFIX',
    'STAC_EXT_PROJECTION',
    'STAC_EXT_RASTER',
    'STAC_EXT_FILE',
    'STAC_EXT_RENDER',
    'STAC_EXT_PROCESSING',

    # Enums
    'AccessLevel',
    'AssetType',

    # Helpers
    'normalize_access_level',

    # Namespace models
    'ProvenanceProperties',   # NEW (geoetl:*)
    'PlatformProperties',     # REWRITTEN (ddh:*)
    'GeoProperties',          # UNCHANGED (geo:*)
    'PostGISProperties',      # UNCHANGED (postgis:*)

    # Structural validation
    'STACItemCore',           # UNCHANGED
]
```

**Removed from exports**:
- `AppProperties` (deleted in P1.4)
- `AzureProperties` (deleted in P1.5)
- `STACItemProperties` (deleted in P1.6)

**Acceptance Criteria**:
- All new symbols exported
- All deleted symbols removed
- File header updated with new date and description

---

### P1.9 — Update File Header and Docstring — COMPLETE

**File**: `core/models/stac.py`
**Action**: Update the file header block and module docstring.

**New header**:
```python
# ============================================================================
# STAC DATA MODELS
# ============================================================================
# EPOCH: 4 - ACTIVE (Aligned with Epoch 5 patterns)
# STATUS: Core - Centralized STAC property schemas
# PURPOSE: Type-safe Pydantic models for STAC property namespaces
# LAST_REVIEWED: 16 FEB 2026
# ============================================================================
```

**New docstring** should list:
- `geoetl:*` — Platform provenance (via APP_PREFIX)
- `ddh:*` — DDH platform identifiers (B2B passthrough)
- `geo:*` — Geographic attribution (ISO3 codes)
- `postgis:*` — PostGIS vector table metadata
- Extension URL constants

Remove mentions of `platform:*`, `app:*`, `azure:*` from the docstring.

**Acceptance Criteria**:
- Header reflects Epoch 5 alignment
- Docstring lists only the surviving/new namespaces
- `LAST_REVIEWED` updated to `16 FEB 2026`

---

## Phase 1 Validation — PASSED

After completing P1.1–P1.9, the file should:

1. **Have these classes**: `ProvenanceProperties`, `PlatformProperties`, `GeoProperties`, `PostGISProperties`, `STACItemCore`, `AccessLevel`, `AssetType`
2. **NOT have these classes**: `AppProperties`, `AzureProperties`, `STACItemProperties`
3. **Have these constants**: `STAC_VERSION`, `APP_PREFIX`, `STAC_EXT_PROJECTION`, `STAC_EXT_RASTER`, `STAC_EXT_FILE`, `STAC_EXT_RENDER`, `STAC_EXT_PROCESSING`
4. **Import cleanly**: `python -c "from core.models.stac import *"` should succeed
5. **Match Epoch 5**: `ProvenanceProperties` and `PlatformProperties` should be structurally identical to `rmhdagmaster/core/models/stac_properties.py` (same `managed_by` default, `epoch=4` instead of `5`)

**WARNING**: After Phase 1, the codebase **WILL NOT RUN**. ~25 files import deleted classes. This is expected — Phases 2-4 fix consumers.

---

## Phase 2: Unified Metadata → STAC (Canonical Builder)

**BLOCKED_BY**: Phase 1 complete
**Architecture**: `extract_item_from_blob()` extracts metadata → stores in `app.cog_metadata` → `RasterMetadata.to_stac_item()` is the single canonical STAC builder for both initial creation and rebuild.
**Key Principle**: "item analysis → geoetl's central metadata records → STAC materialized view"

**Key Files**:
- `core/models/unified_metadata.py` — `RasterMetadata.to_stac_item()` (the canonical builder, lines 1348-1545)
- `core/models/raster_metadata.py` — `CogMetadataRecord` (DDL model, 39 columns)
- `infrastructure/raster_metadata_repository.py` — `RasterMetadataRepository.upsert()` (CRUD)
- `services/service_stac_metadata.py` — `extract_item_from_blob()` (extraction engine)
- `services/stac_metadata_helper.py` — `STACMetadataHelper` (TiTiler URL generation)
- `services/handler_process_raster_complete.py` — Phase 3a upsert call (lines 2064-2096)

**Reference** (Epoch 5):
- `rmhdagmaster/handlers/raster/stac.py` (lines 443-629 — target item builder)
- `rmhdagmaster/handlers/raster/statistics.py` (lines 182-361 — renders builder)

**Current state** (as of 16 FEB 2026):
- `app.cog_metadata` table exists with 39 columns including bbox, resolution, transform, raster_bands, colormap, rescale_range
- `RasterMetadataRepository.upsert()` is called in the pipeline but only populates ~10 of 39 fields
- `RasterMetadata.to_stac_item()` works (used by rebuild_stac_handlers) but has wrong patterns (HTTPS URLs, wrong extension versions, no geoetl:/ddh: namespaces)
- `extract_item_from_blob()` builds STAC items directly instead of populating metadata first
- Band statistics are skipped for files >1GB (incorrect — always extract from mounted filestore)

---

### P2.1 — Create Renders Builder Module

**File**: NEW `services/stac_renders.py`
**Action**: Port `_build_renders()` and helpers from Epoch 5.
**Reference**: `rmhdagmaster/handlers/raster/statistics.py` (lines 182-361)
**BLOCKED_BY**: P1.1 (needs APP_PREFIX)

**Port these functions**:
- `_build_renders(raster_type, band_count, dtype, band_stats, rgb_bands)` → `Optional[Dict]`
- `_get_single_band_rescale(band_stats, raster_type)` → `Optional[List]`
- `_recommend_colormap(raster_type)` → `Optional[str]`
- `_recommend_rgb_bands(band_count)` → `Optional[List[int]]`
- `COLORMAPS` dict constant

**Acceptance Criteria**:
- All 4 functions ported from Epoch 5
- Colormap lookup table includes all Epoch 5 entries: dem→terrain, categorical→tab20, flood_depth→blues, flood_probability→reds, vegetation_index→rdylgn, population→ylorrd, continuous→viridis
- RGB band recommendation: WorldView [5,3,2], Sentinel [4,3,2], default [1,2,3]
- Returns dict matching STAC Renders Extension v2.0.0 schema
- Pure functions — no IO, no imports beyond typing

---

### P2.2 — Always Extract Band Statistics (Remove Size Gate)

**File**: `services/service_stac_metadata.py`
**Action**: Remove the 1GB size gate that skips band statistics extraction.
**BLOCKED_BY**: P1.1

**Current behavior** (Step D, ~line 140):
- Files >1GB: skip statistics, `statistics_extracted = False`
- Epoch 5 `handlers/raster/statistics.py` line 86: same `SIZE_THRESHOLD_MB = 1000`

**New behavior**:
- **Always extract** band count, dtype, nodata, and full raster:bands statistics
- Reading from mounted Azure File Share, not over the network — timeout concern is greatly reduced
- Add `skip_stats` parameter override for edge cases (e.g., known-good data or testing)
- Remove `SIZE_THRESHOLD_MB` constant

**Rationale** (from Robert): "We want full raster statistics regardless of size — we are reading from mounted filestore. Statistics always extracted with parameter skip_stats override option."

**Acceptance Criteria**:
- Band statistics extracted for ALL files regardless of size (default behavior)
- `skip_stats: bool = False` parameter on extraction method for override
- `geoetl:statistics_extracted` reflects actual extraction (always True unless skip_stats=True)
- Pixel inspection (band_count, dtype) always happens regardless of skip_stats

---

### P2.3 — Enrich cog_metadata Upsert (Store ALL Metadata)

**File**: `services/handler_process_raster_complete.py`
**Action**: Populate all available fields in `cog_repo.upsert()` call (currently only ~10 of 39 columns).
**BLOCKED_BY**: P2.2 (needs statistics to always be available)

**Current upsert** (lines 2071-2085) stores:
```
cog_id, container, blob_path, cog_url, band_count, dtype, nodata, crs,
is_cog, stac_item_id, stac_collection_id, etl_job_id, source_file
```

**New upsert** must also store:
| Field | Source | Notes |
|-------|--------|-------|
| `width`, `height` | rasterio `src.width`, `src.height` | Required by DDL model |
| `transform` | rasterio affine transform | `[a, b, c, d, e, f]` as JSONB |
| `resolution` | rasterio `src.res` | `[x_res, y_res]` as JSONB |
| `bbox_minx/miny/maxx/maxy` | rasterio `src.bounds` | For fast spatial queries |
| `raster_bands` | Band statistics from P2.2 | `raster:bands[]` per STAC raster extension |
| `colormap` | From renders builder (P2.1) | Default colormap name |
| `rescale_range` | From renders builder (P2.1) | `[min, max]` rescale |
| `compression` | rasterio `src.profile['compress']` | DEFLATE, LZW, etc. |
| `blocksize` | rasterio `src.profile['blockxsize']` | Internal tile size |
| `overview_levels` | rasterio `src.overviews(1)` | COG overview levels |
| `raster_type` | via `custom_properties` | From validation handler (dem, rgb, etc.) |

**The `cog_url` should use `/vsiaz/` format**, not HTTPS:
```python
# OLD
cog_url = f"https://{config.storage.silver.account_name}.blob.core.windows.net/{cog_container}/{cog_blob}"
# NEW
cog_url = f"/vsiaz/{cog_container}/{cog_blob}"
```

**Acceptance Criteria**:
- All rasterio-available metadata stored in cog_metadata
- Band statistics stored in `raster_bands` column as JSONB
- `cog_url` uses `/vsiaz/` format (not HTTPS)
- Bbox populated for spatial queries
- Width/height populated (required by DDL model)
- Render-related fields (colormap, rescale_range) populated from renders builder

---

### P2.4 — Align RasterMetadata.to_stac_item() with Epoch 5

**File**: `core/models/unified_metadata.py`
**Action**: Rewrite `to_stac_item()` (lines 1348-1545) to match Epoch 5 patterns.
**BLOCKED_BY**: P1.1, P1.2, P1.3, P2.1
**Reference**: `rmhdagmaster/handlers/raster/stac.py:443-629`

**This is the canonical STAC builder** — used by both initial creation AND rebuild.

**Current issues in `to_stac_item()` and fixes**:

| Issue | Current (line) | Fix |
|-------|---------------|-----|
| Asset href | HTTPS URL (line 1488) | `/vsiaz/{container}/{blob_path}` |
| `raster:bands` location | In properties as `raster:bands_count` (line 1429) | On **asset** as `raster:bands[]` array |
| `raster:dtype` | In properties (line 1431) | **Delete** — dtype is per-band in `raster:bands[].data_type` |
| Render extension URL | `v1.0.0` (line 1454) | `v2.0.0` (use `STAC_EXT_RENDER` constant) |
| Processing extension URL | `v1.1.0` (line 1447) | `v1.2.0` (use `STAC_EXT_PROCESSING` constant) |
| Extension URLs | Hardcoded strings | Use constants from `core/models/stac.py` |
| Custom namespaces | None | Add `geoetl:*` and `ddh:*` properties |
| TiTiler thumbnail | Uses HTTPS URL + custom params (line 1521) | Build from `renders.default` parameters |
| `processing:lineage` | `f"ETL job {self.etl_job_id}"` (line 1439) | `f"Processed by {APP_PREFIX} epoch {epoch}"` |
| `processing:source_file` | Custom (line 1441) | **Delete** — not a standard processing extension field |

**New `to_stac_item()` signature**:
```python
def to_stac_item(
    self,
    base_url: str,
    provenance_props: Optional['ProvenanceProperties'] = None,
    platform_props: Optional['PlatformProperties'] = None,
    geo_props: Optional['GeoProperties'] = None,
    titiler_base_url: Optional[str] = None,
    renders: Optional[Dict[str, Dict[str, Any]]] = None,
) -> Dict[str, Any]:
```

**New properties construction** (matching Epoch 5 `_build_stac_item()`):
```python
properties = {
    "datetime": ...,  # existing logic
    "title": self.title,
    # proj:* extension
    "proj:epsg": ...,  # existing logic
    "proj:transform": self.transform,
    # processing:* extension
    "processing:lineage": f"Processed by {APP_PREFIX} epoch {provenance_props.epoch}",
    # file:* extension
    "file:size": ...,  # bytes
    # geoetl:* custom namespace
    **provenance_props.to_prefixed_dict(),
    # ddh:* B2B passthrough
    **platform_props.model_dump(by_alias=True, exclude_none=True),
    # geo:* geographic attribution
    **geo_props.to_flat_dict(),
}
# Conditionally add renders to properties
if renders:
    properties["renders"] = renders
```

**New asset construction**:
```python
cog_asset = {
    "href": f"/vsiaz/{self.container}/{self.blob_path}",
    "type": "image/tiff; application=geotiff; profile=cloud-optimized",
    "title": "Cloud-optimized GeoTIFF",
    "roles": ["data"],
}
# raster:bands on ASSET (not in properties)
if self.raster_bands:
    cog_asset["raster:bands"] = self.raster_bands
```

**Acceptance Criteria**:
- Output matches Epoch 5 target JSON structure (Section 3 of `V0.9_PGSTAC.md`)
- Asset href always `/vsiaz/{container}/{blob_path}`
- `raster:bands[]` on asset, not in properties
- Extension URLs use constants (`STAC_EXT_*`)
- `geoetl:*` and `ddh:*` namespaces present
- No `app:*`, `azure:*`, or `platform:*` properties
- `renders` in properties when provided
- Returns plain dict

---

### P2.5 — Refactor extract_item_from_blob() to Metadata Extractor

**File**: `services/service_stac_metadata.py`
**Action**: Refactor from "STAC item builder" to "metadata extractor that populates cog_metadata".
**BLOCKED_BY**: P2.3, P2.4

**Current flow** (Steps A-I): Extracts metadata AND builds STAC item inline.

**New flow**:
```
extract_item_from_blob()
  → A: Generate SAS URL (KEEP — needed for rasterio access)
  → B: Determine datetime (KEEP)
  → C: Determine item ID (KEEP)
  → D: Open rasterio, extract ALL metadata (no size gate)
  → E: rio-stac for geometry/bbox/proj (KEEP)
  → F: Extract band statistics (ALWAYS, from P2.2)
  → G: Build renders via renders builder (P2.1)
  → H: Populate RasterMetadata domain model
  → I: Call RasterMetadata.to_stac_item() for STAC output
  → DELETE: Steps for azure:*, app:*, stac-pydantic validation
```

**Key change**: The method no longer constructs STAC items directly. It:
1. Extracts all raster metadata via rasterio + rio-stac
2. Populates/updates the `RasterMetadata` domain model
3. Delegates STAC construction to `RasterMetadata.to_stac_item()`

**New return**: Still returns a dict (STAC item), but produced by `to_stac_item()`.

**Acceptance Criteria**:
- Metadata extraction (rasterio, rio-stac) still happens here
- STAC item construction delegated to `RasterMetadata.to_stac_item()`
- No inline STAC property construction (Steps G.1, G.2, H deleted)
- Returns plain dict (not stac-pydantic Item)
- No stac-pydantic imports (`from stac_pydantic import Item` removed)

---

### P2.6 — Rewrite STACMetadataHelper (TiTiler URLs from Renders)

**File**: `services/stac_metadata_helper.py`
**Action**: Rewrite `augment_item()` and TiTiler URL generation. Delete old dataclasses.
**BLOCKED_BY**: P2.1, P1.2, P1.3

**Delete these dataclasses**:
- `PlatformMetadata` (replaced by `PlatformProperties` Pydantic model)
- `AppMetadata` (replaced by `ProvenanceProperties` Pydantic model)
- `RasterVisualizationMetadata` (replaced by renders builder)

**Keep and rewrite**:
- `augment_item()` — now enriches plain dict items (not stac-pydantic objects)
- `_build_titiler_url_params()` — reads from `properties.renders.default` instead of custom `app:*` props:
  ```python
  # OLD: reads app:rescale, app:colormap, app:rgb_bands
  # NEW: reads renders.default.rescale, renders.default.colormap_name, renders.default.bidx
  renders_default = item.get("properties", {}).get("renders", {}).get("default", {})
  colormap = renders_default.get("colormap_name")
  rescale = renders_default.get("rescale")
  bidx = renders_default.get("bidx")
  ```
- `build_titiler_links_cog()` — same interface, reads renders
- `build_titiler_links_pgstac()` — generates TiTiler links for collections via search registration
- `augment_collection()` — update `platform:*` → `ddh:*`

**Acceptance Criteria**:
- Old dataclasses deleted
- `augment_item()` accepts and returns plain dict
- TiTiler URL generation reads from `properties.renders.default`
- No `app:*` or `platform:*` property references
- TiTiler links are the B2B deliverable — must be correct and complete

---

### P2.7 — Update handler_process_raster_complete.py Flow

**File**: `services/handler_process_raster_complete.py`
**Action**: Reorder phases so metadata is stored BEFORE STAC is built.
**BLOCKED_BY**: P2.3, P2.5

**Current phase order**:
```
Phase 1: Upload COG
Phase 2: Extract STAC (calls extract_item_from_blob → builds STAC inline)
Phase 3: Persist metadata (cog_metadata.upsert — partial data)
Phase 4: Insert STAC into pgstac
```

**New phase order**:
```
Phase 1: Upload COG
Phase 2: Extract metadata (calls extract_item_from_blob → populates RasterMetadata)
Phase 3: Persist metadata (cog_metadata.upsert — ALL data from P2.3)
Phase 4: Build STAC from metadata (RasterMetadata.to_stac_item)
Phase 5: Insert STAC into pgstac
```

**Key change**: Phase 3 (metadata persist) happens BEFORE STAC construction, and STAC is built FROM stored metadata, not built inline and then metadata stored as an afterthought.

**Acceptance Criteria**:
- Metadata fully persisted before STAC item is built
- STAC item produced by `RasterMetadata.to_stac_item()`, not inline construction
- `cog_metadata.upsert()` includes all fields from P2.3
- ProvenanceProperties constructed with `job_id`, `epoch=4`, `raster_type`
- PlatformProperties constructed with `ddh:*` fields from job params
- GeoProperties constructed if country/region info available
- Renders built from band statistics via renders builder (P2.1)

---

## Phase 2 Validation

After completing P2.1–P2.7:

1. **Single STAC builder**: All STAC items produced by `RasterMetadata.to_stac_item()` — both initial creation and rebuild use the same path
2. **Unified metadata populated**: `app.cog_metadata` contains all 39 fields (not just 10)
3. **Statistics always extracted**: No size gate — band statistics available for all files
4. **TiTiler URLs work**: Built from `renders.default` parameters, correct for B2B delivery
5. **No stale namespaces**: No `app:*`, `azure:*`, or `platform:*` in STAC output
6. **Asset hrefs correct**: All use `/vsiaz/` format

---

## Phase 3: Infrastructure

**BLOCKED_BY**: Phase 1 complete
**Scope**: `infrastructure/pgstac_repository.py` — accept plain dicts, update B2B queries

---

### P3.1 — Accept Plain Dicts in insert_item() — COMPLETE

**File**: `infrastructure/pgstac_repository.py`
**Action**: Update `insert_item()` to accept `dict` alongside pystac/stac-pydantic.
**BLOCKED_BY**: P1.1

**Current** (line 237): Rejects anything that isn't `pystac.Item` or `StacPydanticItem`.

**New**: Accept `dict` as primary type. Keep pystac/stac-pydantic acceptance for backward compat during migration.

```python
def insert_item(self, item, collection_id: str) -> str:
    # Accept dict (Epoch 5 pattern), pystac.Item, or stac_pydantic.Item
    if isinstance(item, dict):
        item_dict = item
    elif hasattr(item, 'model_dump'):
        item_dict = item.model_dump(mode='json', by_alias=True)
    elif hasattr(item, 'to_dict'):
        item_dict = item.to_dict()
    else:
        raise ValueError(f"Expected dict, pystac.Item, or stac_pydantic.Item, got {type(item).__name__}")
    ...
```

**Acceptance Criteria**:
- `insert_item(plain_dict, collection_id)` works
- Existing pystac/stac-pydantic callers still work (until Phase 4 migrates them)

---

### P3.2 — Accept Plain Dicts in insert_collection() — COMPLETE

**File**: `infrastructure/pgstac_repository.py`
**Action**: Same as P3.1 but for `insert_collection()`.
**BLOCKED_BY**: P1.1

**Current** (line 90): Only accepts `pystac.Collection`.

**New**: Accept `dict` as primary, keep pystac for backward compat.

**Acceptance Criteria**:
- `insert_collection(plain_dict)` works
- Collection dict must have `"id"` key

---

### P3.3 — Update B2B Queries (platform:* → ddh:*) — COMPLETE

**File**: `infrastructure/pgstac_repository.py`
**Action**: Update JSONB queries in `search_by_platform_ids()` and `get_items_by_platform_dataset()`.
**BLOCKED_BY**: P1.2

**Changes**:

`search_by_platform_ids()` (line 598):
```python
# OLD
json.dumps({"platform:dataset_id": dataset_id, "platform:resource_id": resource_id, "platform:version_id": version_id})
# NEW
json.dumps({"ddh:dataset_id": dataset_id, "ddh:resource_id": resource_id, "ddh:version_id": version_id})
```

`get_items_by_platform_dataset()` (line 662):
```python
# OLD
WHERE content->'properties'->>'platform:dataset_id' = %s
# NEW
WHERE content->'properties'->>'ddh:dataset_id' = %s
```

**Acceptance Criteria**:
- All `platform:*` JSONB references replaced with `ddh:*`
- Both methods updated atomically

---

## Phase 4: Consumers + Cleanup

**BLOCKED_BY**: Phase 2 and Phase 3 complete
**Scope**: Update all files that import deleted/changed models

---

### P4.1 — Update Approval Service (Remove app:published)

**File**: `services/asset_approval_service.py`
**Action**: Remove all `app:published`, `app:published_at`, `app:approved_by`, `app:clearance`, `app:revoked`, `app:revoked_at`, `app:revoked_by`, `app:revocation_reason` property updates from STAC items.
**BLOCKED_BY**: P2.5

**Current** (lines 431-436): Writes `app:published=True` to STAC item properties.
**Current** (lines 485-490): Writes `app:revoked=True` to STAC item properties.

**New**: Approval/revocation state managed ONLY in `app.geospatial_assets` table. No STAC item property updates for approval.

Delete methods:
- `_update_stac_published()` (or remove STAC update logic from it)
- `_update_stac_revoked()` (or remove STAC update logic from it)

**Acceptance Criteria**:
- No `app:published` writes to STAC items
- Approval state tracked in app schema only
- Method still updates `geospatial_assets` table (that part stays)

---

### P4.2 — Update QA Viewer (Remove app:qa_status)

**File**: `raster_collection_viewer/triggers.py`
**Action**: Remove `app:qa_status` and `app:qa_updated` STAC property updates (line 194).
**BLOCKED_BY**: P2.5

**Also update**: `raster_collection_viewer/service.py` — JS references to `app:qa_status` (lines 1339, 1372).

**Decision needed**: Should QA status move to `app.geospatial_assets` table too, or use a `geoetl:qa_status`?

**Acceptance Criteria**:
- No `app:qa_status` writes to STAC items
- Viewer still functions (reads QA status from alternative source)

---

### P4.3 — Update stac_collection.py

**File**: `services/stac_collection.py`
**Action**: Update imports from old dataclasses to new Pydantic models.
**BLOCKED_BY**: P2.6

**Current imports**: `RasterVisualizationMetadata`, `AppMetadata` from `stac_metadata_helper.py`
**New imports**: `ProvenanceProperties`, `PlatformProperties` from `core/models/stac.py`

**Acceptance Criteria**:
- No imports of deleted dataclasses
- Collection creation uses new property models

---

### P4.4 — Update stac_catalog.py

**File**: `services/stac_catalog.py`
**Action**: Update imports from old dataclasses to new Pydantic models.
**BLOCKED_BY**: P2.6

**Current imports**: `PlatformMetadata`, `AppMetadata`, `RasterVisualizationMetadata`
**New imports**: `ProvenanceProperties`, `PlatformProperties`

**Acceptance Criteria**:
- No imports of deleted dataclasses
- Catalog creation uses new property models

---

### P4.5 — Update handler_process_raster_complete.py (Consumer Side)

**File**: `services/handler_process_raster_complete.py`
**Action**: Update call to `StacMetadataService.extract_item_from_blob()` with new params.
**BLOCKED_BY**: P2.7

**Changes**:
- Construct `ProvenanceProperties` instead of `AppMetadata`
- Construct `PlatformProperties` (ddh:*) instead of `PlatformMetadata`
- Remove `RasterVisualizationMetadata` param
- Handle plain dict return instead of stac-pydantic Item

**Acceptance Criteria**:
- Calls use new param names and types
- Handles dict return value

---

### P4.6 — Update ingest/handler_register.py

**File**: `services/ingest/handler_register.py`
**Action**: Same as P4.5 — update item builder calls.
**BLOCKED_BY**: P2.5

**Acceptance Criteria**:
- Same as P4.5

---

### P4.7 — Update service_stac_vector.py

**File**: `services/service_stac_vector.py`
**Action**: Update `STACMetadataHelper` usage to new interface.
**BLOCKED_BY**: P2.6

**Keep**: `postgis:*` properties — these are correct and unchanged.
**Update**: Base STAC item structure to match Epoch 5 (stac_extensions, no app:*, no azure:*).

**Acceptance Criteria**:
- Vector items use same `stac_extensions` list
- No `app:*` or `azure:*` properties
- `postgis:*` and `geo:*` properties preserved

---

### P4.8 — Update Trigger Files

**Files**:
- `triggers/stac_extract.py` — calls `StacMetadataService`
- `triggers/stac/stac_bp.py` — STAC API responses
- `triggers/platform/unpublish.py` — uses `PgStacRepository`
- `triggers/trigger_platform_catalog.py` — uses `PgStacRepository`
- `triggers/jobs/resubmit.py` — deletes STAC items
- `triggers/jobs/delete.py` — deletes STAC items
- `triggers/trigger_approvals.py` — references `app:published`
- `triggers/admin/admin_approvals.py` — references `app:published`
**BLOCKED_BY**: P2.5, P3.1, P4.1

**Action**: Update each file to:
- Use new param types when calling item builder
- Remove `app:published` references in approval triggers
- Handle dict returns from item builder

**Acceptance Criteria**:
- No imports of deleted classes
- No `app:*` or `platform:*` property references (except in comments explaining migration)
- All triggers compile and route correctly

---

### P4.9 — Update jobs/unpublish_raster.py

**File**: `jobs/unpublish_raster.py`
**Action**: Remove `app:job_id` and `app:job_type` property reads.
**BLOCKED_BY**: P1.3, P1.4

**Current**: Reads `app:job_id` and `app:job_type` from STAC item properties.
**New**: Read `geoetl:job_id` (no job_type equivalent — if needed, query from app schema).

**Acceptance Criteria**:
- Reads `geoetl:job_id` instead of `app:job_id`
- No `app:*` property references

---

### P4.10 — Update platform_catalog_service.py and orphan_blob_handlers.py

**Files**: `services/platform_catalog_service.py`, `services/orphan_blob_handlers.py`
**Action**: Update any `platform:*` property references to `ddh:*`.
**BLOCKED_BY**: P3.3

**Acceptance Criteria**:
- All `platform:*` → `ddh:*` in JSONB queries and property access

---

### P4.11 — Update DuckDB Queries

**File**: `infrastructure/duckdb_query.py`
**Action**: Update any `platform:` or `app:` property references in DuckDB query generation.
**BLOCKED_BY**: P1.2, P1.4

**Acceptance Criteria**:
- DuckDB queries reference `ddh:*` and `geoetl:*` instead of `platform:*` and `app:*`

---

### P4.12 — Update rebuild_stac_handlers.py

**File**: `services/rebuild_stac_handlers.py`
**Action**: Update `rebuild_raster_stac_item()` to pass new property models to `RasterMetadata.to_stac_item()`.
**BLOCKED_BY**: P2.4

**Current** (line 460): Calls `raster_meta.to_stac_item()` with old signature.
**New**: Pass `provenance_props`, `platform_props`, `geo_props`, `renders` to the aligned `to_stac_item()`.

**Acceptance Criteria**:
- Rebuild path produces identical STAC items to initial creation path
- Both paths use `RasterMetadata.to_stac_item()` with same parameters

---

### P4.13 — Grep Sweep for Stale References

**Action**: Run codebase-wide grep for any remaining references to deleted property names.
**BLOCKED_BY**: All P4.x tasks complete

**Search patterns**:
```
"platform:dataset_id"    → should be "ddh:dataset_id"
"platform:resource_id"   → should be "ddh:resource_id"
"platform:version_id"    → should be "ddh:version_id"
"platform:access_level"  → should be "ddh:access_level"
"platform:request_id"    → should not exist
"platform:client"        → should not exist
"app:job_id"             → should be "geoetl:job_id"
"app:job_type"           → should not exist
"app:created_by"         → should be "geoetl:managed_by"
"app:published"          → should not exist
"app:processing_timestamp" → should not exist
"azure:container"        → should not exist
"azure:blob_path"        → should not exist
"azure:tier"             → should not exist
"azure:size_mb"          → should not exist
"azure:statistics_extracted" → should not exist
"azure:etag"             → should not exist
"azure:content_type"     → should not exist
AppProperties            → should not exist (except in archive)
AzureProperties          → should not exist (except in archive)
STACItemProperties       → should not exist (except in archive)
PlatformMetadata         → should not exist (except in archive)
AppMetadata              → should not exist (except in archive)
RasterVisualizationMetadata → should not exist (except in archive)
```

**Exclude**: `docs/archive/`, `V0.9_PGSTAC*.md`, `docs_claude/HISTORY.md`, `docs_claude/COMPLETED_*.md`

**Acceptance Criteria**:
- Zero matches in active code (non-archive, non-docs)

---

### P4.14 — Nuke and Re-ingest

**Action**: Clear pgstac and re-ingest test data.
**BLOCKED_BY**: P4.13

**Steps**:
1. `POST /api/dbadmin/maintenance?action=rebuild&target=pgstac&confirm=yes`
2. Submit test raster job to verify new STAC item structure
3. Verify item in pgstac matches Epoch 5 target JSON structure
4. Verify TiTiler can render the item using `properties.renders`

**Acceptance Criteria**:
- pgstac clean
- New items match Epoch 5 structure
- TiTiler renders work
- B2B lookup via `ddh:dataset_id` works

---

## Summary

| Phase | Tasks | Scope | Key Change | Status |
|-------|-------|-------|------------|--------|
| **1: Models** | P1.1–P1.9 | `core/models/stac.py` only | Namespace alignment | **COMPLETE** |
| **2: Unified Metadata → STAC** | P2.1–P2.7 | unified_metadata, service_stac_metadata, stac_metadata_helper, handler_process_raster_complete, new stac_renders | Canonical builder via `RasterMetadata.to_stac_item()`, always-on statistics, full cog_metadata | NOT STARTED |
| **3: Infrastructure** | P3.1–P3.3 | `infrastructure/pgstac_repository.py` only | Plain dicts + ddh:* queries | **COMPLETE** |
| **4: Consumers** | P4.1–P4.14 | ~15 consumer files + grep sweep + re-ingest | Wire everything together | NOT STARTED |

**Total**: 33 tasks across 4 phases.

**Architecture after completion**:
```
Raster Processing (Docker Worker)
  → rasterio + rio-stac extract ALL metadata (band stats always)
  → Renders builder produces visualization config
  → app.cog_metadata stores EVERYTHING (39 columns, source of truth)
  → RasterMetadata.to_stac_item() builds STAC from stored metadata
  → pgstac receives clean, Epoch 5-aligned STAC items
  → TiTiler reads renders.default for visualization
  → B2B app receives TiTiler URLs as deliverables
```
