# Data-Behavior Separation Architecture

**Date**: 1 OCT 2025
**Author**: Robert and Geospatial Claude Legion

## ðŸŽ¯ Core Principle: Composition over Inheritance

The "Task" and "Job" conceptual entities are **NOT represented by single classes**.
Instead, they emerge from the **collaboration between DATA and BEHAVIOR components**.

## Two Orthogonal Concerns

### 1. DATA (What entities ARE)
- **Pydantic Models** - Define structure, validation, serialization
- **Base Contracts** - TaskData, JobData (core/contracts/)
- **Boundary Specializations** - Add boundary-specific fields
  - Database: TaskRecord, JobRecord (core/models/)
  - Queue: TaskQueueMessage, JobQueueMessage (core/schema/)

### 2. BEHAVIOR (What entities DO)
- **Abstract Base Classes** - Define execution contracts
- **TaskExecutor** (services/task.py) - Task business logic
- **Workflow** (services/workflow.py) - Job orchestration logic

## Why Keep Them Separate?

âœ… **Flexibility**: Swap data format without touching business logic
âœ… **Testability**: Test behavior without database/queue infrastructure
âœ… **Single Responsibility**: Data structure changes don't affect behavior
âœ… **Boundary Crossing**: Data models cross boundaries, behavior stays internal

âŒ **Anti-pattern**: `class Task(BaseModel, ABC)` - Mixing concerns creates tight coupling

## The Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CONCEPTUAL ENTITIES                             â”‚
â”‚                                                                      â”‚
â”‚  "Task" Entity = TaskData + TaskExecutor (Composition)              â”‚
â”‚  "Job" Entity  = JobData  + Workflow     (Composition)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DATA (Pydantic)       â”‚         â”‚   BEHAVIOR (ABC)                â”‚
â”‚                         â”‚         â”‚                                 â”‚
â”‚   TaskData              â”‚         â”‚   TaskExecutor                  â”‚
â”‚   (core/contracts)      â”‚         â”‚   (services/task.py)            â”‚
â”‚   â”œâ”€ task_id            â”‚         â”‚   â””â”€ execute(params) -> result  â”‚
â”‚   â”œâ”€ parent_job_id      â”‚         â”‚                                 â”‚
â”‚   â”œâ”€ job_type           â”‚         â”‚   Workflow                      â”‚
â”‚   â”œâ”€ task_type â†â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â†’ (services/workflow.py)        â”‚
â”‚   â”œâ”€ stage              â”‚  LINK   â”‚   â””â”€ define_stages() -> [Stage] â”‚
â”‚   â”œâ”€ task_index         â”‚         â”‚                                 â”‚
â”‚   â””â”€ parameters         â”‚         â”‚                                 â”‚
â”‚        â†“                â”‚         â”‚                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚         â”‚                                 â”‚
â”‚   â”‚ Boundaries:  â”‚      â”‚         â”‚                                 â”‚
â”‚   â”œâ”€ TaskRecord  â”‚      â”‚         â”‚                                 â”‚
â”‚   â”‚   (Database) â”‚      â”‚         â”‚                                 â”‚
â”‚   â”‚   +status    â”‚      â”‚         â”‚                                 â”‚
â”‚   â”‚   +result    â”‚      â”‚         â”‚                                 â”‚
â”‚   â”‚   +timestampsâ”‚      â”‚         â”‚                                 â”‚
â”‚   â”‚              â”‚      â”‚         â”‚                                 â”‚
â”‚   â””â”€ TaskQueue   â”‚      â”‚         â”‚                                 â”‚
â”‚      Message     â”‚      â”‚         â”‚                                 â”‚
â”‚      (Queue)     â”‚      â”‚         â”‚                                 â”‚
â”‚      +retry_countâ”‚      â”‚         â”‚                                 â”‚
â”‚      +timestamp  â”‚      â”‚         â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                      â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   COMPOSITION LAYER   â”‚
            â”‚   (Brings them together) â”‚
            â”‚                       â”‚
            â”‚   CoreMachine         â”‚
            â”‚   TaskExecutionServiceâ”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## The Link: task_type Field

The `task_type` field in TaskData is the **bridge** connecting data to behavior:

```python
# 1. Data knows WHAT task to execute
task_record = TaskRecord(
    task_type="validate_raster",  # â† The link
    parameters={"file": "raster.tif"}
)

# 2. Registry maps task_type to behavior
TASK_REGISTRY = {
    "validate_raster": ValidateRasterTaskExecutor,
    "generate_tiles": GenerateTilesTaskExecutor,
}

# 3. Composition brings them together
executor_class = TASK_REGISTRY[task_record.task_type]
executor = executor_class()
result = executor.execute(task_record.parameters)
```

## Hierarchy Details

### Task Hierarchy

```
TaskData (BaseModel)
  â”œâ”€ task_id: str
  â”œâ”€ parent_job_id: str
  â”œâ”€ job_type: str
  â”œâ”€ task_type: str
  â”œâ”€ stage: int
  â”œâ”€ task_index: str
  â””â”€ parameters: dict
       â†“ inherits
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
  â”‚          â”‚
TaskRecord  TaskQueueMessage
(Database)  (Queue)
  â”‚          â”‚
  +status    +retry_count
  +result    +timestamp
  +metadata  +parent_task_id
  +error
  +heartbeat
  +timestamps
```

### Job Hierarchy

```
JobData (BaseModel)
  â”œâ”€ job_id: str (SHA256)
  â”œâ”€ job_type: str
  â””â”€ parameters: dict
       â†“ inherits
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
  â”‚          â”‚
JobRecord   JobQueueMessage
(Database)  (Queue)
  â”‚          â”‚
  +status    +stage
  +stage     +stage_results
  +total_stages +retry_count
  +stage_results +timestamp
  +metadata
  +result
  +error
  +timestamps
```

## Real-World Example: Task Execution

```python
# ============================================================================
# STEP 1: Queue message arrives (DATA in motion)
# ============================================================================
queue_message = TaskQueueMessage(
    task_id="abc123-s2-tile_5_10",
    parent_job_id="def456...",
    job_type="stage_raster",
    task_type="generate_cog",  # â† Links to behavior
    stage=2,
    task_index="tile_5_10",
    parameters={
        "input_tile": "/bronze/chunk_5_10.tif",
        "output_cog": "/silver/cog_5_10.tif"
    }
)

# ============================================================================
# STEP 2: Create database record (DATA at rest)
# ============================================================================
task_record = TaskRecord(
    **queue_message.model_dump(exclude={'retry_count', 'timestamp'}),
    status=TaskStatus.PROCESSING,
    created_at=datetime.now()
)
await db.upsert_task(task_record)

# ============================================================================
# STEP 3: Look up behavior from registry
# ============================================================================
executor_class = TASK_REGISTRY["generate_cog"]  # GenerateCOGTaskExecutor
executor = executor_class()

# ============================================================================
# STEP 4: Execute behavior with data
# ============================================================================
result = executor.execute(task_record.parameters)
# result = {"status": "completed", "cog_size_mb": 45.2, "epsg": 4326}

# ============================================================================
# STEP 5: Update data with results
# ============================================================================
task_record.status = TaskStatus.COMPLETED
task_record.result_data = result
task_record.updated_at = datetime.now()
await db.update_task(task_record)
```

## Benefits of This Architecture

### 1. Independent Evolution
```python
# Change data structure without touching business logic
class TaskRecord(TaskData):
    # Add new field
    gpu_used: Optional[str] = None  # TaskExecutor doesn't care!
```

### 2. Easy Testing
```python
# Test behavior without database
def test_generate_cog_executor():
    executor = GenerateCOGTaskExecutor()
    result = executor.execute({"input_tile": "test.tif"})
    assert result["status"] == "completed"
```

### 3. Boundary Flexibility
```python
# Same TaskData base, different boundaries
class TaskKafkaMessage(TaskData):  # New boundary!
    partition: int
    offset: int
```

### 4. Clear Responsibilities
- **TaskData**: Validation, serialization, boundary contracts
- **TaskExecutor**: Business logic, domain operations
- **TaskExecutionService**: Coordination, composition

## Comparison: Before vs After

### âŒ Before (Pyramid/God Class)

```python
class Task(BaseModel, ABC):
    # Data fields
    task_id: str
    status: str
    parameters: dict

    # Behavior
    @abstractmethod
    def execute(self):
        pass

# Problems:
# - Can't serialize behavior to database
# - Can't have different data formats
# - Can't test behavior independently
# - Tight coupling everywhere
```

### âœ… After (Composition)

```python
# Data (can evolve independently)
class TaskData(BaseModel):
    task_id: str
    task_type: str
    parameters: dict

class TaskRecord(TaskData):
    status: TaskStatus
    result: dict

# Behavior (can evolve independently)
class TaskExecutor(ABC):
    @abstractmethod
    def execute(self, params: dict) -> dict:
        pass

class GenerateCOGTaskExecutor(TaskExecutor):
    def execute(self, params):
        # Business logic here
        pass

# Composition (brings them together)
class TaskExecutionService:
    def execute_task(self, task_record: TaskRecord):
        executor = TASK_REGISTRY[task_record.task_type]()
        result = executor.execute(task_record.parameters)
        return result
```

## Key Files

### Data Contracts
- **core/contracts/__init__.py** - TaskData, JobData base classes
- **core/models/task.py** - TaskRecord (database boundary)
- **core/models/job.py** - JobRecord (database boundary)
- **core/schema/queue.py** - TaskQueueMessage, JobQueueMessage (queue boundary)

### Behavior Contracts
- **services/task.py** - TaskExecutor (ABC)
- **services/workflow.py** - Workflow (ABC)

### Composition Layer
- **core/machine.py** - CoreMachine (coordinates Job workflows)
- **services/** (future) - TaskExecutionService (coordinates Task execution)

## Mental Model

Think of a real-world task like "paint a room":

**Work Order (TaskRecord)** - The DATA
- Task ID: #12345
- Type: "paint_room"
- Status: "in_progress"
- Params: `{room: "bedroom", color: "blue"}`

**Painter (TaskExecutor)** - The BEHAVIOR
- Knows HOW to paint
- Has the technique
- Can execute the work

**Foreman (TaskExecutionService)** - The COMPOSITION
- Reads the work order (data)
- Assigns to someone who knows how to do it (behavior)
- Records the results (updates data)

Neither alone is complete! The "task" entity emerges from their collaboration.

## Summary

**The "Task" and "Job" entities are NOT single classes.**

They are **conceptual entities** that emerge from the **collaboration** between:
1. **Data components** (TaskData/JobData + boundary specializations)
2. **Behavior components** (TaskExecutor/Workflow)
3. **Composition layer** (CoreMachine, TaskExecutionService)

This separation provides:
- âœ… Flexibility to evolve data and behavior independently
- âœ… Testability without infrastructure dependencies
- âœ… Clear separation of concerns
- âœ… Boundary flexibility (database, queue, etc.)

**Principle**: "Favor composition over inheritance"

The conceptual entity is expressed through **collaboration**, not **inheritance**.
