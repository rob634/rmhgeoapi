# V0.8 DDH Column Migration Plan

**Created**: 30 JAN 2026
**Completed**: 30 JAN 2026
**Status**: ✅ COMPLETE
**Purpose**: Remove explicit DDH columns, migrate to `platform_id` + `platform_refs` model
**Approach**: Complete breaking changes - NO fallback patterns

---

## Executive Summary

Remove the DDH-specific columns (`dataset_id`, `resource_id`, `version_id`) from `GeospatialAsset` and all related code. All identification will use the flexible `platform_id` + `platform_refs` (JSONB) model.

**Before:**
```python
class GeospatialAsset:
    platform_id: str = "ddh"
    platform_refs: Dict = {"dataset_id": "X", "resource_id": "Y", "version_id": "Z"}
    # REDUNDANT - these duplicate platform_refs:
    dataset_id: str = "X"
    resource_id: str = "Y"
    version_id: str = "Z"
```

**After:**
```python
class GeospatialAsset:
    platform_id: str = "ddh"
    platform_refs: Dict = {"dataset_id": "X", "resource_id": "Y", "version_id": "Z"}
    # NO explicit DDH columns - use platform_refs only
```

---

## Prerequisites

- [x] `app.platforms` table exists with DDH seed
- [x] `Platform` model in `core/models/platform_registry.py`
- [x] `PlatformRegistryRepository` in `infrastructure/platform_registry_repository.py`
- [x] `platform_id` column on `geospatial_assets`
- [x] `platform_refs` JSONB column with GIN index
- [x] `list_by_platform_refs()` method exists

---

## Migration Tiers

### TIER 1: Core Model & Repository ✅ COMPLETE

These changes form the foundation - all other tiers depend on this.

#### 1.1 GeospatialAsset Model (`core/models/asset.py`) ✅ COMPLETE

- [x] **Remove explicit DDH fields** (lines 221-235)
- [x] **Update unique constraint** - Removed, using GIN index + application logic
- [x] **Update identity index** - Removed idx_assets_identity
- [x] **Update `to_dict()` method** - Removed DDH columns
- [x] **Update `generate_asset_id()` method** - Only accepts `(platform_id, platform_refs)`
- [x] **Remove `generate_asset_id_ddh()` helper** - Deleted
- [x] **Add `get_ddh_refs()` helper** - Convenience method for DDH platform

#### 1.2 Asset Repository (`infrastructure/asset_repository.py`) ✅ COMPLETE

- [x] **Replaced `get_by_identity()` with `get_by_platform_refs_exact()`**
  - Uses JSONB equality for exact match
- [x] **Updated `upsert()` method signature**
  - Now takes `(asset_id, platform_id, platform_refs, ...)`
- [x] **Updated `create()` method**
  - Uses platform_id + platform_refs instead of DDH columns
- [x] **Updated `_row_to_model()` method**
  - Removed DDH column mappings

#### 1.3 Asset Service (`services/asset_service.py`) ✅ COMPLETE

- [x] **Updated `AssetExistsError`** - Now takes `(asset_id, platform_id, platform_refs)`
- [x] **Updated `create_or_update_asset()`** - Takes `(platform_id, platform_refs, ...)`
- [x] **Updated `get_or_create_asset()`** - Takes `(platform_id, platform_refs, ...)`
- [x] **Replaced `get_asset_by_identity()`** with `get_asset_by_platform_refs()`
- [x] **Replaced `link_job_by_identity()`** with `link_job_by_platform_refs()`
- [x] **Replaced `soft_delete_by_identity()`** with `soft_delete_by_platform_refs()`
- [x] **Updated `generate_asset_id()`** - Takes `(platform_id, platform_refs)`
- [x] **Updated class docstring** with V0.8 example

---

### TIER 2: Platform API Layer ✅ COMPLETE

#### 2.1 Platform Submit (`triggers/platform/submit.py`) ✅ COMPLETE

- [x] **Updated submit handler** to build `platform_refs` dict from request
- [x] **Pass to `create_or_update_asset(platform_id="ddh", platform_refs=...)`**

#### 2.2 Platform Status (`triggers/trigger_platform_status.py`) ✅ NO CHANGES NEEDED

- Status endpoint reads from `ApiRequest` records (API contract unchanged)
- `ApiRequest` model maintains DDH fields for B2B compatibility
- Asset info fetched separately when available

#### 2.3 Platform Catalog (`triggers/trigger_platform_catalog.py`) ✅ NO CHANGES NEEDED

- Catalog endpoints use query parameters for DDH lookups (API contract)
- Delegates to `platform_catalog_service` for STAC lookups
- DDH identifiers in STAC items come from `platform:*` properties

---

### TIER 3: Internal Job System ✅ NO CHANGES NEEDED

#### 3.1 Job Submission (`triggers/submit_job.py`) ✅ NO CHANGES NEEDED

- Job params continue to include `dataset_id`, `resource_id`, `version_id` as individual fields
- This is correct - job handlers need these to know what to process
- Handlers build `platform_refs` when interacting with assets
- Job ID generation uses these params for deterministic hashing

#### 3.2 Docker Service (`docker_service.py`) ✅ NO CHANGES NEEDED

- UI form → Platform API with DDH identifiers
- Platform API submit handler builds `platform_refs` (done in TIER 2)
- Clean separation: UI/forms stay unchanged, API layer handles conversion

---

### TIER 4: Supporting Models ✅ COMPLETE

#### 4.1 Platform Request Model (`core/models/platform.py`) ✅ NO CHANGES NEEDED

- [x] Keep `dataset_id`, `resource_id`, `version_id` as INPUT fields (API contract)
- [x] `submit.py` builds `platform_refs` dict from these fields (done in TIER 2)

#### 4.2 STAC Metadata (`core/models/stac.py`) ✅ COMPLETE

- [x] **Added `PlatformProperties.from_platform_refs()` factory method**
  ```python
  @classmethod
  def from_platform_refs(cls, platform_refs: Dict[str, Any], ...) -> "PlatformProperties":
      return cls(
          dataset_id=platform_refs.get("dataset_id"),
          resource_id=platform_refs.get("resource_id"),
          version_id=platform_refs.get("version_id"),
          ...
      )
  ```

#### 4.3 External Refs (`core/models/external_refs.py`) ✅ NO CHANGES NEEDED

- [x] Separate concern - tracks external references, not asset identifiers
- [x] Uses its own DDH columns for lookup purposes (not part of GeospatialAsset)

#### 4.4 UI Adapter (`ui/adapters/epoch4.py`) ✅ COMPLETE

- [x] **Updated `asset_to_dto()` to read from `platform_refs`**
  ```python
  platform_refs = getattr(asset, 'platform_refs', {}) or {}
  return AssetDTO(
      dataset_id=platform_refs.get('dataset_id', ''),
      resource_id=platform_refs.get('resource_id', ''),
      version_id=platform_refs.get('version_id', ''),
      ...
  )
  ```

---

### TIER 5: Schema/DDL Changes ✅ COMPLETE

#### 5.1 SQL Generator (`core/schema/sql_generator.py`) ✅ COMPLETE

- [x] **DDH columns removed from `GeospatialAsset` model** (TIER 1)
  - Table generated from Pydantic model - columns automatically removed

- [x] **Updated `upsert_geospatial_asset` function signature**
  - FROM: `p_dataset_id, p_resource_id, p_version_id`
  - TO: `p_platform_id VARCHAR(50), p_platform_refs JSONB`

- [x] **Updated INSERT statement in upsert function**
  - Now uses `p_platform_id, p_platform_refs` parameters
  - No DDH columns in column list or values

- [x] **GIN index on `platform_refs`** (already exists, unchanged)

- [x] **No `idx_assets_identity` index** - never existed on geospatial_assets

#### 5.2 Workflow Schema (`core/schema/workflow.py`) ✅ NO CHANGES NEEDED

- [x] Workflow parameters stay unchanged - handlers build `platform_refs` when needed
- [x] Job handlers use individual fields (dataset_id, resource_id, version_id) for processing
- [x] Clean separation: workflow params → handler logic → asset service with platform_refs

---

---

## Execution Order

1. **TIER 1** - Core Model & Repository (foundation) ✅ COMPLETE
2. **TIER 2** - Platform API Layer (external interface) ✅ COMPLETE
3. **TIER 3** - Internal Job System ✅ NO CHANGES NEEDED
4. **TIER 4** - Supporting Models (prepare helpers) ✅ COMPLETE
5. **TIER 5** - Schema/DDL Changes (sql_generator.py) ✅ COMPLETE
6. **Deploy & Rebuild** - `action=rebuild` creates fresh schema without DDH columns ✅ COMPLETE (30 JAN 2026)

**Note**: No data migration needed - this is a dev system. Schema rebuild (`action=rebuild`) creates the new structure from scratch.

---

## Rollback Plan

If issues arise:
1. Revert code to previous commit
2. Do NOT run database migration until code is verified
3. Database columns remain until migration script runs

---

## Testing Checklist

### Already Verified ✅
- [x] ETL raster job completes successfully
- [x] STAC metadata contains `platform:*` properties (verified in job eb8bb38b...)
- [x] Schema rebuild creates table without DDH columns

### Platform API Tests (B2B Interface)
- [ ] **Platform Submit** (`/api/platform/submit`) - Creates GeospatialAsset with platform_refs
- [ ] **Platform Unpublish** (`/api/platform/unpublish`) - Soft-deletes asset by platform_refs
- [ ] **Platform Status** (`/api/platform/status/{request_id}`) - Reads asset info
- [ ] **Platform Catalog** (`/api/platform/catalog`) - Queries assets

### UI Tests
- [ ] Job detail page shows asset identifiers correctly
- [ ] Asset list displays DDH refs from platform_refs

### Approval Workflow Tests
- [ ] Approve asset by job_id
- [ ] Reject asset by job_id
- [ ] Change clearance level

---

## Files Changed Summary

| Tier | Files | Status |
|------|-------|--------|
| 1 | `asset.py`, `asset_repository.py`, `asset_service.py` | ✅ Complete |
| 2 | `submit.py` | ✅ Complete |
| 3 | `submit_job.py`, `docker_service.py` | ✅ No changes needed |
| 4 | `stac.py`, `epoch4.py` | ✅ Complete |
| 5 | `sql_generator.py` | ✅ Complete |

**No migration scripts** - dev system uses `action=rebuild` for fresh schema.

**Code migration complete!** Run `action=rebuild` to create the new schema.

---

## References

- [V0.8_ENTITIES.md](/V0.8_ENTITIES.md) - Entity architecture specification
- [V0.8_ENTITIES.md#14](/V0.8_ENTITIES.md#14-platform-registry) - Platform Registry design
- `core/models/platform_registry.py` - Platform model
- `infrastructure/platform_registry_repository.py` - Platform repository
