## Epic E4: Data Externalization & Security Zones ðŸ“‹

**Business Requirement**: Controlled data movement between security zones via Azure Data Factory
**Status**: ðŸ“‹ PLANNED
**Last Updated**: 30 DEC 2025

**Strategic Context**:
> E4 handles movement of data between security zones. ADF copies data from the **Silver Zone**
> (internal working storage) to target zones: **External** (public hosting via CDN) or
> **Restricted** (internal but access-controlled). Restricted zone is NOT IN SCOPE currently,
> but the workflow pattern established here will apply to future restricted data scenarios.

```
SILVER ZONE                      TARGET ZONES
(App Working Storage)            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                         â”‚ EXTERNAL (public hosting)   â”‚
       â”‚    Approval +           â”‚  â€¢ CDN/WAF fronted          â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â€¢ Public read access       â”‚
       â”‚    ADF Copy             â”‚  â€¢ Partner/client delivery  â”‚
       â”‚                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚                         â”‚ RESTRICTED (future)         â”‚
       â”” â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â–¶â”‚  â€¢ Internal but limited     â”‚
             (not in scope)      â”‚  â€¢ Role-based access        â”‚
                                 â”‚  â€¢ Audit logging            â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture: Python â†” Data Factory Integration

```
ETL Function App (Python)              Azure Data Factory              Target
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AzureDataFactoryRepository â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Pipeline Execution  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ External    â”‚
â”‚ â€¢ trigger_pipeline()     â”‚â—€â”€â”€â”€â”€â”€â”€â”‚ â€¢ Copy Activity     â”‚        â”‚ Storage     â”‚
â”‚ â€¢ wait_for_completion()  â”‚ status â”‚ â€¢ Linked Services   â”‚        â”‚ or Database â”‚
â”‚ â€¢ get_activity_runs()    â”‚        â”‚ â€¢ Parameterized     â”‚        â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        Python side                        ADF GUI side                 Infra side
     (Geospatial owns)                  (DevOps owns)               (DevOps owns)
```

**Python Status**: âœ… `AzureDataFactoryRepository` built (`infrastructure/data_factory.py`)

---

### Feature F4.1: Publishing Workflow ðŸ“‹ PLANNED

**Owner**: Geospatial Team
**Deliverable**: Approval queue, audit log, status APIs

| Story | Status | Acceptance Criteria |
|-------|--------|---------------------|
| S4.1.1 | â¬œ | Design publish schema (`app.publish_queue`, `app.publish_audit_log`) |
| S4.1.2 | â¬œ | Create publishing repository |
| S4.1.3 | â¬œ | Submit for review endpoint |
| S4.1.4 | â¬œ | Approve/Reject endpoints |
| S4.1.5 | â¬œ | Status check endpoint |
| S4.1.6 | â¬œ | Audit log queries |

---

### Feature F4.2: ADF Python Integration ðŸš§ PARTIAL

**Owner**: Geospatial Team
**Deliverable**: Python code to trigger and monitor ADF pipelines
**Depends on**: F4.4 (ADF infrastructure must exist first)

| Story | Status | Description | Acceptance Criteria |
|-------|--------|-------------|---------------------|
| S4.2.1 | âœ… | Create `AzureDataFactoryRepository` | Repository can trigger, poll, wait for pipelines |
| S4.2.2 | âœ… | Add ADF config to `app_config.py` | `adf_subscription_id`, `adf_factory_name`, `adf_resource_group` |
| S4.2.3 | â¬œ | Integrate approve endpoint with ADF trigger | `/api/publish/approve` triggers ADF pipeline |
| S4.2.4 | â¬œ | Add ADF status polling to audit log | Audit log updated with copy status |
| S4.2.5 | â¬œ | Add ADF health check to `/api/health` | Health endpoint shows ADF connectivity |
| S4.2.6 | â¬œ | Create `/api/adf/pipelines` listing endpoint | List available pipelines for debugging |
| S4.2.7 | â¬œ | Create `/api/adf/status/{run_id}` endpoint | Check pipeline run status |

**Key Files**: `infrastructure/data_factory.py`, `infrastructure/interface_repository.py`

### F4.2 Python Usage Pattern

```python
# Triggered from approve endpoint after approval workflow completes
from infrastructure import RepositoryFactory

adf_repo = RepositoryFactory.create_data_factory_repository()

# Trigger the pipeline
result = adf_repo.trigger_pipeline(
    pipeline_name="CopyBlobToExternal",
    parameters={
        "source_container": "silver-cogs",
        "source_blob": "rasters/dataset-123/file.tif",
        "destination_container": "public",
        "destination_blob": "rasters/dataset-123/file.tif"
    },
    reference_name=job_id  # For correlation in logs
)

# Optionally wait for completion (or poll asynchronously)
final = adf_repo.wait_for_pipeline_completion(result['run_id'])
# Returns: {'status': 'Succeeded', 'duration_ms': 45000, ...}
```

---

### Feature F4.3: External Delivery Infrastructure ðŸš§ PARTIAL

**Owner**: DevOps (infrastructure)
**Deliverable**: External storage, database, CDN, and identity configuration

**Current State**: Storage and database are **provisioned** but need validation and configuration.

#### Phase 1: Storage Setup

| Story | Status | Description | Owner | Acceptance Criteria |
|-------|--------|-------------|-------|---------------------|
| S4.3.1 | âœ… | Create **External Storage Account** | DevOps | Storage account exists |
| S4.3.2 | â¬œ | Validate storage access | DevOps | Confirm connectivity, list containers |
| S4.3.3 | â¬œ | Configure storage RBAC | DevOps | Required identities have appropriate roles |
| S4.3.4 | â¬œ | Configure storage CORS | DevOps | CORS allows reads from approved domains |

#### Phase 2: Database Setup

| Story | Status | Description | Owner | Acceptance Criteria |
|-------|--------|-------------|-------|---------------------|
| S4.3.5 | âœ… | Create **External PostgreSQL** | DevOps | Database server exists |
| S4.3.6 | â¬œ | Validate database connectivity | DevOps | Can connect from approved networks |
| S4.3.7 | â¬œ | Install PostGIS extension | DevOps | **Service Request Required** â€” PostGIS enabled on external DB |
| S4.3.8 | â¬œ | Create external schemas | Geospatial | `geo`, `app`, `pgstac` schemas created |
| S4.3.9 | â¬œ | Configure database RBAC | DevOps | Required identities have appropriate roles |

#### Phase 3: Identity Setup

| Story | Status | Description | Owner | Acceptance Criteria |
|-------|--------|-------------|-------|---------------------|
| S4.3.10 | â¬œ | Create **External Reader Identity** | DevOps | User-assigned managed identity for external read access |
| S4.3.11 | â¬œ | Grant External Reader â†’ External Storage | DevOps | `Storage Blob Data Reader` on external storage |
| S4.3.12 | â¬œ | Grant External Reader â†’ External Database | DevOps | Read-only access to external PostgreSQL |
| S4.3.13 | â¬œ | Document identity separation | DevOps | Internal vs External reader identity matrix |

### F4.3 Identity Separation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INTERNAL ZONE                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Internal Reader ID   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Bronze/Silver Storage            â”‚ â”‚
â”‚  â”‚ (existing)           â”‚         â”‚ Internal PostgreSQL              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        EXTERNAL ZONE                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ External Reader ID   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ External Storage                 â”‚ â”‚
â”‚  â”‚ (NEW - S4.3.10)      â”‚         â”‚ External PostgreSQL              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Principle: Separate identities for internal vs external access
```

#### Phase 4: CDN/WAF Setup

| Story | Status | Description | Owner | Acceptance Criteria |
|-------|--------|-------------|-------|---------------------|
| S4.3.14 | â¬œ | Create Cloudflare zone | DevOps | Zone exists for external data domain |
| S4.3.15 | â¬œ | Configure **CDN/WAF** caching rules | DevOps | COGs and vectors cached at edge |
| S4.3.16 | â¬œ | Configure **CDN/WAF** security rules | DevOps | Rate limiting, bot protection enabled |
| S4.3.17 | â¬œ | Configure custom domain DNS | DevOps | CNAME points to Cloudflare |
| S4.3.18 | â¬œ | Validate end-to-end access | DevOps | Public URL serves data through CDN |

### F4.3 Cloudflare Configuration

**Caching Rules**:
| Path Pattern | Cache TTL | Notes |
|--------------|-----------|-------|
| `*.tif`, `*.tiff` | 7 days | COG files rarely change |
| `*.geojson` | 1 day | Vector exports |
| `*.parquet` | 7 days | Analytics exports |
| `*/metadata.json` | 1 hour | STAC-like metadata |

**Security Rules**:
| Rule | Setting | Rationale |
|------|---------|-----------|
| Rate Limiting | 1000 req/min per IP | Prevent abuse |
| Bot Protection | Challenge suspicious | Block scrapers |
| Hotlink Protection | Enabled | Prevent bandwidth theft |
| Browser Integrity Check | Enabled | Block headless browsers |

### F4.3 Service Requests Required

| Item | Request Type | Notes |
|------|--------------|-------|
| **PostGIS on External DB** | Service Request | Azure Flexible Server requires support ticket for extensions |

---

### Feature F4.4: ADF Infrastructure & Pipelines ðŸ“‹ PLANNED

**Owner**: DevOps (100% Azure Portal / CLI / ARM work â€” no Python)
**Deliverable**: Functional ADF instance with copy pipelines
**Skills Needed**: Azure Portal, Data Factory GUI, ARM templates, Azure RBAC

> **For DevOps teammates**: This feature is entirely Azure infrastructure work.
> No Python or geospatial knowledge required. Standard Azure Data Factory patterns.

#### Phase 1: ADF Instance Setup

| Story | Status | Description | Acceptance Criteria |
|-------|--------|-------------|---------------------|
| S4.4.1 | â¬œ | Create Data Factory instance | `az datafactory create --name rmhazureadf --resource-group rmhazure_rg` succeeds |
| S4.4.2 | â¬œ | Enable system-assigned managed identity | ADF has managed identity in Azure AD |
| S4.4.3 | â¬œ | Grant ADF read access to Silver Storage | `Storage Blob Data Reader` role on `rmhstorage123` |
| S4.4.4 | â¬œ | Grant ADF write access to External Storage | `Storage Blob Data Contributor` role on external account |
| S4.4.5 | â¬œ | Document ADF resource names | Add to environment config template |

#### Phase 2: Linked Services (Connections)

| Story | Status | Description | Acceptance Criteria |
|-------|--------|-------------|---------------------|
| S4.4.6 | â¬œ | Create Silver Storage linked service | ADF can connect to Silver using managed identity |
| S4.4.7 | â¬œ | Create External Storage linked service | ADF can connect to External using managed identity |
| S4.4.8 | â¬œ | Test linked service connections | "Test connection" succeeds in ADF UI |

#### Phase 3: Pipeline Development (GUI)

| Story | Status | Description | Acceptance Criteria |
|-------|--------|-------------|---------------------|
| S4.4.9 | â¬œ | Create `CopyBlobToExternal` pipeline | Pipeline exists in ADF with Copy activity |
| S4.4.10 | â¬œ | Add pipeline parameters | Accepts `source_container`, `source_blob`, `destination_container`, `destination_blob` |
| S4.4.11 | â¬œ | Configure Copy activity source | Uses Silver linked service + parameterized path |
| S4.4.12 | â¬œ | Configure Copy activity sink | Uses External linked service + parameterized path |
| S4.4.13 | â¬œ | Add logging/audit activity (optional) | Pipeline logs execution metadata |

#### Phase 4: Testing & Validation

| Story | Status | Description | Acceptance Criteria |
|-------|--------|-------------|---------------------|
| S4.4.14 | â¬œ | Manual pipeline test (Debug) | Run in ADF Debug mode with test parameters |
| S4.4.15 | â¬œ | Trigger test from Azure CLI | `az datafactory pipeline create-run` succeeds |
| S4.4.16 | â¬œ | Monitor run in ADF UI | Can see run status, duration, rows copied |
| S4.4.17 | â¬œ | Verify blob in External Storage | Copied file exists and is identical to source |

#### Phase 5: Function App Configuration

| Story | Status | Description | Acceptance Criteria |
|-------|--------|-------------|---------------------|
| S4.4.18 | â¬œ | Set `ADF_SUBSCRIPTION_ID` in Function App | Environment variable configured |
| S4.4.19 | â¬œ | Set `ADF_FACTORY_NAME` in Function App | Environment variable configured |
| S4.4.20 | â¬œ | Grant Function App identity access to ADF | Function App can trigger pipelines |
| S4.4.21 | â¬œ | End-to-end Pythonâ†’ADF test | `/api/adf/pipelines` returns list successfully |

### F4.4 Pipeline Parameters Schema

```json
{
  "source_container": "silver-cogs",
  "source_blob": "rasters/dataset-123/file.tif",
  "destination_container": "public",
  "destination_blob": "rasters/dataset-123/file.tif"
}
```

### F4.4 Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Azure Data Factory                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Pipeline: CopyBlobToExternal                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Parameters  â”‚â”€â”€â”€â–¶â”‚ Copy Activity  â”‚â”€â”€â”€â–¶â”‚ (Optional)      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ source_*    â”‚    â”‚ Binary copy    â”‚    â”‚ Logging/Audit   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ dest_*      â”‚    â”‚ No transform   â”‚    â”‚ Activity        â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Linked Services            â”‚                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ SilverStorage    â”‚â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â–¶â”‚ ExternalStorage          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ (Managed ID)     â”‚  Binary copy  â”‚ (Managed ID)             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Blob Data Reader â”‚               â”‚ Blob Data Contributor    â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### F4.4 Azure CLI Quick Reference (for DevOps)

```bash
# Phase 1: Create ADF
az datafactory create \
  --name rmhazureadf \
  --resource-group rmhazure_rg \
  --location eastus

# Enable managed identity (usually automatic with create)
az datafactory show --name rmhazureadf --resource-group rmhazure_rg \
  --query identity

# Phase 1: Grant storage access
ADF_PRINCIPAL_ID=$(az datafactory show --name rmhazureadf \
  --resource-group rmhazure_rg --query identity.principalId -o tsv)

# Reader on Silver
az role assignment create \
  --assignee $ADF_PRINCIPAL_ID \
  --role "Storage Blob Data Reader" \
  --scope /subscriptions/{sub}/resourceGroups/rmhazure_rg/providers/Microsoft.Storage/storageAccounts/rmhstorage123

# Contributor on External
az role assignment create \
  --assignee $ADF_PRINCIPAL_ID \
  --role "Storage Blob Data Contributor" \
  --scope /subscriptions/{sub}/resourceGroups/rmhazure_rg/providers/Microsoft.Storage/storageAccounts/{external-account}

# Phase 5: Set Function App env vars
az functionapp config appsettings set \
  --name rmhazuregeoapi \
  --resource-group rmhazure_rg \
  --settings ADF_SUBSCRIPTION_ID={subscription-id} ADF_FACTORY_NAME=rmhazureadf
```

---

### Feature F4.5: Database-to-Database Pipelines ðŸ”µ BACKLOG

**Owner**: DevOps (ADF) + Geospatial Team (triggers)
**Deliverable**: ADF pipelines for database copy operations
**Status**: Deferred â€” implement when database promotion workflow is needed

> **Use Case**: Copy staging tables to production, or archive data between databases.
> Similar pattern to blob copy, but uses Azure Database linked services.

| Story | Status | Description |
|-------|--------|-------------|
| S4.5.1 | ðŸ”µ | Create PostgreSQL linked service | ADF connects to Business Database |
| S4.5.2 | ðŸ”µ | Create `CopyTableToProduction` pipeline | Parameterized table copy |
| S4.5.3 | ðŸ”µ | Add database triggers to Python repo | Same pattern as blob triggers |

---

### E4 Dependency Summary

```
F4.4: ADF Infrastructure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ F4.2: Python Integration
        (DevOps)                              (Geospatial)
            â”‚                                      â”‚
            â–¼                                      â–¼
F4.3: External Storage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ F4.1: Publishing Workflow
        (DevOps)                              (Geospatial)
                                                   â”‚
                                                   â–¼
                                          End-to-End Testing
```

**Critical Path**: F4.4 â†’ F4.2 â†’ F4.1 â†’ Integration Testing

---

---

