{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# API Examples - Quick Reference\n\nCondensed notebook covering the core Platform endpoints (updated 19 DEC 2025):\n\n### CoreMachine API (Direct ETL Access)\n1. Health Check\n2. Container Check (Sync)\n3. Process Vector\n4. **Process Raster v2** (single file, ‚â§800 MB)\n5. **Process Large Raster v2** (100 MB - 30 GB, tiled processing)\n6. **Process Raster Collection v2** (‚â§20 files, each ‚â§800 MB)\n7. Rejection Examples (size/count limit violations)\n\n### Platform API (Anti-Corruption Layer)\n8. Platform Single Raster (DDH identifiers)\n9. Platform Raster Collection (DDH identifiers)\n10. Platform Status Check\n11. **Unpublish Vector** (3 options: DDH IDs, request_id, cleanup mode)\n12. **Unpublish Raster** (3 options: DDH IDs, request_id, cleanup mode)\n\n### Size Routing Summary\n\n| File Size | Job Type | Notes |\n|-----------|----------|-------|\n| ‚â§800 MB | `process_raster_v2` | Standard COG conversion |\n| 100 MB - 30 GB | `process_large_raster_v2` | Tiled COG workflow |\n| Collection ‚â§20 files | `process_raster_collection_v2` | Each file must be ‚â§800 MB |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "API CONFIGURATION\n",
      "============================================================\n",
      "Base URL:          https://rmhazuregeoapi-a3dma3ctfdgngwf6.eastus-01.azurewebsites.net\n",
      "Bronze Container:  rmhazuregeobronze\n",
      "Silver Container:  silver-cogs\n",
      "PostGIS Schema:    geo\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - All variables defined here\n",
    "# =============================================================================\n",
    "\n",
    "# Function App Base URL\n",
    "BASE_URL = \"https://rmhazuregeoapi-a3dma3ctfdgngwf6.eastus-01.azurewebsites.net\"\n",
    "\n",
    "# Storage Containers\n",
    "BRONZE_CONTAINER = \"rmhazuregeobronze\"  # Main bronze container for raw input\n",
    "SILVER_CONTAINER = \"silver-cogs\"         # Processed COGs output\n",
    "\n",
    "# PostGIS Schema\n",
    "POSTGIS_SCHEMA = \"geo\"\n",
    "\n",
    "# =============================================================================\n",
    "# Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def api_call(method, endpoint, data=None, params=None, timeout=30):\n",
    "    \"\"\"Make API call and return formatted response.\"\"\"\n",
    "    url = f\"{BASE_URL}{endpoint}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{method} {endpoint}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if data:\n",
    "        print(f\"\\nRequest Body:\")\n",
    "        print(json.dumps(data, indent=2))\n",
    "    \n",
    "    try:\n",
    "        if method == \"GET\":\n",
    "            response = requests.get(url, params=params, timeout=timeout)\n",
    "        elif method == \"POST\":\n",
    "            response = requests.post(url, json=data, headers=headers, timeout=timeout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "        \n",
    "        print(f\"\\nStatus: {response.status_code}\")\n",
    "        \n",
    "        try:\n",
    "            result = response.json()\n",
    "            print(f\"\\nResponse:\")\n",
    "            print(json.dumps(result, indent=2, default=str))\n",
    "            return result\n",
    "        except:\n",
    "            print(f\"\\nResponse (text): {response.text[:500]}\")\n",
    "            return response.text\n",
    "            \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"\\n‚ùå Request timed out (timeout={timeout}s)\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def check_job_status(job_id, max_polls=20, poll_interval=5):\n",
    "    \"\"\"Poll job status until completion or timeout.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Polling job: {job_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i in range(max_polls):\n",
    "        result = requests.get(f\"{BASE_URL}/api/jobs/status/{job_id}\", timeout=30).json()\n",
    "        status = result.get(\"status\", \"unknown\")\n",
    "        stage = result.get(\"current_stage\", \"?\")\n",
    "        \n",
    "        print(f\"  [{i+1}/{max_polls}] Status: {status}, Stage: {stage}\")\n",
    "        \n",
    "        if status in [\"completed\", \"failed\"]:\n",
    "            print(f\"\\nFinal Result:\")\n",
    "            print(json.dumps(result, indent=2, default=str))\n",
    "            return result\n",
    "        \n",
    "        time.sleep(poll_interval)\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è Polling timeout after {max_polls * poll_interval}s\")\n",
    "    return result\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"API CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Base URL:          {BASE_URL}\")\n",
    "print(f\"Bronze Container:  {BRONZE_CONTAINER}\")\n",
    "print(f\"Silver Container:  {SILVER_CONTAINER}\")\n",
    "print(f\"PostGIS Schema:    {POSTGIS_SCHEMA}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Health Check\n",
    "\n",
    "Comprehensive system health check (~60s due to database, Service Bus, and storage checks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GET /api/health\n",
      "============================================================\n",
      "\n",
      "Status: 200\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"status\": \"healthy\",\n",
      "  \"components\": {\n",
      "    \"deployment_config\": {\n",
      "      \"component\": \"deployment_config\",\n",
      "      \"description\": \"Tenant-specific configuration validation for production deployments\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"config_status\": \"configured\",\n",
      "        \"deployment_ready\": true,\n",
      "        \"azure_tenant_specific_configs\": {\n",
      "          \"total_checked\": 5,\n",
      "          \"properly_configured\": 5,\n",
      "          \"using_defaults\": 0\n",
      "        },\n",
      "        \"issues\": null,\n",
      "        \"defaults_detected\": null,\n",
      "        \"environment_vars_set\": {\n",
      "          \"BRONZE_STORAGE_ACCOUNT\": true,\n",
      "          \"TITILER_BASE_URL\": true,\n",
      "          \"OGC_STAC_APP_URL\": true,\n",
      "          \"ETL_APP_URL\": true,\n",
      "          \"USE_MANAGED_IDENTITY\": false,\n",
      "          \"POSTGIS_HOST\": true\n",
      "        },\n",
      "        \"recommendation\": null\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:01.182965+00:00\"\n",
      "    },\n",
      "    \"app_mode\": {\n",
      "      \"component\": \"app_mode\",\n",
      "      \"description\": \"Multi-Function App deployment mode and queue routing configuration\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"mode\": \"standalone\",\n",
      "        \"app_name\": \"rmhazuregeoapi\",\n",
      "        \"queues_listening\": {\n",
      "          \"jobs\": true,\n",
      "          \"raster_tasks\": true,\n",
      "          \"vector_tasks\": true\n",
      "        },\n",
      "        \"queue_names\": {\n",
      "          \"jobs\": \"geospatial-jobs\",\n",
      "          \"raster_tasks\": \"raster-tasks\",\n",
      "          \"vector_tasks\": \"vector-tasks\"\n",
      "        },\n",
      "        \"routing\": {\n",
      "          \"routes_raster_externally\": false,\n",
      "          \"routes_vector_externally\": false,\n",
      "          \"raster_app_url\": null,\n",
      "          \"vector_app_url\": null\n",
      "        },\n",
      "        \"role\": {\n",
      "          \"is_platform\": true,\n",
      "          \"is_worker\": false,\n",
      "          \"has_http\": true\n",
      "        },\n",
      "        \"environment_var\": {\n",
      "          \"APP_MODE\": \"standalone\",\n",
      "          \"APP_NAME\": \"rmhazuregeoapi\"\n",
      "        }\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:01.183032+00:00\"\n",
      "    },\n",
      "    \"imports\": {\n",
      "      \"component\": \"import_validation\",\n",
      "      \"description\": \"Python module imports (lightweight sys.modules check)\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"overall_success\": true,\n",
      "        \"validation_summary\": \"All critical modules loaded\",\n",
      "        \"statistics\": {\n",
      "          \"modules_checked\": 5,\n",
      "          \"modules_loaded\": 5,\n",
      "          \"success_rate_percent\": 100.0\n",
      "        },\n",
      "        \"critical_dependencies\": {\n",
      "          \"azure.functions\": {\n",
      "            \"loaded\": true,\n",
      "            \"description\": \"Azure Functions runtime\"\n",
      "          },\n",
      "          \"pydantic\": {\n",
      "            \"loaded\": true,\n",
      "            \"description\": \"Data validation library\"\n",
      "          },\n",
      "          \"psycopg\": {\n",
      "            \"loaded\": true,\n",
      "            \"description\": \"PostgreSQL adapter\"\n",
      "          },\n",
      "          \"azure.identity\": {\n",
      "            \"loaded\": true,\n",
      "            \"description\": \"Azure authentication\"\n",
      "          },\n",
      "          \"azure.storage.blob\": {\n",
      "            \"loaded\": true,\n",
      "            \"description\": \"Azure Blob Storage client\"\n",
      "          }\n",
      "        },\n",
      "        \"note\": \"Lightweight check via sys.modules - full validation runs at startup only\",\n",
      "        \"rationale\": \"If this endpoint responds, function_app.py loaded successfully, proving all imports work\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:01.183071+00:00\"\n",
      "    },\n",
      "    \"storage_containers\": {\n",
      "      \"component\": \"storage_containers\",\n",
      "      \"description\": \"Bronze and Silver zone storage accounts and critical containers\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"zones\": {\n",
      "          \"bronze\": {\n",
      "            \"account\": \"rmhazuregeo\",\n",
      "            \"account_accessible\": true,\n",
      "            \"containers\": {\n",
      "              \"rmhazuregeobronze\": {\n",
      "                \"status\": \"exists\",\n",
      "                \"purpose\": \"Raw raster uploads (GeoTIFF)\",\n",
      "                \"criticality\": \"high\"\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"silver\": {\n",
      "            \"account\": \"rmhstorage123\",\n",
      "            \"account_accessible\": true,\n",
      "            \"containers\": {\n",
      "              \"silver-cogs\": {\n",
      "                \"status\": \"exists\",\n",
      "                \"purpose\": \"Cloud Optimized GeoTIFFs (COG output)\",\n",
      "                \"criticality\": \"high\"\n",
      "              },\n",
      "              \"pickles\": {\n",
      "                \"status\": \"exists\",\n",
      "                \"purpose\": \"Vector ETL intermediate storage\",\n",
      "                \"criticality\": \"high\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"summary\": {\n",
      "          \"total_containers_checked\": 4,\n",
      "          \"containers_exist\": 4,\n",
      "          \"containers_missing\": 0,\n",
      "          \"zones_accessible\": 2,\n",
      "          \"zones_error\": 0\n",
      "        }\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:01.216535+00:00\"\n",
      "    },\n",
      "    \"service_bus\": {\n",
      "      \"component\": \"service_bus\",\n",
      "      \"description\": \"Azure Service Bus message queues for job and task orchestration\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"geospatial-jobs\": {\n",
      "          \"status\": \"accessible\",\n",
      "          \"purpose\": \"Job orchestration + stage_complete signals\",\n",
      "          \"approximate_message_count\": 0,\n",
      "          \"note\": \"Count is approximate (peek limit: 100)\"\n",
      "        },\n",
      "        \"raster-tasks\": {\n",
      "          \"status\": \"accessible\",\n",
      "          \"purpose\": \"Raster tasks (GDAL, low concurrency)\",\n",
      "          \"approximate_message_count\": 0,\n",
      "          \"note\": \"Count is approximate (peek limit: 100)\"\n",
      "        },\n",
      "        \"vector-tasks\": {\n",
      "          \"status\": \"accessible\",\n",
      "          \"purpose\": \"Vector tasks (DB, high concurrency)\",\n",
      "          \"approximate_message_count\": 0,\n",
      "          \"note\": \"Count is approximate (peek limit: 100)\"\n",
      "        },\n",
      "        \"_summary\": {\n",
      "          \"total_queues\": 3,\n",
      "          \"accessible\": 3,\n",
      "          \"missing\": 0,\n",
      "          \"multi_function_app_ready\": true,\n",
      "          \"note\": \"All 4 queues required for Multi-Function App Architecture\"\n",
      "        },\n",
      "        \"_repository_info\": {\n",
      "          \"singleton_id\": 139087871966672,\n",
      "          \"type\": \"ServiceBusRepository\",\n",
      "          \"namespace\": \"rmhazure.servicebus.windows.net\"\n",
      "        }\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.396416+00:00\"\n",
      "    },\n",
      "    \"tables\": {\n",
      "      \"component\": \"tables\",\n",
      "      \"status\": \"deprecated\",\n",
      "      \"details\": {\n",
      "        \"message\": \"Azure Table Storage deprecated - using PostgreSQL instead\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.396482+00:00\"\n",
      "    },\n",
      "    \"vault\": {\n",
      "      \"component\": \"vault\",\n",
      "      \"status\": \"disabled\",\n",
      "      \"details\": {\n",
      "        \"message\": \"Key Vault disabled - using environment variables only\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.396504+00:00\"\n",
      "    },\n",
      "    \"database_config\": {\n",
      "      \"component\": \"database_config\",\n",
      "      \"description\": \"PostgreSQL connection environment variables and configuration\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"required_env_vars_present\": {\n",
      "          \"POSTGIS_DATABASE\": \"geopgflex\",\n",
      "          \"POSTGIS_HOST\": \"rmhpgflex.postgres.database.azure.com\",\n",
      "          \"POSTGIS_PORT\": \"5432\"\n",
      "        },\n",
      "        \"missing_required_vars\": [\n",
      "          \"POSTGIS_USER\"\n",
      "        ],\n",
      "        \"optional_env_vars\": {\n",
      "          \"KEY_VAULT\": \"rmhazurevault\",\n",
      "          \"KEY_VAULT_DATABASE_SECRET\": \"postgis-password\",\n",
      "          \"POSTGIS_PASSWORD\": false,\n",
      "          \"POSTGIS_SCHEMA\": \"geo\",\n",
      "          \"APP_SCHEMA\": \"app\"\n",
      "        },\n",
      "        \"loaded_config_values\": {\n",
      "          \"postgis_host\": \"rmhpgflex.postgres.database.azure.com\",\n",
      "          \"postgis_port\": 5432,\n",
      "          \"postgis_user\": null,\n",
      "          \"postgis_database\": \"geopgflex\",\n",
      "          \"postgis_schema\": \"geo\",\n",
      "          \"app_schema\": \"app\",\n",
      "          \"key_vault_name\": null,\n",
      "          \"key_vault_database_secret\": \"postgis-password\",\n",
      "          \"postgis_password_configured\": false\n",
      "        },\n",
      "        \"configuration_complete\": false\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.396611+00:00\"\n",
      "    },\n",
      "    \"database\": {\n",
      "      \"component\": \"database\",\n",
      "      \"description\": \"PostgreSQL/PostGIS database connectivity and query metrics\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"postgresql_version\": \"PostgreSQL\",\n",
      "        \"postgis_version\": \"3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\",\n",
      "        \"connection\": \"successful\",\n",
      "        \"connection_time_ms\": 97.13,\n",
      "        \"schema_health\": {\n",
      "          \"app_schema_name\": \"app\",\n",
      "          \"app_schema_exists\": true,\n",
      "          \"app_schema_critical\": true,\n",
      "          \"postgis_schema_name\": \"geo\",\n",
      "          \"postgis_schema_exists\": true,\n",
      "          \"app_tables\": {\n",
      "            \"jobs\": true,\n",
      "            \"tasks\": true\n",
      "          }\n",
      "        },\n",
      "        \"table_management\": {\n",
      "          \"auto_creation_enabled\": true,\n",
      "          \"operations_performed\": {\n",
      "            \"jobs\": \"exists\",\n",
      "            \"tasks\": \"exists\"\n",
      "          },\n",
      "          \"tables_ready\": true\n",
      "        },\n",
      "        \"stac_data\": {\n",
      "          \"items_count\": 0,\n",
      "          \"schema_accessible\": true\n",
      "        },\n",
      "        \"detailed_schema_inspection\": {\n",
      "          \"jobs_columns\": [\n",
      "            {\n",
      "              \"column_name\": \"job_id\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"job_type\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"parameters\",\n",
      "              \"data_type\": \"jsonb\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"'{}'::jsonb\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"status\",\n",
      "              \"data_type\": \"USER-DEFINED\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"'queued'::app.job_status\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"stage\",\n",
      "              \"data_type\": \"integer\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"1\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"total_stages\",\n",
      "              \"data_type\": \"integer\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"1\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"stage_results\",\n",
      "              \"data_type\": \"jsonb\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"'{}'::jsonb\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"metadata\",\n",
      "              \"data_type\": \"jsonb\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"'{}'::jsonb\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"result_data\",\n",
      "              \"data_type\": \"jsonb\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"error_details\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"created_at\",\n",
      "              \"data_type\": \"timestamp without time zone\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"now()\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"updated_at\",\n",
      "              \"data_type\": \"timestamp without time zone\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"now()\"\n",
      "            }\n",
      "          ],\n",
      "          \"tasks_columns\": [\n",
      "            {\n",
      "              \"column_name\": \"task_id\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"parent_job_id\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"job_type\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"task_type\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"stage\",\n",
      "              \"data_type\": \"integer\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"task_index\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"'0'::character varying\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"parameters\",\n",
      "              \"data_type\": \"jsonb\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"'{}'::jsonb\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"status\",\n",
      "              \"data_type\": \"USER-DEFINED\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"'pending'::app.task_status\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"result_data\",\n",
      "              \"data_type\": \"jsonb\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"metadata\",\n",
      "              \"data_type\": \"jsonb\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"'{}'::jsonb\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"error_details\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"retry_count\",\n",
      "              \"data_type\": \"integer\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"0\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"heartbeat\",\n",
      "              \"data_type\": \"timestamp without time zone\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"next_stage_params\",\n",
      "              \"data_type\": \"jsonb\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"target_queue\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"executed_by_app\",\n",
      "              \"data_type\": \"character varying\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"execution_started_at\",\n",
      "              \"data_type\": \"timestamp without time zone\",\n",
      "              \"is_nullable\": \"YES\",\n",
      "              \"column_default\": null\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"created_at\",\n",
      "              \"data_type\": \"timestamp without time zone\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"now()\"\n",
      "            },\n",
      "            {\n",
      "              \"column_name\": \"updated_at\",\n",
      "              \"data_type\": \"timestamp without time zone\",\n",
      "              \"is_nullable\": \"NO\",\n",
      "              \"column_default\": \"now()\"\n",
      "            }\n",
      "          ],\n",
      "          \"postgresql_functions\": [\n",
      "            {\n",
      "              \"function_name\": \"advance_job_stage\",\n",
      "              \"return_type\": \"record\",\n",
      "              \"definition_snippet\": \"\\n\\nDECLARE\\n    v_total_stages INTEGER;\\n    v_new_stage INTEGER;\\nBEGIN\\n    -- Update job stage and stage results atomically\\n    UPDATE app.jobs\\n    SET \\n        stage = stage + 1,\\n        stage_results ...\"\n",
      "            },\n",
      "            {\n",
      "              \"function_name\": \"check_job_completion\",\n",
      "              \"return_type\": \"record\",\n",
      "              \"definition_snippet\": \"\\n\\nDECLARE\\n    v_job_record RECORD;\\n    v_task_counts RECORD;\\nBEGIN\\n    -- Get job info with row-level lock\\n    SELECT job_id, job_type, status, stage, total_stages, stage_results\\n    INTO v_job_record...\"\n",
      "            },\n",
      "            {\n",
      "              \"function_name\": \"complete_task_and_check_stage\",\n",
      "              \"return_type\": \"record\",\n",
      "              \"definition_snippet\": \"\\n\\nDECLARE\\n    v_job_id VARCHAR(64);\\n    v_stage INTEGER;\\n    v_remaining INTEGER;\\n    v_task_status app.task_status;\\nBEGIN\\n    -- Get task info and update atomically\\n    -- Now validates that p_job_id...\"\n",
      "            }\n",
      "          ],\n",
      "          \"function_test\": \"SUCCESS - Function signature matches query\"\n",
      "        },\n",
      "        \"query_performance\": {\n",
      "          \"connection_time_ms\": 97.13,\n",
      "          \"note\": \"Detailed metrics available at /api/dbadmin/stats\",\n",
      "          \"metrics_removed_reason\": \"Performance optimization - health check should be <5s\"\n",
      "        }\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.549608+00:00\"\n",
      "    },\n",
      "    \"duckdb\": {\n",
      "      \"component\": \"duckdb\",\n",
      "      \"status\": \"disabled\",\n",
      "      \"details\": {\n",
      "        \"message\": \"DuckDB check disabled via config - module still available\",\n",
      "        \"enable_with\": \"Set ENABLE_DUCKDB_HEALTH_CHECK=true\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.549640+00:00\"\n",
      "    },\n",
      "    \"jobs\": {\n",
      "      \"component\": \"jobs\",\n",
      "      \"description\": \"Job registry showing available ETL job types and their handlers\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"available_jobs\": [\n",
      "          \"bootstrap_h3_land_grid_pyramid\",\n",
      "          \"create_h3_base\",\n",
      "          \"curated_dataset_update\",\n",
      "          \"generate_h3_level4\",\n",
      "          \"h3_raster_aggregation\",\n",
      "          \"hello_world\",\n",
      "          \"inventory_container_contents\",\n",
      "          \"inventory_fathom_container\",\n",
      "          \"process_fathom_merge\",\n",
      "          \"process_fathom_stack\",\n",
      "          \"process_large_raster_v2\",\n",
      "          \"process_raster_collection_v2\",\n",
      "          \"process_raster_v2\",\n",
      "          \"process_vector\",\n",
      "          \"stac_catalog_container\",\n",
      "          \"stac_catalog_vectors\",\n",
      "          \"summarize_container\",\n",
      "          \"unpublish_raster\",\n",
      "          \"unpublish_vector\",\n",
      "          \"validate_raster_job\"\n",
      "        ],\n",
      "        \"total_jobs\": 20,\n",
      "        \"registry_location\": \"jobs/__init__.py\",\n",
      "        \"validation_performed\": true,\n",
      "        \"registry_type\": \"explicit\",\n",
      "        \"note\": \"Jobs are explicitly registered in jobs/__init__.py ALL_JOBS dict\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.549675+00:00\"\n",
      "    },\n",
      "    \"pgstac\": {\n",
      "      \"component\": \"pgstac\",\n",
      "      \"description\": \"PgSTAC extension for STAC catalog storage and TiTiler integration\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"schema_exists\": true,\n",
      "        \"installed\": true,\n",
      "        \"pgstac_version\": \"0.9.8\",\n",
      "        \"critical_tables\": {\n",
      "          \"collections\": true,\n",
      "          \"items\": true,\n",
      "          \"searches\": true\n",
      "        },\n",
      "        \"searches_table_exists\": true,\n",
      "        \"critical_functions\": {\n",
      "          \"search_tohash\": true,\n",
      "          \"search_hash\": true,\n",
      "          \"searches_hash_column_generated\": true\n",
      "        },\n",
      "        \"table_counts\": {\n",
      "          \"collections\": 2,\n",
      "          \"items\": 0\n",
      "        },\n",
      "        \"all_critical_tables_present\": true,\n",
      "        \"all_critical_functions_present\": true,\n",
      "        \"criticality\": \"medium\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.667115+00:00\"\n",
      "    },\n",
      "    \"system_reference_tables\": {\n",
      "      \"component\": \"system_reference_tables\",\n",
      "      \"description\": \"Reference data tables for ISO3 country attribution and spatial enrichment\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"admin0_table\": \"geo.curated_admin0\",\n",
      "        \"exists\": true,\n",
      "        \"row_count\": 288,\n",
      "        \"columns\": {\n",
      "          \"iso3\": true,\n",
      "          \"geom\": true,\n",
      "          \"name\": true\n",
      "        },\n",
      "        \"spatial_index\": true,\n",
      "        \"ready_for_attribution\": true,\n",
      "        \"criticality\": \"low\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.792561+00:00\"\n",
      "    },\n",
      "    \"schema_summary\": {\n",
      "      \"component\": \"schema_summary\",\n",
      "      \"description\": \"Database schema inventory with table counts and STAC statistics\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"schemas\": {\n",
      "          \"app\": {\n",
      "            \"exists\": true,\n",
      "            \"tables\": [\n",
      "              \"api_requests\",\n",
      "              \"curated_datasets\",\n",
      "              \"curated_update_log\",\n",
      "              \"etl_fathom\",\n",
      "              \"janitor_runs\",\n",
      "              \"jobs\",\n",
      "              \"tasks\",\n",
      "              \"unpublish_jobs\"\n",
      "            ],\n",
      "            \"table_count\": 8,\n",
      "            \"row_counts\": {\n",
      "              \"api_requests\": 0,\n",
      "              \"curated_datasets\": 0,\n",
      "              \"curated_update_log\": 0,\n",
      "              \"etl_fathom\": 0,\n",
      "              \"janitor_runs\": 0,\n",
      "              \"jobs\": 0,\n",
      "              \"tasks\": 0,\n",
      "              \"unpublish_jobs\": 0\n",
      "            },\n",
      "            \"note\": \"Row counts are approximate (from pg_stat_user_tables)\"\n",
      "          },\n",
      "          \"geo\": {\n",
      "            \"exists\": true,\n",
      "            \"tables\": [\n",
      "              \"curated_admin0\",\n",
      "              \"feature_collection_styles\",\n",
      "              \"table_metadata\",\n",
      "              \"test_geojson_16dec_eight_v1\"\n",
      "            ],\n",
      "            \"table_count\": 4,\n",
      "            \"row_counts\": {\n",
      "              \"curated_admin0\": 288,\n",
      "              \"feature_collection_styles\": 1,\n",
      "              \"table_metadata\": 1,\n",
      "              \"test_geojson_16dec_eight_v1\": 3879\n",
      "            },\n",
      "            \"note\": \"Row counts are approximate (from pg_stat_user_tables)\",\n",
      "            \"geometry_columns\": 2\n",
      "          },\n",
      "          \"pgstac\": {\n",
      "            \"exists\": true,\n",
      "            \"tables\": [\n",
      "              \"collections\",\n",
      "              \"cql2_ops\",\n",
      "              \"format_item_cache\",\n",
      "              \"items\",\n",
      "              \"items_staging\",\n",
      "              \"items_staging_ignore\",\n",
      "              \"items_staging_upsert\",\n",
      "              \"migrations\",\n",
      "              \"partition_stats\",\n",
      "              \"pgstac_settings\",\n",
      "              \"query_queue\",\n",
      "              \"query_queue_history\",\n",
      "              \"queryables\",\n",
      "              \"search_wheres\",\n",
      "              \"searches\",\n",
      "              \"stac_extensions\"\n",
      "            ],\n",
      "            \"table_count\": 16,\n",
      "            \"row_counts\": {\n",
      "              \"collections\": 2,\n",
      "              \"cql2_ops\": 29,\n",
      "              \"format_item_cache\": 0,\n",
      "              \"items\": 0,\n",
      "              \"items_staging\": 0,\n",
      "              \"items_staging_ignore\": 0,\n",
      "              \"items_staging_upsert\": 0,\n",
      "              \"migrations\": 1,\n",
      "              \"partition_stats\": 0,\n",
      "              \"partition_steps\": 0,\n",
      "              \"partitions\": 0,\n",
      "              \"pgstac_settings\": 11,\n",
      "              \"query_queue\": 0,\n",
      "              \"query_queue_history\": 0,\n",
      "              \"queryables\": 3,\n",
      "              \"search_wheres\": 0,\n",
      "              \"searches\": 0,\n",
      "              \"stac_extensions\": 0\n",
      "            },\n",
      "            \"note\": \"Row counts are approximate (from pg_stat_user_tables)\",\n",
      "            \"stac_counts\": {\n",
      "              \"collections\": 2,\n",
      "              \"items\": 0\n",
      "            }\n",
      "          },\n",
      "          \"h3\": {\n",
      "            \"exists\": true,\n",
      "            \"tables\": [\n",
      "              \"batch_progress\",\n",
      "              \"cell_admin0\",\n",
      "              \"cell_admin1\",\n",
      "              \"cells\",\n",
      "              \"point_stats\",\n",
      "              \"stat_registry\",\n",
      "              \"zonal_stats\"\n",
      "            ],\n",
      "            \"table_count\": 7,\n",
      "            \"row_counts\": {\n",
      "              \"batch_progress\": 0,\n",
      "              \"cell_admin0\": 17268011,\n",
      "              \"cell_admin1\": 0,\n",
      "              \"cells\": 17373953,\n",
      "              \"point_stats\": 0,\n",
      "              \"stat_registry\": 0,\n",
      "              \"zonal_stats\": 0\n",
      "            },\n",
      "            \"note\": \"Row counts are approximate (from pg_stat_user_tables)\"\n",
      "          }\n",
      "        },\n",
      "        \"total_tables\": 35,\n",
      "        \"schemas_checked\": [\n",
      "          \"app\",\n",
      "          \"geo\",\n",
      "          \"pgstac\",\n",
      "          \"h3\"\n",
      "        ]\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:04.920039+00:00\"\n",
      "    },\n",
      "    \"titiler\": {\n",
      "      \"component\": \"titiler\",\n",
      "      \"description\": \"TiTiler-pgstac raster tile server for COG visualization\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"configured\": true,\n",
      "        \"base_url\": \"https://rmhtitiler-ghcyd7g0bxdvc2hc.eastus-01.azurewebsites.net\",\n",
      "        \"livez\": {\n",
      "          \"status_code\": 200,\n",
      "          \"ok\": true\n",
      "        },\n",
      "        \"health\": {\n",
      "          \"status_code\": 200,\n",
      "          \"ok\": true,\n",
      "          \"body\": {\n",
      "            \"status\": \"healthy\",\n",
      "            \"checks\": {\n",
      "              \"database\": {\n",
      "                \"status\": \"ok\",\n",
      "                \"required_for\": [\n",
      "                  \"pgSTAC searches\",\n",
      "                  \"mosaic endpoints\"\n",
      "                ],\n",
      "                \"host\": \"rmhpgflex.postgres.database.azure.com:5432\"\n",
      "              },\n",
      "              \"storage_oauth\": {\n",
      "                \"status\": \"ok\",\n",
      "                \"expires_in_seconds\": 64485,\n",
      "                \"storage_account\": \"rmhstorage123\",\n",
      "                \"required_for\": [\n",
      "                  \"Azure blob storage access\"\n",
      "                ]\n",
      "              },\n",
      "              \"postgres_oauth\": {\n",
      "                \"status\": \"ok\",\n",
      "                \"expires_in_seconds\": 64485,\n",
      "                \"required_for\": [\n",
      "                  \"PostgreSQL database connection\"\n",
      "                ]\n",
      "              }\n",
      "            },\n",
      "            \"issues\": null,\n",
      "            \"config\": {\n",
      "              \"postgres_auth_mode\": \"managed_identity\",\n",
      "              \"azure_auth_enabled\": true,\n",
      "              \"local_mode\": false\n",
      "            },\n",
      "            \"available_features\": {\n",
      "              \"cog_tiles\": true,\n",
      "              \"pgstac_searches\": true,\n",
      "              \"mosaic_json\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"overall_status\": \"healthy\",\n",
      "        \"status_reason\": \"Both /livez and /healthz endpoints responding\",\n",
      "        \"purpose\": \"Raster tile server for COG visualization via TiTiler-pgstac\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:05.060056+00:00\"\n",
      "    },\n",
      "    \"ogc_features\": {\n",
      "      \"component\": \"ogc_features\",\n",
      "      \"description\": \"OGC API - Features for PostGIS vector queries\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"details\": {\n",
      "        \"configured\": true,\n",
      "        \"features_url\": \"https://rmhogcstac-b4f5ccetf0a7hwe9.eastus-01.azurewebsites.net/api/features\",\n",
      "        \"app_base_url\": \"https://rmhogcstac-b4f5ccetf0a7hwe9.eastus-01.azurewebsites.net\",\n",
      "        \"is_self_hosted\": false,\n",
      "        \"health_endpoint\": \"https://rmhogcstac-b4f5ccetf0a7hwe9.eastus-01.azurewebsites.net/api/health\",\n",
      "        \"health\": {\n",
      "          \"status_code\": 200,\n",
      "          \"ok\": true,\n",
      "          \"status\": \"healthy\"\n",
      "        },\n",
      "        \"overall_status\": \"healthy\",\n",
      "        \"status_reason\": \"/api/health endpoint responding\",\n",
      "        \"purpose\": \"OGC API - Features for vector data queries\"\n",
      "      },\n",
      "      \"checked_at\": \"2025-12-19T06:23:05.180101+00:00\"\n",
      "    }\n",
      "  },\n",
      "  \"warnings\": [],\n",
      "  \"environment\": {\n",
      "    \"bronze_storage_account\": \"rmhazuregeo\",\n",
      "    \"python_version\": \"3.12.11\",\n",
      "    \"function_runtime\": \"python\",\n",
      "    \"health_check_version\": \"v2025-12-08_IDENTITY_ECHO\"\n",
      "  },\n",
      "  \"identity\": {\n",
      "    \"database\": {\n",
      "      \"admin_identity_name\": \"rmhpgflexadmin\",\n",
      "      \"use_managed_identity\": true,\n",
      "      \"auth_method\": \"managed_identity\",\n",
      "      \"note\": \"Single admin identity used for all database operations (ETL, OGC/STAC, TiTiler)\"\n",
      "    },\n",
      "    \"storage\": {\n",
      "      \"auth_method\": \"DefaultAzureCredential (system-assigned)\",\n",
      "      \"note\": \"Storage uses system-assigned managed identity via DefaultAzureCredential\"\n",
      "    }\n",
      "  },\n",
      "  \"errors\": [],\n",
      "  \"debug_status\": {\n",
      "    \"debug_mode\": true,\n",
      "    \"debug_logging\": true,\n",
      "    \"environment\": \"dev\",\n",
      "    \"log_level\": \"INFO\",\n",
      "    \"features_enabled\": [\n",
      "      \"memory_tracking\",\n",
      "      \"detailed_timing\",\n",
      "      \"config_sources_in_health\",\n",
      "      \"verbose_validation_messages\",\n",
      "      \"parameter_origin_logging\",\n",
      "      \"full_parameter_dumps_on_failure\",\n",
      "      \"debug_log_level\",\n",
      "      \"verbose_sql_logging\",\n",
      "      \"request_payload_logging\"\n",
      "    ],\n",
      "    \"is_production\": false,\n",
      "    \"verbose_enabled\": true\n",
      "  },\n",
      "  \"config_sources\": {\n",
      "    \"configs\": {\n",
      "      \"bronze_storage_account\": {\n",
      "        \"value\": \"rmhazuregeo\",\n",
      "        \"source\": \"ENV\",\n",
      "        \"env_var\": \"BRONZE_STORAGE_ACCOUNT\",\n",
      "        \"is_default\": false\n",
      "      },\n",
      "      \"managed_identity_admin_name\": {\n",
      "        \"value\": \"rmhpgflexadmin\",\n",
      "        \"source\": \"ENV\",\n",
      "        \"env_var\": \"DB_ADMIN_MANAGED_IDENTITY_NAME\",\n",
      "        \"is_default\": false\n",
      "      },\n",
      "      \"postgis_host\": {\n",
      "        \"value\": \"rmhpgflex.postgres.database.azure.com\",\n",
      "        \"source\": \"ENV\",\n",
      "        \"env_var\": \"POSTGIS_HOST\",\n",
      "        \"is_default\": false\n",
      "      },\n",
      "      \"postgis_database\": {\n",
      "        \"value\": \"geopgflex\",\n",
      "        \"source\": \"ENV\",\n",
      "        \"env_var\": \"POSTGIS_DATABASE\",\n",
      "        \"is_default\": false\n",
      "      },\n",
      "      \"titiler_base_url\": {\n",
      "        \"value\": \"https://rmhtitiler-ghcyd7g0bxdvc2hc.eastus-01.azurewebsites.net\",\n",
      "        \"source\": \"ENV\",\n",
      "        \"env_var\": \"TITILER_BASE_URL\",\n",
      "        \"is_default\": false\n",
      "      },\n",
      "      \"etl_app_base_url\": {\n",
      "        \"value\": \"https://rmhazuregeoapi-a3dma3ctfdgngwf6.eastus-01.azurewebsites.net\",\n",
      "        \"source\": \"ENV\",\n",
      "        \"env_var\": \"ETL_APP_URL\",\n",
      "        \"is_default\": false\n",
      "      },\n",
      "      \"service_bus_namespace\": {\n",
      "        \"value\": \"rmhazure.servicebus.windows.net\",\n",
      "        \"source\": \"DEFAULT\",\n",
      "        \"env_var\": \"SERVICE_BUS_NAMESPACE\",\n",
      "        \"is_default\": true\n",
      "      },\n",
      "      \"debug_mode\": {\n",
      "        \"value\": true,\n",
      "        \"source\": \"ENV\",\n",
      "        \"env_var\": \"DEBUG_MODE\",\n",
      "        \"is_default\": false\n",
      "      }\n",
      "    },\n",
      "    \"summary\": {\n",
      "      \"total_checked\": 8,\n",
      "      \"from_environment\": 7,\n",
      "      \"using_defaults\": 1\n",
      "    },\n",
      "    \"note\": \"Only shown when DEBUG_MODE=true\"\n",
      "  },\n",
      "  \"_debug_mode\": true,\n",
      "  \"_debug_notice\": \"Verbose config sources included - DEBUG_MODE=true\",\n",
      "  \"request_id\": \"e8605737-6dd1-4b11-948b-e7a09fb10bed\",\n",
      "  \"timestamp\": \"2025-12-19T06:23:05.180202+00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Health Check (takes ~60s)\n",
    "result = api_call(\"GET\", \"/api/health\", timeout=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Container Check (Sync)\n",
    "\n",
    "Quick synchronous endpoint to list blobs in a container. No job queue - returns immediately.\n",
    "\n",
    "**Parameters:**\n",
    "- `suffix`: Filter by extension (e.g., `.tif`, `.geojson`)\n",
    "- `metadata`: `true` (default) returns full blob info, `false` returns just names\n",
    "- `limit`: Max blobs to return (default: 500, max: 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GET /api/containers/rmhazuregeobronze/blobs\n",
      "============================================================\n",
      "\n",
      "Status: 200\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"zone\": \"bronze\",\n",
      "  \"container\": \"rmhazuregeobronze\",\n",
      "  \"prefix\": null,\n",
      "  \"suffix\": \".tif\",\n",
      "  \"metadata\": true,\n",
      "  \"limit\": 10,\n",
      "  \"count\": 2,\n",
      "  \"blobs\": [\n",
      "    {\n",
      "      \"name\": \"0403c87a-0c6c-4767-a6ad-78a8026258db/Vivid_Standard_30_CO02_24Q2/browse.tif\",\n",
      "      \"size\": 65227247,\n",
      "      \"last_modified\": \"2025-08-21T22:29:42+00:00\",\n",
      "      \"content_type\": \"application/octet-stream\",\n",
      "      \"etag\": \"0x8DDE10239863830\",\n",
      "      \"metadata\": {},\n",
      "      \"size_mb\": 62.21\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"0403c87a-0c6c-4767-a6ad-78a8026258db/Vivid_Standard_30_CO02_24Q2/raster_tiles/0300103212112.tif\",\n",
      "      \"size\": 87420083,\n",
      "      \"last_modified\": \"2025-08-21T22:30:01+00:00\",\n",
      "      \"content_type\": \"application/octet-stream\",\n",
      "      \"etag\": \"0x8DDE10244721508\",\n",
      "      \"metadata\": {},\n",
      "      \"size_mb\": 83.37\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "üìä Found 2 TIF files\n",
      "üì¶ Total size: 145.58 MB\n"
     ]
    }
   ],
   "source": [
    "# Container Check - Sync endpoint (returns immediately, no job queue)\n",
    "# List first 10 TIF files with full metadata\n",
    "\n",
    "result = api_call(\"GET\", f\"/api/containers/{BRONZE_CONTAINER}/blobs\", \n",
    "                  params={\"suffix\": \".tif\", \"limit\": 10, \"metadata\": \"true\"})\n",
    "\n",
    "# Show summary\n",
    "if result and isinstance(result, dict):\n",
    "    count = result.get(\"count\", 0)\n",
    "    blobs = result.get(\"blobs\", [])\n",
    "    print(f\"\\nüìä Found {count} TIF files\")\n",
    "    if blobs:\n",
    "        total_mb = sum(b.get(\"size_mb\", 0) for b in blobs)\n",
    "        print(f\"üì¶ Total size: {total_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Process Vector\n",
    "\n",
    "Submit a vector file (GeoJSON, Shapefile, GeoPackage) for ingestion into PostGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "POST /api/platform/submit\n",
      "============================================================\n",
      "\n",
      "Request Body:\n",
      "{\n",
      "  \"dataset_id\": \"test-vectors\",\n",
      "  \"resource_id\": \"geojson-8\",\n",
      "  \"version_id\": \"v1\",\n",
      "  \"container_name\": \"rmhazuregeobronze\",\n",
      "  \"file_name\": \"8.geojson\",\n",
      "  \"service_name\": \"Test GeoJSON 8\"\n",
      "}\n",
      "\n",
      "Status: 202\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"request_id\": \"c8ce488d998be1c7c7c16d950f405f9b\",\n",
      "  \"job_id\": \"f33a04e08d64c1a32cfecf06b0b2b169b9f22de2fa7edbfa0231c0488bbc4abc\",\n",
      "  \"job_type\": \"process_vector\",\n",
      "  \"message\": \"Platform request submitted. CoreMachine job created.\",\n",
      "  \"monitor_url\": \"/api/platform/status/c8ce488d998be1c7c7c16d950f405f9b\"\n",
      "}\n",
      "\n",
      "üìã Job ID: f33a04e08d64c1a32cfecf06b0b2b169b9f22de2fa7edbfa0231c0488bbc4abc\n"
     ]
    }
   ],
   "source": [
    "# Submit Vector\n",
    "vector_request = {\n",
    "    \"dataset_id\": \"test-vectors\",\n",
    "    \"resource_id\": \"geojson-8\",\n",
    "    \"version_id\": \"v1\",\n",
    "    \"container_name\": BRONZE_CONTAINER,\n",
    "    \"file_name\": \"8.geojson\",\n",
    "    \"service_name\": \"Test GeoJSON 8\"\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/platform/submit\", vector_request)\n",
    "vector_job_id = result.get(\"job_id\") if result else None\n",
    "print(f\"\\nüìã Job ID: {vector_job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Polling job: f33a04e08d64c1a32cfecf06b0b2b169b9f22de2fa7edbfa0231c0488bbc4abc\n",
      "============================================================\n",
      "  [1/20] Status: processing, Stage: ?\n",
      "  [2/20] Status: processing, Stage: ?\n",
      "  [3/20] Status: completed, Stage: ?\n",
      "\n",
      "Final Result:\n",
      "{\n",
      "  \"jobId\": \"f33a04e08d64c1a32cfecf06b0b2b169b9f22de2fa7edbfa0231c0488bbc4abc\",\n",
      "  \"jobType\": \"process_vector\",\n",
      "  \"status\": \"completed\",\n",
      "  \"stage\": 3,\n",
      "  \"totalStages\": 3,\n",
      "  \"parameters\": {\n",
      "    \"schema\": \"geo\",\n",
      "    \"indexes\": {\n",
      "      \"spatial\": true,\n",
      "      \"temporal\": [],\n",
      "      \"attributes\": []\n",
      "    },\n",
      "    \"blob_name\": \"8.geojson\",\n",
      "    \"overwrite\": false,\n",
      "    \"table_name\": \"test_vectors_geojson_8_v1\",\n",
      "    \"container_name\": \"rmhazuregeobronze\",\n",
      "    \"file_extension\": \"geojson\",\n",
      "    \"geometry_params\": {},\n",
      "    \"converter_params\": {}\n",
      "  },\n",
      "  \"stageResults\": {},\n",
      "  \"createdAt\": \"2025-12-19T06:23:47.477602\",\n",
      "  \"updatedAt\": \"2025-12-19T06:24:01.758466\",\n",
      "  \"resultData\": {\n",
      "    \"stac\": {\n",
      "      \"bbox\": [\n",
      "        -71.226859,\n",
      "        -56.318334,\n",
      "        -69.547205,\n",
      "        -54.679262\n",
      "      ],\n",
      "      \"stac_id\": null,\n",
      "      \"pgstac_id\": null,\n",
      "      \"collection_id\": \"system-vectors\",\n",
      "      \"feature_count\": null,\n",
      "      \"inserted_to_pgstac\": true\n",
      "    },\n",
      "    \"schema\": \"geo\",\n",
      "    \"summary\": {\n",
      "      \"success_rate\": \"100.0%\",\n",
      "      \"total_chunks\": 10,\n",
      "      \"chunks_failed\": 0,\n",
      "      \"data_complete\": true,\n",
      "      \"chunks_uploaded\": 10,\n",
      "      \"stage_1_metadata\": {\n",
      "        \"chunk_count\": 10,\n",
      "        \"total_features\": 3879,\n",
      "        \"chunk_size_used\": 400\n",
      "      },\n",
      "      \"total_rows_deleted\": 0,\n",
      "      \"total_rows_inserted\": 3879,\n",
      "      \"idempotent_reruns_detected\": false\n",
      "    },\n",
      "    \"job_type\": \"process_vector\",\n",
      "    \"blob_name\": \"8.geojson\",\n",
      "    \"table_name\": \"test_vectors_geojson_8_v1\",\n",
      "    \"viewer_url\": \"https://rmhazuregeoapi-a3dma3ctfdgngwf6.eastus-01.azurewebsites.net/api/vector/viewer?collection=test_vectors_geojson_8_v1\",\n",
      "    \"container_name\": \"rmhazuregeobronze\",\n",
      "    \"file_extension\": \"geojson\",\n",
      "    \"tasks_by_status\": {\n",
      "      \"failed\": 0,\n",
      "      \"queued\": 0,\n",
      "      \"completed\": 12\n",
      "    },\n",
      "    \"ogc_features_url\": \"https://rmhogcstac-b4f5ccetf0a7hwe9.eastus-01.azurewebsites.net/api/features/collections/test_vectors_geojson_8_v1\",\n",
      "    \"stages_completed\": 3,\n",
      "    \"total_tasks_executed\": 12\n",
      "  },\n",
      "  \"taskSummary\": {\n",
      "    \"total\": 12,\n",
      "    \"completed\": 12,\n",
      "    \"failed\": 0,\n",
      "    \"processing\": 0,\n",
      "    \"pending\": 0,\n",
      "    \"queued\": 0,\n",
      "    \"byStage\": {\n",
      "      \"1\": {\n",
      "        \"total\": 1,\n",
      "        \"completed\": 1,\n",
      "        \"taskTypes\": [\n",
      "          \"process_vector_prepare\"\n",
      "        ]\n",
      "      },\n",
      "      \"2\": {\n",
      "        \"total\": 10,\n",
      "        \"completed\": 10,\n",
      "        \"taskTypes\": [\n",
      "          \"process_vector_upload\"\n",
      "        ]\n",
      "      },\n",
      "      \"3\": {\n",
      "        \"total\": 1,\n",
      "        \"completed\": 1,\n",
      "        \"taskTypes\": [\n",
      "          \"create_vector_stac\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"architecture\": \"strong_typing_discipline\",\n",
      "  \"pattern\": \"Job\\u2192Stage\\u2192Task with Pydantic validation\",\n",
      "  \"schema_validated\": true,\n",
      "  \"request_id\": \"39809178\",\n",
      "  \"timestamp\": \"2025-12-19T06:24:02.460920+00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check Vector Job Status\n",
    "if vector_job_id:\n",
    "    check_job_status(vector_job_id)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No job_id from previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Process Raster (Single File)\n",
    "\n",
    "Submit a single raster file for COG conversion and STAC cataloging.\n",
    "\n",
    "### Size Limits (13 DEC 2025)\n",
    "\n",
    "| Limit | Value | Behavior |\n",
    "|-------|-------|----------|\n",
    "| **Max file size** | 800 MB | Files >800MB rejected ‚Üí use `process_large_raster_v2` |\n",
    "| **Min file size** | None | Any size accepted |\n",
    "\n",
    "**Pre-flight validation** automatically checks file size before processing.\n",
    "\n",
    "### Test Data\n",
    "- **dctest.tif** (25.8 MB) - Small RGB GeoTIFF, processes in ~22 seconds\n",
    "- **antigua.tif** (11.16 GB) - Too large, will be rejected with error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit Single Raster via CoreMachine API (direct)\n",
    "# Using dctest.tif (25.8 MB) - verified working 13 DEC 2025\n",
    "\n",
    "raster_request = {\n",
    "    \"blob_name\": \"dctest.tif\",\n",
    "    \"container_name\": BRONZE_CONTAINER\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/jobs/submit/process_raster_v2\", raster_request)\n",
    "raster_job_id = result.get(\"job_id\") if result else None\n",
    "\n",
    "# Show size metadata from pre-flight validation\n",
    "if result and \"parameters\" in result:\n",
    "    params = result[\"parameters\"]\n",
    "    print(f\"\\nüìè Pre-flight Size Check:\")\n",
    "    print(f\"   File size: {params.get('_blob_size_mb', 'N/A'):.2f} MB\")\n",
    "    print(f\"   File exists: ‚úÖ\")\n",
    "\n",
    "print(f\"\\nüìã Job ID: {raster_job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Raster Job Status\n",
    "if raster_job_id:\n",
    "    check_job_status(raster_job_id)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No job_id from previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Process Large Raster (100 MB - 30 GB)\n",
    "\n",
    "Submit a large raster for tiled COG processing. Uses 5-stage workflow:\n",
    "1. Generate tiling scheme\n",
    "2. Extract tiles (sequential)\n",
    "3. Create COGs (parallel)\n",
    "4. Create MosaicJSON\n",
    "5. Create STAC collection\n",
    "\n",
    "### Size Limits (13 DEC 2025)\n",
    "\n",
    "| Limit | Value | Behavior |\n",
    "|-------|-------|----------|\n",
    "| **Min file size** | 100 MB | Files <100MB should use `process_raster_v2` |\n",
    "| **Max file size** | 30 GB | Files >30GB not supported |\n",
    "\n",
    "### Test Data\n",
    "- **antigua.tif** (11.16 GB) - Maxar Vivid Imagery of Antigua island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit Large Raster via CoreMachine API (direct)\n",
    "# Using antigua.tif (11.16 GB) - verified 13 DEC 2025\n",
    "# Note: This is a long-running job (~30+ minutes for tiling and COG creation)\n",
    "\n",
    "large_raster_request = {\n",
    "    \"blob_name\": \"antigua.tif\",\n",
    "    \"container_name\": BRONZE_CONTAINER\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/jobs/submit/process_large_raster_v2\", large_raster_request)\n",
    "large_raster_job_id = result.get(\"job_id\") if result else None\n",
    "\n",
    "# Show size metadata from pre-flight validation\n",
    "if result and \"parameters\" in result:\n",
    "    params = result[\"parameters\"]\n",
    "    size_mb = params.get('_blob_size_mb', 0)\n",
    "    print(f\"\\nüìè Pre-flight Size Check:\")\n",
    "    print(f\"   File size: {size_mb:.2f} MB ({size_mb/1024:.2f} GB)\")\n",
    "    print(f\"   Valid for large raster: {'‚úÖ' if 100 <= size_mb <= 30000 else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\nüìã Job ID: {large_raster_job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Large Raster Job Status\n",
    "if large_raster_job_id:\n",
    "    check_job_status(large_raster_job_id, max_polls=30, poll_interval=10)  # Longer timeout for large files\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No job_id from previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Process Raster Collection (Multi-File)\n",
    "\n",
    "Submit multiple raster files to be processed as a collection with MosaicJSON.\n",
    "\n",
    "### Size and Count Limits (13 DEC 2025)\n",
    "\n",
    "| Limit | Value | Behavior |\n",
    "|-------|-------|----------|\n",
    "| **Max files per collection** | 20 | Collections with >20 files rejected |\n",
    "| **Max individual file size** | 800 MB | Collections with ANY file >800MB rejected |\n",
    "| **Min files per collection** | 2 | Single files should use `process_raster_v2` |\n",
    "\n",
    "**Pre-flight validation order:**\n",
    "1. **Collection count** - Rejected immediately if >20 files (before any blob checks)\n",
    "2. **Individual file sizes** - Each blob checked in parallel; rejected if ANY exceeds 800MB\n",
    "3. **File existence** - All blobs must exist in the container\n",
    "\n",
    "### Size Metadata Captured\n",
    "After validation, these fields are available in job parameters:\n",
    "- `_blob_list_count` - Number of files\n",
    "- `_blob_list_max_size_mb` - Largest file size\n",
    "- `_blob_list_total_size_mb` - Total size of all files\n",
    "- `_blob_list_largest_blob` - Name of largest file\n",
    "- `_blob_list_has_large_raster` - True if any file >800MB\n",
    "\n",
    "### Test Data\n",
    "- **namangan/** folder (4 tiles, 1.6 GB total):\n",
    "  - R1C1: 778 MB, R1C2: 704 MB, R2C1: 73 MB, R2C2: 65 MB\n",
    "  - All under 800 MB limit ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit Raster Collection via CoreMachine API (direct)\n",
    "# Using namangan 4-tile collection (1.6 GB total) - verified 13 DEC 2025\n",
    "\n",
    "collection_request = {\n",
    "    \"container_name\": BRONZE_CONTAINER,\n",
    "    \"blob_list\": [\n",
    "        \"namangan/namangan14aug2019_R1C1cog.tif\",  # 778 MB\n",
    "        \"namangan/namangan14aug2019_R1C2cog.tif\",  # 704 MB\n",
    "        \"namangan/namangan14aug2019_R2C1cog.tif\",  # 73 MB\n",
    "        \"namangan/namangan14aug2019_R2C2cog.tif\"   # 65 MB\n",
    "    ],\n",
    "    \"collection_id\": \"namangan-test\"\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/jobs/submit/process_raster_collection_v2\", collection_request)\n",
    "collection_job_id = result.get(\"job_id\") if result else None\n",
    "\n",
    "# Show size metadata from pre-flight validation\n",
    "if result and \"parameters\" in result:\n",
    "    params = result[\"parameters\"]\n",
    "    print(f\"\\nüìè Pre-flight Size Check:\")\n",
    "    print(f\"   Files in collection: {params.get('_blob_list_count', 'N/A')}\")\n",
    "    print(f\"   Largest file: {params.get('_blob_list_max_size_mb', 0):.2f} MB\")\n",
    "    print(f\"   Total size: {params.get('_blob_list_total_size_mb', 0):.2f} MB\")\n",
    "    print(f\"   Largest blob: {params.get('_blob_list_largest_blob', 'N/A')}\")\n",
    "    print(f\"   Has large raster (>800MB): {'‚ùå Yes' if params.get('_blob_list_has_large_raster') else '‚úÖ No'}\")\n",
    "\n",
    "print(f\"\\nüìã Job ID: {collection_job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Raster Collection Job Status\n",
    "if collection_job_id:\n",
    "    check_job_status(collection_job_id, max_polls=30, poll_interval=10)  # Longer timeout for multi-file\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No job_id from previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Reference: Manual Job Status Check\n",
    "\n",
    "Use this cell to check any job by ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Job Status Check\n",
    "# Replace with your job_id\n",
    "manual_job_id = \"YOUR_JOB_ID_HERE\"\n",
    "\n",
    "if manual_job_id != \"YOUR_JOB_ID_HERE\":\n",
    "    check_job_status(manual_job_id)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Replace 'YOUR_JOB_ID_HERE' with an actual job_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Rejection Examples (Size/Count Limit Violations)\n",
    "\n",
    "These examples demonstrate the pre-flight validation rejecting invalid requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Single raster too large (>800 MB)\n",
    "# antigua.tif is 11.16 GB - should be rejected with message to use process_large_raster_v2\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Single raster exceeding 800 MB limit\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "large_single_request = {\n",
    "    \"blob_name\": \"antigua.tif\",  # 11.16 GB\n",
    "    \"container_name\": BRONZE_CONTAINER\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/jobs/submit/process_raster_v2\", large_single_request)\n",
    "if result and \"error\" in result:\n",
    "    print(f\"\\n‚úÖ Correctly rejected: {result.get('message', '')[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Collection with too many files (>20)\n",
    "# Should be rejected before any blob checks are made\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Collection exceeding 20 file limit\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "too_many_files_request = {\n",
    "    \"container_name\": BRONZE_CONTAINER,\n",
    "    \"blob_list\": [f\"file{i}.tif\" for i in range(21)],  # 21 files\n",
    "    \"collection_id\": \"test-too-many\"\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/jobs/submit/process_raster_collection_v2\", too_many_files_request)\n",
    "if result and \"error\" in result:\n",
    "    print(f\"\\n‚úÖ Correctly rejected: {result.get('message', '')[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Collection with missing blob\n",
    "# Should be rejected with list of missing files\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Collection with non-existent file\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_blob_request = {\n",
    "    \"container_name\": BRONZE_CONTAINER,\n",
    "    \"blob_list\": [\n",
    "        \"namangan/namangan14aug2019_R1C1cog.tif\",  # exists\n",
    "        \"nonexistent_file_xyz123.tif\"               # does not exist\n",
    "    ],\n",
    "    \"collection_id\": \"test-missing\"\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/jobs/submit/process_raster_collection_v2\", missing_blob_request)\n",
    "if result and \"error\" in result:\n",
    "    print(f\"\\n‚úÖ Correctly rejected: {result.get('message', '')[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# Platform API (Anti-Corruption Layer)\n\nThe Platform API is an **Anti-Corruption Layer (ACL)** that shields external applications from CoreMachine internals. External apps use high-level DDH identifiers (`dataset_id`, `resource_id`, `version_id`); Platform translates them to CoreMachine job parameters automatically.\n\n### Platform API vs CoreMachine API\n\n| Aspect | Platform API | CoreMachine API |\n|--------|--------------|-----------------|\n| **Audience** | External applications (DDH) | Internal tools, power users |\n| **Identifiers** | `dataset_id`, `resource_id`, `version_id` | `blob_name`, `table_name`, `collection_id` |\n| **Output naming** | Auto-generated from DDH IDs | You specify everything |\n| **Status tracking** | `request_id` (DDH-friendly) | `job_id` (internal hash) |\n\n### Endpoints Summary\n\n| Endpoint | Purpose |\n|----------|---------|\n| `/api/platform/raster` | Single raster file processing |\n| `/api/platform/raster-collection` | Multiple raster files (2-20 files) |\n| `/api/platform/submit` | Generic submission (auto-detects data type) |\n| `/api/platform/status/{request_id}` | Check request/job status |\n| `/api/platform/unpublish/vector` | Remove vector data |\n| `/api/platform/unpublish/raster` | Remove raster data |\n\n**Note**: For system health, use `/api/health`. For job failures, use `/api/dbadmin/jobs?status=failed`."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Platform API - Single Raster\n",
    "\n",
    "Submit a single raster file using DDH identifiers. Output paths are auto-generated from identifiers.\n",
    "\n",
    "### Key Benefit\n",
    "Files exceeding 800 MB are automatically routed to the large raster tiling workflow - no action required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform API - Single Raster with DDH Identifiers\n",
    "# Uses dataset_id/resource_id/version_id for output naming\n",
    "\n",
    "platform_raster_request = {\n",
    "    \"dataset_id\": \"test-raster-notebook\",\n",
    "    \"resource_id\": \"dctest\",\n",
    "    \"version_id\": \"v1\",\n",
    "    \"container_name\": BRONZE_CONTAINER,\n",
    "    \"file_name\": \"dctest.tif\",\n",
    "    \"service_name\": \"DC Test Imagery\",\n",
    "    \"access_level\": \"OUO\",\n",
    "    \"description\": \"Test raster via Platform API\"\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/platform/raster\", platform_raster_request)\n",
    "platform_raster_request_id = result.get(\"request_id\") if result else None\n",
    "platform_raster_job_id = result.get(\"job_id\") if result else None\n",
    "\n",
    "print(f\"\\nüìã Request ID: {platform_raster_request_id}\")\n",
    "print(f\"üìã Job ID: {platform_raster_job_id}\")\n",
    "if result:\n",
    "    print(f\"üìç Monitor URL: {result.get('monitor_url', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Platform API - Raster Collection\n",
    "\n",
    "Submit multiple raster files using DDH identifiers. Creates a unified STAC collection with MosaicJSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform API - Raster Collection with DDH Identifiers\n",
    "# Uses dataset_id/resource_id/version_id for output naming\n",
    "\n",
    "platform_collection_request = {\n",
    "    \"dataset_id\": \"namangan-imagery\",\n",
    "    \"resource_id\": \"aug2019\",\n",
    "    \"version_id\": \"v1\",\n",
    "    \"container_name\": BRONZE_CONTAINER,\n",
    "    \"file_name\": [\n",
    "        \"namangan/namangan14aug2019_R1C1cog.tif\",\n",
    "        \"namangan/namangan14aug2019_R1C2cog.tif\",\n",
    "        \"namangan/namangan14aug2019_R2C1cog.tif\",\n",
    "        \"namangan/namangan14aug2019_R2C2cog.tif\"\n",
    "    ],\n",
    "    \"service_name\": \"Namangan Satellite Imagery\",\n",
    "    \"access_level\": \"OUO\"\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/platform/raster-collection\", platform_collection_request)\n",
    "platform_collection_request_id = result.get(\"request_id\") if result else None\n",
    "\n",
    "print(f\"\\nüìã Request ID: {platform_collection_request_id}\")\n",
    "print(f\"üìã File Count: {result.get('file_count', 'N/A')}\" if result else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Platform Status Check\n",
    "\n",
    "Check request status using DDH-friendly `request_id` (shorter than `job_id`).\n",
    "\n",
    "Returns comprehensive status including job progress, stage info, and task summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform Status Check - Use request_id from Platform submission\n",
    "# Replace with your request_id from earlier Platform API calls\n",
    "\n",
    "platform_request_id = platform_raster_request_id or \"YOUR_REQUEST_ID_HERE\"\n",
    "\n",
    "if platform_request_id and platform_request_id != \"YOUR_REQUEST_ID_HERE\":\n",
    "    result = api_call(\"GET\", f\"/api/platform/status/{platform_request_id}\")\n",
    "    \n",
    "    if result and result.get(\"success\"):\n",
    "        print(f\"\\nüìä Status Summary:\")\n",
    "        print(f\"   Job Status: {result.get('job_status', 'N/A')}\")\n",
    "        print(f\"   Job Stage: {result.get('job_stage', 'N/A')}\")\n",
    "        print(f\"   Data Type: {result.get('data_type', 'N/A')}\")\n",
    "        \n",
    "        task_summary = result.get('task_summary', {})\n",
    "        if task_summary:\n",
    "            print(f\"\\n   Tasks: {task_summary.get('completed', 0)}/{task_summary.get('total', 0)} completed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set platform_request_id to a valid request_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Unpublish Vector Data\n",
    "\n",
    "Remove vector data from the platform. Three ways to identify what to delete:\n",
    "\n",
    "1. **By DDH Identifiers** (Preferred) - Uses `dataset_id`, `resource_id`, `version_id`\n",
    "2. **By Request ID** - Uses original platform request_id from submission\n",
    "3. **Cleanup Mode** - Direct table_name for orphaned data\n",
    "\n",
    "### Workflow Stages\n",
    "1. **Inventory** - Query `geo.table_metadata` for ETL/STAC linkage\n",
    "2. **Drop Table** - DROP PostGIS table + DELETE metadata row\n",
    "3. **Cleanup** - Delete STAC item if linked + create audit record\n",
    "\n",
    "### Important\n",
    "- Default `dry_run=true` for safety (shows what would be deleted)\n",
    "- Set `dry_run=false` to actually execute deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpublish Vector - Option 1: By DDH Identifiers (Preferred)\n",
    "# dry_run=true shows what would be deleted without executing\n",
    "\n",
    "unpublish_vector_ddh = {\n",
    "    \"dataset_id\": \"test-vectors\",\n",
    "    \"resource_id\": \"geojson-8\",\n",
    "    \"version_id\": \"v1\",\n",
    "    \"dry_run\": True  # Set to False to actually delete\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/platform/unpublish/vector\", unpublish_vector_ddh)\n",
    "if result:\n",
    "    print(f\"\\nüìã Mode: {result.get('mode', 'N/A')}\")\n",
    "    print(f\"üîç Dry Run: {result.get('dry_run', 'N/A')}\")\n",
    "    print(f\"üìç Table: {result.get('table_name', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpublish Vector - Option 2: By Request ID\n",
    "# Uses the request_id from the original platform submission\n",
    "\n",
    "unpublish_vector_request = {\n",
    "    \"request_id\": \"YOUR_ORIGINAL_REQUEST_ID\",  # From /api/platform/submit response\n",
    "    \"dry_run\": True\n",
    "}\n",
    "\n",
    "# Uncomment to test (replace with actual request_id)\n",
    "# result = api_call(\"POST\", \"/api/platform/unpublish/vector\", unpublish_vector_request)\n",
    "print(\"‚ö†Ô∏è Uncomment and replace request_id to test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpublish Vector - Option 3: Cleanup Mode (Direct table_name)\n",
    "# For orphaned tables that don't have platform request records\n",
    "\n",
    "unpublish_vector_cleanup = {\n",
    "    \"table_name\": \"orphaned_table_v1_0\",\n",
    "    \"schema_name\": \"geo\",  # Optional, defaults to \"geo\"\n",
    "    \"dry_run\": True\n",
    "}\n",
    "\n",
    "# Uncomment to test (replace with actual table_name)\n",
    "# result = api_call(\"POST\", \"/api/platform/unpublish/vector\", unpublish_vector_cleanup)\n",
    "print(\"‚ö†Ô∏è Uncomment and replace table_name to test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Unpublish Raster Data\n",
    "\n",
    "Remove raster data from the platform. Three ways to identify what to delete:\n",
    "\n",
    "1. **By DDH Identifiers** (Preferred) - Uses `dataset_id`, `resource_id`, `version_id`\n",
    "2. **By Request ID** - Uses original platform request_id from submission\n",
    "3. **Cleanup Mode** - Direct STAC identifiers for orphaned data\n",
    "\n",
    "### Workflow Stages\n",
    "1. **Inventory** - Query STAC item, extract asset hrefs for deletion\n",
    "2. **Delete Blobs** - Fan-out deletion of COG/MosaicJSON blobs\n",
    "3. **Cleanup** - Delete STAC item + create audit record\n",
    "\n",
    "### Important\n",
    "- Default `dry_run=true` for safety (shows what would be deleted)\n",
    "- Set `dry_run=false` to actually execute deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpublish Raster - Option 1: By DDH Identifiers (Preferred)\n",
    "# dry_run=true shows what would be deleted without executing\n",
    "\n",
    "unpublish_raster_ddh = {\n",
    "    \"dataset_id\": \"test-raster-notebook\",\n",
    "    \"resource_id\": \"dctest\",\n",
    "    \"version_id\": \"v1\",\n",
    "    \"dry_run\": True  # Set to False to actually delete\n",
    "}\n",
    "\n",
    "result = api_call(\"POST\", \"/api/platform/unpublish/raster\", unpublish_raster_ddh)\n",
    "if result:\n",
    "    print(f\"\\nüìã Mode: {result.get('mode', 'N/A')}\")\n",
    "    print(f\"üîç Dry Run: {result.get('dry_run', 'N/A')}\")\n",
    "    print(f\"üìç STAC Item: {result.get('stac_item_id', 'N/A')}\")\n",
    "    print(f\"üìÅ Collection: {result.get('collection_id', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpublish Raster - Option 2: By Request ID\n",
    "# Uses the request_id from the original platform submission\n",
    "\n",
    "unpublish_raster_request = {\n",
    "    \"request_id\": \"YOUR_ORIGINAL_REQUEST_ID\",  # From /api/platform/raster response\n",
    "    \"dry_run\": True\n",
    "}\n",
    "\n",
    "# Uncomment to test (replace with actual request_id)\n",
    "# result = api_call(\"POST\", \"/api/platform/unpublish/raster\", unpublish_raster_request)\n",
    "print(\"‚ö†Ô∏è Uncomment and replace request_id to test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpublish Raster - Option 3: Cleanup Mode (Direct STAC identifiers)\n",
    "# For orphaned STAC items that don't have platform request records\n",
    "\n",
    "unpublish_raster_cleanup = {\n",
    "    \"stac_item_id\": \"aerial-imagery-2024-site-alpha-v1-0\",\n",
    "    \"collection_id\": \"aerial-imagery-2024\",\n",
    "    \"dry_run\": True\n",
    "}\n",
    "\n",
    "# Uncomment to test (replace with actual STAC identifiers)\n",
    "# result = api_call(\"POST\", \"/api/platform/unpublish/raster\", unpublish_raster_cleanup)\n",
    "print(\"‚ö†Ô∏è Uncomment and replace STAC identifiers to test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}