"""
STAC Catalog Services - Two-Stage Pattern for Bulk STAC Extraction

Stage 1: list_raster_files - Returns list of raster file names
Stage 2: extract_stac_metadata - Extracts STAC metadata and inserts into PgSTAC

Author: Robert and Geospatial Claude Legion
Date: 6 OCT 2025
"""

from typing import Any
from datetime import datetime
from infrastructure.blob import BlobRepository
# NOTE: StacMetadataService import moved inside extract_stac_metadata() to avoid
# stac-pydantic import at module load time (allows registry to build without STAC deps)


def list_raster_files(params: dict) -> dict[str, Any]:
    """
    Stage 1: List all raster files in container.

    Returns list of raster file names for Stage 2 fan-out.

    Args:
        params: {
            "container_name": str,
            "extension_filter": str (default: ".tif"),
            "prefix": str (default: ""),
            "file_limit": int | None
        }

    Returns:
        Dict with success status and raster file list:
        {
            "success": True,
            "result": {
                "raster_files": [list of raster file names],
                "total_count": int,
                "extension_filter": str,
                "execution_info": {...}
            }
        }
    """
    try:
        container_name = params["container_name"]
        extension_filter = params.get("extension_filter", ".tif").lower()
        prefix = params.get("prefix", "")
        file_limit = params.get("file_limit")

        blob_repo = BlobRepository.instance()

        start_time = datetime.utcnow()

        # Get all blobs
        blobs = blob_repo.list_blobs(
            container=container_name,
            prefix=prefix,
            limit=None  # Get all, then filter
        )

        # Filter by extension
        raster_files = []
        for blob in blobs:
            blob_name = blob['name']
            if blob_name.lower().endswith(extension_filter):
                raster_files.append(blob_name)

                # Apply file_limit if specified
                if file_limit and len(raster_files) >= file_limit:
                    break

        duration = (datetime.utcnow() - start_time).total_seconds()

        # SUCCESS - return raster file names for Stage 2
        return {
            "success": True,
            "result": {
                "raster_files": raster_files,
                "total_count": len(raster_files),
                "extension_filter": extension_filter,
                "container_name": container_name,
                "prefix": prefix,
                "execution_info": {
                    "scan_duration_seconds": round(duration, 2),
                    "total_blobs_scanned": len(blobs),
                    "raster_files_found": len(raster_files),
                    "file_limit_applied": file_limit is not None
                }
            }
        }

    except Exception as e:
        # FAILURE - return error
        return {
            "success": False,
            "error": str(e) or type(e).__name__,
            "error_type": type(e).__name__,
            "container_name": params.get("container_name")
        }


def extract_stac_metadata(params: dict) -> dict[str, Any]:
    """
    Stage 2: Extract STAC metadata for a single raster file.

    This function is called once per raster file in parallel.
    Extracts STAC Item metadata and inserts into PgSTAC database.

    Args:
        params: {
            "container_name": str,
            "blob_name": str,
            "collection_id": str (default: "dev")
        }

    Returns:
        Dict with success status and STAC metadata:
        {
            "success": True,
            "result": {
                "item_id": str,
                "blob_name": str,
                "collection_id": str,
                "bbox": [float, float, float, float],
                "geometry_type": str,
                "bands_count": int,
                "epsg": int,
                "inserted_to_pgstac": bool,
                "stac_item": {...}  # Full STAC Item
            }
        }
    """
    # CRITICAL: Log entry BEFORE any imports to confirm handler is called
    import sys
    print(f"üöÄ HANDLER ENTRY: extract_stac_metadata called with params keys: {list(params.keys())}", file=sys.stderr, flush=True)
    print(f"üöÄ HANDLER ENTRY: blob_name={params.get('blob_name', 'MISSING')}", file=sys.stderr, flush=True)

    # STEP 0: Import dependencies with explicit error handling
    # These imports are logged separately to catch import failures that prevent handler execution
    logger = None  # Initialize to None for error handling
    try:
        print(f"üì¶ STEP 0A: Importing LoggerFactory and traceback...", file=sys.stderr, flush=True)
        from util_logger import LoggerFactory, ComponentType
        import traceback
        logger = LoggerFactory.create_logger(ComponentType.SERVICE, "extract_stac_metadata")
        logger.info("‚úÖ STEP 0A: Logger initialized successfully")
        print(f"‚úÖ STEP 0A: Logger initialized", file=sys.stderr, flush=True)

        print(f"üì¶ STEP 0B: Importing StacMetadataService (lazy import - may trigger stac-pydantic)...", file=sys.stderr, flush=True)
        logger.info("üì¶ STEP 0B: Starting lazy import of StacMetadataService...")
        from .service_stac_metadata import StacMetadataService
        logger.info("‚úÖ STEP 0B: StacMetadataService imported successfully")
        print(f"‚úÖ STEP 0B: StacMetadataService imported", file=sys.stderr, flush=True)

        print(f"üì¶ STEP 0C: Importing StacInfrastructure...", file=sys.stderr, flush=True)
        logger.info("üì¶ STEP 0C: Importing StacInfrastructure...")
        from infrastructure.stac import StacInfrastructure
        logger.info("‚úÖ STEP 0C: StacInfrastructure imported successfully")
        print(f"‚úÖ STEP 0C: All imports successful!", file=sys.stderr, flush=True)

    except ImportError as e:
        error_msg = f"IMPORT FAILED: {e}"
        print(f"‚ùå {error_msg}", file=sys.stderr, flush=True)
        if logger:
            logger.error(f"‚ùå {error_msg}\n{traceback.format_exc()}")
        return {
            "success": False,
            "error": error_msg,
            "error_type": "ImportError",
            "import_failed": True,
            "failed_module": str(e),
            "blob_name": params.get("blob_name"),
            "container_name": params.get("container_name"),
            "traceback": traceback.format_exc() if 'traceback' in dir() else str(e)
        }
    except Exception as e:
        error_msg = f"UNEXPECTED ERROR DURING IMPORTS: {type(e).__name__}: {e}"
        print(f"‚ùå {error_msg}", file=sys.stderr, flush=True)
        if logger:
            logger.error(f"‚ùå {error_msg}\n{traceback.format_exc() if 'traceback' in dir() else ''}")
        return {
            "success": False,
            "error": error_msg,
            "error_type": type(e).__name__,
            "import_phase_error": True,
            "blob_name": params.get("blob_name"),
            "container_name": params.get("container_name")
        }

    try:
        # STEP 1: Extract parameters
        try:
            container_name = params["container_name"]
            blob_name = params["blob_name"]
            collection_id = params.get("collection_id", "dev")
            logger.info(f"üìã STEP 1: Parameters extracted - container={container_name}, blob={blob_name[:50]}..., collection={collection_id}")
        except Exception as e:
            logger.error(f"‚ùå STEP 1 FAILED: Parameter extraction error: {e}")
            raise

        start_time = datetime.utcnow()

        # STEP 2: Initialize STAC service
        try:
            logger.debug(f"üîß STEP 2: Initializing StacMetadataService...")
            stac_service = StacMetadataService()
            logger.info(f"‚úÖ STEP 2: StacMetadataService initialized")
        except Exception as e:
            logger.error(f"‚ùå STEP 2 FAILED: StacMetadataService initialization error: {e}\n{traceback.format_exc()}")
            raise

        # STEP 3: Extract STAC item from blob (THIS IS THE SLOW PART)
        try:
            logger.info(f"üì° STEP 3: Starting STAC extraction from blob (this may take 30-60s)...")
            extract_start = datetime.utcnow()

            item = stac_service.extract_item_from_blob(
                container=container_name,
                blob_name=blob_name,
                collection_id=collection_id
            )

            extract_duration = (datetime.utcnow() - extract_start).total_seconds()
            logger.info(f"‚úÖ STEP 3: STAC extraction completed in {extract_duration:.2f}s - item_id={item.id}")
        except Exception as e:
            extract_duration = (datetime.utcnow() - extract_start).total_seconds() if 'extract_start' in locals() else 0
            logger.error(f"‚ùå STEP 3 FAILED after {extract_duration:.2f}s: STAC extraction error: {e}\n{traceback.format_exc()}")
            raise

        # STEP 4: Initialize PgSTAC infrastructure
        try:
            logger.debug(f"üóÑÔ∏è STEP 4: Initializing StacInfrastructure...")
            stac_infra = StacInfrastructure()
            logger.info(f"‚úÖ STEP 4: StacInfrastructure initialized")
        except Exception as e:
            logger.error(f"‚ùå STEP 4 FAILED: StacInfrastructure initialization error: {e}\n{traceback.format_exc()}")
            raise

        # STEP 5: Insert into PgSTAC (with idempotency check)
        try:
            insert_start = datetime.utcnow()

            # Check if item already exists (idempotency)
            logger.debug(f"üîç STEP 5A: Checking if item {item.id} already exists in collection {collection_id}...")
            if stac_infra.item_exists(item.id, collection_id):
                logger.info(f"‚è≠Ô∏è STEP 5: Item {item.id} already exists in PgSTAC - skipping insertion (idempotent)")
                insert_result = {
                    'success': True,
                    'item_id': item.id,
                    'collection': collection_id,
                    'skipped': True,
                    'reason': 'Item already exists (idempotent operation)'
                }
            else:
                # Item doesn't exist - insert it
                logger.info(f"üíæ STEP 5B: Inserting new item {item.id} into PgSTAC collection {collection_id}...")
                insert_result = stac_infra.insert_item(item, collection_id)
                logger.info(f"‚úÖ STEP 5B: PgSTAC insert completed - success={insert_result.get('success')}")

            insert_duration = (datetime.utcnow() - insert_start).total_seconds()
            logger.info(f"‚úÖ STEP 5: PgSTAC operation completed in {insert_duration:.2f}s")
        except Exception as e:
            insert_duration = (datetime.utcnow() - insert_start).total_seconds() if 'insert_start' in locals() else 0
            logger.error(f"‚ùå STEP 5 FAILED after {insert_duration:.2f}s: PgSTAC error: {e}\n{traceback.format_exc()}")
            raise

        duration = (datetime.utcnow() - start_time).total_seconds()

        # STEP 6: Extract metadata for summary
        try:
            logger.debug(f"üìä STEP 6: Extracting metadata summary...")
            item_dict = item.model_dump(mode='json', by_alias=True)
            bbox = item.bbox
            # FIX: item.geometry is Shapely object, not dict - use item_dict instead
            geometry_type = item_dict.get('geometry', {}).get('type', 'Unknown') if item_dict.get('geometry') else 'Unknown'

            # Count raster bands if present
            bands_count = 0
            if 'assets' in item_dict:
                for asset in item_dict['assets'].values():
                    if 'raster:bands' in asset:
                        bands_count = len(asset['raster:bands'])
                        break

            # Get EPSG code
            epsg = item_dict.get('properties', {}).get('proj:epsg')

            logger.info(f"‚úÖ STEP 6: Metadata extracted - bbox={bbox}, epsg={epsg}, bands={bands_count}")
        except Exception as e:
            logger.error(f"‚ùå STEP 6 FAILED: Metadata extraction error: {e}\n{traceback.format_exc()}")
            raise

        # SUCCESS - return STAC metadata
        logger.info(f"üéâ SUCCESS: STAC cataloging completed in {duration:.2f}s for {blob_name}")
        return {
            "success": True,
            "result": {
                "item_id": item.id,
                "blob_name": blob_name,
                "collection_id": collection_id,
                "bbox": bbox,
                "geometry_type": geometry_type,
                "bands_count": bands_count,
                "epsg": epsg,
                "inserted_to_pgstac": insert_result.get('success', False),
                "item_skipped": insert_result.get('skipped', False),
                "skip_reason": insert_result.get('reason') if insert_result.get('skipped') else None,
                "insert_error": insert_result.get('error') if not insert_result.get('success') else None,
                "execution_time_seconds": round(duration, 2),
                "extract_time_seconds": round(extract_duration, 2),
                "insert_time_seconds": round(insert_duration, 2),
                "stac_item": item_dict  # Full STAC Item for reference
            }
        }

    except Exception as e:
        # FAILURE - return error with context
        duration = (datetime.utcnow() - start_time).total_seconds() if 'start_time' in locals() else 0
        error_msg = str(e) or type(e).__name__
        logger.error(f"üí• COMPLETE FAILURE after {duration:.2f}s: {error_msg}\n{traceback.format_exc()}")

        return {
            "success": False,
            "error": error_msg,
            "error_type": type(e).__name__,
            "blob_name": params.get("blob_name"),
            "container_name": params.get("container_name"),
            "collection_id": params.get("collection_id"),
            "execution_time_seconds": round(duration, 2),
            "traceback": traceback.format_exc()
        }
